---
title: "RCT_analysis"
author: "Yulin Shao"
date: "2025-06-02"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rio)
library(janitor)
library(readxl)
library(striprtf)
library(stringr)
library(tibble)
library(tidyr)
library(stringi)
library(haven)
library(purrr)
library(DescTools)
library(RobinCar)
library(ggplot2)
library(writexl)
```

# Load Data

```{r}
df_comparison = read_xlsx("cleaned_data/meta_data_comparison.xlsx")
```

# Function

## analyze_rct_sl()

```{r}
analyze_rct_sl = function(data,
                          treatment_col  = "Treatment",
                          outcome_cols,
                          covariate_cols,
                          reference_arm  = NULL,
                          K              = 5,
                          SL_methods     = c("SL.glm", "SL.mean", "SL.glmnet", "SL.rpart", "SL.randomForest", "SL.gam", "SL.bartMachine"),
                          n_cores        = parallel::detectCores() - 2) {
  require(dplyr)
  require(SuperLearner)
  require(foreach)
  require(doSNOW)
  require(doRNG)
  
  n  = nrow(data)
  
  ## ── set up inner cluster ────────────────────────────────────────────────
  cl = makeCluster(n_cores)
  registerDoSNOW(cl)
  registerDoRNG()
  on.exit(stopCluster(cl), add = TRUE)
  
  arms = levels(data[[treatment_col]])
  if (is.null(reference_arm))
    reference_arm = arms[1]
  if (!(reference_arm %in% arms))
    stop("reference_arm must be one of: ", paste(arms, collapse = ", "))
  
  pi_tab = prop.table(table(data[[treatment_col]]))
  
  ## CV splits — handle K = 1 specially
  if (K == 1) {
    splits = list(seq_len(n))
  } else {
    split_ix = sample(rep(1:K, length.out = n))
    splits   = split(seq_len(n), split_ix)
  }
  
  combos = expand.grid(
    Outcome   = outcome_cols,
    Treatment = setdiff(arms, reference_arm),
    stringsAsFactors = FALSE
  )
  
  results = foreach(
    i = seq_len(nrow(combos)),
    .combine = dplyr::bind_rows,
    .packages = c("dplyr", "SuperLearner")
  ) %dopar% {
    Y   = combos$Outcome[i]
    arm = combos$Treatment[i]
    pair_arms = c(reference_arm, arm)
    pi_pair   = pi_tab[pair_arms]
    
    ## matrix to hold EIF contributions for all n rows
    full_preds = matrix(
      NA_real_,
      nrow = n,
      ncol = 2,
      dimnames = list(NULL, pair_arms)
    )
    
    for (k in seq_along(splits)) {
      val_ix   = splits[[k]]
      train_ix = if (K == 1)
        val_ix
      else
        setdiff(seq_len(n), val_ix)
      
      for (a in pair_arms) {
        sel_tr = train_ix[data[[treatment_col]][train_ix] == a]
        
        fit = SuperLearner(
          Y          = data[[Y]][sel_tr],
          X          = data[sel_tr, covariate_cols, drop = FALSE],
          newX       = data[val_ix, covariate_cols, drop = FALSE],
          family     = gaussian(),
          cvControl  = list(V = min(10, length(sel_tr))),
          SL.library = SL_methods
        )
        
        eta_hat = fit$SL.predict
        A_k     = as.integer(data[[treatment_col]][val_ix] == a)
        full_preds[val_ix, a] =
          A_k / pi_pair[a] * (data[[Y]][val_ix] - eta_hat) + eta_hat
      }
    }
    
    D_i = full_preds[, arm] - full_preds[, reference_arm]
    tibble(
      Outcome   = Y,
      Treatment = arm,
      Control   = reference_arm,
      Est_SL    = mean(D_i),
      SE_SL     = sqrt(var(D_i) / n)
    )
  }
  
  results
}
```

## analyze_rct()

```{r}
# variable selection 1
analyze_rct = function(df,
                       outcome_cols = NULL,
                       covariate_col = NULL,
                       treatment_col = "Treatment",
                       K = 5,
                       SL_methods = c("SL.glm", "SL.mean", "SL.glmnet", "SL.rpart", "SL.randomForest", "SL.gam", "SL.bartMachine"),
                       selection = FALSE,
                       n_select = 3,
                       n_cores = parallel::detectCores() - 2,
                       seed = 123) {
  require(dplyr)
  require(RobinCar)
  require(tidyr)
  require(DescTools)
  
  # Set seed once at the beginning for reproducibility
  set.seed(seed)
  
  # Auto-detect outcome columns if not specified
  if (is.null(outcome_cols)) {
    # All YP columns
    yp_cols = names(df)[startsWith(names(df), "YP")]
    
    # Numeric and binary YS columns
    ys_cols = names(df)[startsWith(names(df), "YS")]
    ys_valid = character(0)
    for (col in ys_cols) {
      if (is.numeric(df[[col]]) ||
          (is.factor(df[[col]]) &&
           length(levels(df[[col]])) == 2)) {
        ys_valid = c(ys_valid, col)
      }
    }
    
    outcome_cols = c(yp_cols, ys_valid)
    cat(
      "Auto-detected",
      length(outcome_cols),
      "outcome columns:",
      paste(outcome_cols, collapse = ", "),
      "\n"
    )
  }
  
  # Setup covariates
  if (is.null(covariate_col)) {
    covariates = names(df)[startsWith(names(df), "X_")]
    # Add n_participants if it exists
    if ("n_participants" %in% names(df)) {
      covariates = c(covariates, "n_participants")
    }
  } else {
    covariates = covariate_col
  }
  
  # Fill missing values in covariates
  df = df %>%
    mutate(across(all_of(covariates), ~ if (is.numeric(.)) {
      replace(., is.na(.), mean(., na.rm = TRUE))
    } else if (is.factor(.)) {
      replace(., is.na(.), Mode(., na.rm = TRUE)[1])
    }))
  
  control_level = levels(df[[treatment_col]])[1]
  treat_pattern = paste0("^", treatment_col)
  
  control_level = levels(df[[treatment_col]])[1]
  treat_pattern = paste0("^", treatment_col)
  
  # Process each outcome
  all_results = vector("list", length(outcome_cols))
  valid_outcomes = character(0)
  
  for (i in seq_along(outcome_cols)) {
    outcome = outcome_cols[i]
    
    # Check missing proportion for outcome
    missing_prop = mean(is.na(df[[outcome]]))
    if (missing_prop > 0.4) {
      cat(
        "REMOVED outcome:",
        outcome,
        "- Missing proportion:",
        round(missing_prop, 3),
        "(> 0.4)\n"
      )
      next
    }
    
    # Filter complete cases for this outcome
    complete_vars = c(outcome, treatment_col, covariates)
    complete_cases_idx = complete.cases(df[, complete_vars, drop = FALSE])
    df_complete = df[complete_cases_idx, , drop = FALSE]
    
    cat(
      "Outcome:",
      outcome,
      "- Sample size:",
      nrow(df_complete),
      "(",
      nrow(df) - nrow(df_complete),
      "rows removed)\n"
    )
    
    # Check for single-level factors after filtering
    if (is.factor(df_complete[[outcome]]) &&
        length(levels(droplevels(df_complete[[outcome]]))) <= 1) {
      cat("REMOVED outcome:",
          outcome,
          "- Only one level after filtering\n")
      next
    }
    
    # Check covariates for single levels and remove them
    valid_covariates = character(0)
    for (cov in covariates) {
      if (is.factor(df_complete[[cov]]) &&
          length(levels(droplevels(df_complete[[cov]]))) <= 1) {
        cat(
          "REMOVED covariate:",
          cov,
          "- Only one level after filtering (outcome:",
          outcome,
          ")\n"
        )
      } else {
        valid_covariates = c(valid_covariates, cov)
      }
    }
    
    # Determine if outcome is binary
    is_binary = is.factor(df_complete[[outcome]]) && 
                length(levels(droplevels(df_complete[[outcome]]))) == 2
    
    # For variable selection and traditional models, convert to numeric
    df_complete_numeric = df_complete
    if (is_binary) {
      # Convert binary factor/numeric to 0,1
      # Handle cases where data is already 0,1 or needs conversion from 1,2
      numeric_outcome = as.numeric(df_complete_numeric[[outcome]])
      unique_vals = sort(unique(numeric_outcome))
      
      if (all(unique_vals == c(0, 1))) {
        # Already 0,1 - keep as is
        df_complete_numeric[[outcome]] = numeric_outcome
      } else if (all(unique_vals == c(1, 2))) {
        # Convert 1,2 to 0,1
        df_complete_numeric[[outcome]] = numeric_outcome - 1
      } else {
        stop(paste("Binary outcome", outcome, "has unexpected values:", paste(unique_vals, collapse = ", "), "- expected 0,1 or 1,2"))
      }
    } else {
      df_complete_numeric[[outcome]] = as.numeric(df_complete_numeric[[outcome]])
    }
    
    # Variable selection: select top n_select covariates by outcome-specific correlation
    if (selection && length(valid_covariates) > 0) {
      if (length(valid_covariates) > n_select) {
        # Get correlations between this outcome and ALL covariates (convert factors to numeric temporarily)
        cov_values = numeric(length(valid_covariates))
        names(cov_values) = valid_covariates
        
        for (cov in valid_covariates) {
          # Convert covariate to numeric temporarily for correlation computation
          cov_numeric = as.numeric(df_complete_numeric[[cov]])
          cov_values[cov] = cor(df_complete_numeric[[outcome]], cov_numeric, use = "complete.obs")
        }
        
        # Select top n_select by absolute correlation magnitude
        top_idx = order(abs(cov_values), decreasing = TRUE)[1:n_select]
        selected_covariates = valid_covariates[top_idx]
        valid_covariates = selected_covariates
      }
      # If ≤n_select valid covariates, use all of them (valid_covariates unchanged)
    }
    
    
    # Fit traditional models (using numeric version)
    coef_unadj = coef(summary(lm(
      reformulate(treatment_col, outcome), df_complete_numeric
    )))
    coef_ancova = coef(summary(lm(
      reformulate(c(treatment_col, valid_covariates), outcome), df_complete_numeric
    )))
    
    # Extract treatment effects
    treat_idx_unadj = which(startsWith(rownames(coef_unadj), treatment_col))
    treat_idx_ancova = which(startsWith(rownames(coef_ancova), treatment_col))
    
    # Create results for this outcome
    n_treat = length(treat_idx_unadj)
    treatment_levels = sub(treat_pattern, "", rownames(coef_unadj)[treat_idx_unadj])
    
    # Calculate pairwise sample sizes (control + current treatment)
    pairwise_n = sapply(treatment_levels, function(treat_level) {
      sum(df_complete[[treatment_col]] %in% c(control_level, treat_level))
    })
    
    # Create base outcome results
    outcome_results = tibble(
      Outcome = rep(outcome, n_treat),
      Treatment = treatment_levels,
      Control = rep(control_level, n_treat),
      N = pairwise_n,
      N_Covariates = rep(length(valid_covariates), n_treat),
      # Unadjusted
      Est_UN = coef_unadj[treat_idx_unadj, 1],
      SE_UN = coef_unadj[treat_idx_unadj, 2],
      # ANCOVA
      Est_AC = coef_ancova[treat_idx_ancova, 1],
      SE_AC = coef_ancova[treat_idx_ancova, 2]
    )
    
    # Add Selected_Covariates column only if selection = TRUE
    if (selection) {
      outcome_results$Selected_Covariates = rep(paste(valid_covariates, collapse = ", "), n_treat)
    }
    
    # RobinCar - run both ANCOVA and ANHECOVA (using numeric version)
    rc_fit_ancova = suppressWarnings(
      robincar_linear(
        df_complete_numeric,
        treatment_col,
        outcome,
        covariate_cols = valid_covariates,
        adj_method = "ANCOVA",
        contrast_h = "diff"
      )
    )
    rc_result_ancova = rc_fit_ancova$contrast$result
    outcome_results$Est_RC_ANCOVA = rc_result_ancova$estimate
    outcome_results$SE_RC_ANCOVA = rc_result_ancova$se
    
    rc_fit_anhecova = suppressWarnings(
      robincar_linear(
        df_complete_numeric,
        treatment_col,
        outcome,
        covariate_cols = valid_covariates,
        adj_method = "ANHECOVA",
        contrast_h = "diff"
      )
    )
    rc_result_anhecova = rc_fit_anhecova$contrast$result
    outcome_results$Est_RC_ANHECOVA = rc_result_anhecova$estimate
    outcome_results$SE_RC_ANHECOVA = rc_result_anhecova$se
    
    # RobinCar GLM for binary outcomes
    if (is_binary) {
      # Create formula for GLM: outcome ~ Treatment + covariates
      formula_terms = c(treatment_col, valid_covariates)
      glm_formula = as.formula(paste(outcome, "~", paste(formula_terms, collapse = " + ")))
      
      rc_fit_binom = suppressWarnings(
        robincar_glm(
          df_complete_numeric,  # Use numeric version (0,1 for binary outcome)
          treatment_col,
          outcome,
          formula = glm_formula,
          g_family = stats::binomial,
          contrast_h = "diff"
        )
      )
      rc_result_binom = rc_fit_binom$contrast$result
      outcome_results$Est_RC_Binom = rc_result_binom$estimate
      outcome_results$SE_RC_Binom = rc_result_binom$se
    } else {
      # For non-binary outcomes, set Binom results to NA
      outcome_results$Est_RC_Binom = rep(NA_real_, n_treat)
      outcome_results$SE_RC_Binom = rep(NA_real_, n_treat)
    }
    
    # SuperLearner - run ensemble and individual methods (using numeric version)
    tryCatch({
      sl_res = analyze_rct_sl(
        data = df_complete_numeric,
        outcome_cols = outcome,
        covariate_cols = valid_covariates,
        treatment_col = treatment_col,
        reference_arm = control_level,
        K = K,
        SL_methods = SL_methods,
        n_cores = n_cores
      )
      outcome_results$Est_SL = sl_res$Est_SL
      outcome_results$SE_SL = sl_res$SE_SL
    }, error = function(e) {
      if (grepl("All algorithms dropped from library", e$message)) {
        outcome_results$Est_SL <<- rep(NA_real_, n_treat)
        outcome_results$SE_SL <<- rep(NA_real_, n_treat)
      } else {
        stop(e)
      }
    })
    
    # Run individual SL methods
    individual_methods = c("SL.rpart", "SL.randomForest", "SL.glmnet", "SL.gam", "SL.bartMachine")
    for (method in individual_methods) {
      tryCatch({
        sl_res_individual = analyze_rct_sl(
          data = df_complete_numeric,
          outcome_cols = outcome,
          covariate_cols = valid_covariates,
          treatment_col = treatment_col,
          reference_arm = control_level,
          K = K,
          SL_methods = method,
          n_cores = n_cores
        )
        # Clean method name for column naming
        method_clean = gsub("SL\\.", "SL_", method)
        outcome_results[[paste0("Est_", method_clean)]] = sl_res_individual$Est_SL
        outcome_results[[paste0("SE_", method_clean)]] = sl_res_individual$SE_SL
      }, error = function(e) {
        # For any error, set to NA
        method_clean = gsub("SL\\.", "SL_", method)
        outcome_results[[paste0("Est_", method_clean)]] <<- rep(NA_real_, n_treat)
        outcome_results[[paste0("SE_", method_clean)]] <<- rep(NA_real_, n_treat)
      })
    }
    
    valid_outcomes = c(valid_outcomes, outcome)
    all_results[[length(valid_outcomes)]] = outcome_results
  }
  
  if (length(valid_outcomes) == 0) {
    stop("No valid outcomes remaining after data cleaning")
  }
  
  # Combine all outcomes
  final_results = bind_rows(all_results[1:length(valid_outcomes)]) %>%
    # Round for cleaner output
    mutate(across(starts_with("Est_"), ~ round(.x, 5)),
           across(starts_with("SE_"), ~ round(.x, 5))) %>%
    # Reorder columns
    select(
      Outcome,
      N,
      N_Covariates,
      Treatment,
      Control,
      Est_RC_ANCOVA,
      SE_RC_ANCOVA,
      Est_RC_ANHECOVA,
      SE_RC_ANHECOVA,
      Est_RC_Binom,
      SE_RC_Binom,
      Est_AC,
      SE_AC,
      Est_UN,
      SE_UN,
      Est_SL,
      SE_SL,
      everything()
    )
  
  return(final_results)
}
```

## analyze_rct2
```{r}
# variable selection 2
analyze_rct2 = function(df,
                       outcome_cols = NULL,
                       covariate_col = NULL,
                       treatment_col = "Treatment",
                       K = 5,
                       SL_methods = c("SL.glm", "SL.mean", "SL.glmnet", "SL.rpart", "SL.randomForest", "SL.gam", "SL.bartMachine"),
                       selection = FALSE,
                       manual_covariates = NULL,
                       n_cores = parallel::detectCores() - 2,
                       seed = 123) {
  require(dplyr)
  require(RobinCar)
  require(tidyr)
  require(DescTools)
  
  # Set seed once at the beginning for reproducibility
  set.seed(seed)
  
  # Auto-detect outcome columns if not specified
  if (is.null(outcome_cols)) {
    # All YP columns
    yp_cols = names(df)[startsWith(names(df), "YP")]
    
    # Numeric and binary YS columns
    ys_cols = names(df)[startsWith(names(df), "YS")]
    ys_valid = character(0)
    for (col in ys_cols) {
      if (is.numeric(df[[col]]) ||
          (is.factor(df[[col]]) &&
           length(levels(df[[col]])) == 2)) {
        ys_valid = c(ys_valid, col)
      }
    }
    
    outcome_cols = c(yp_cols, ys_valid)
    cat(
      "Auto-detected",
      length(outcome_cols),
      "outcome columns:",
      paste(outcome_cols, collapse = ", "),
      "\n"
    )
  }
  
  # Setup covariates
  if (is.null(covariate_col)) {
    covariates = names(df)[startsWith(names(df), "X_")]
    # Add n_participants if it exists
    if ("n_participants" %in% names(df)) {
      covariates = c(covariates, "n_participants")
    }
  } else {
    covariates = covariate_col
  }
  
  # Fill missing values in covariates
  df = df %>%
    mutate(across(all_of(covariates), ~ if (is.numeric(.)) {
      replace(., is.na(.), mean(., na.rm = TRUE))
    } else if (is.factor(.)) {
      replace(., is.na(.), Mode(., na.rm = TRUE)[1])
    }))
  
  control_level = levels(df[[treatment_col]])[1]
  treat_pattern = paste0("^", treatment_col)
  
  control_level = levels(df[[treatment_col]])[1]
  treat_pattern = paste0("^", treatment_col)
  
  # Process each outcome
  all_results = vector("list", length(outcome_cols))
  valid_outcomes = character(0)
  
  for (i in seq_along(outcome_cols)) {
    outcome = outcome_cols[i]
    
    # Check missing proportion for outcome
    missing_prop = mean(is.na(df[[outcome]]))
    if (missing_prop > 0.4) {
      cat(
        "REMOVED outcome:",
        outcome,
        "- Missing proportion:",
        round(missing_prop, 3),
        "(> 0.4)\n"
      )
      next
    }
    
    # Filter complete cases for this outcome
    complete_vars = c(outcome, treatment_col, covariates)
    complete_cases_idx = complete.cases(df[, complete_vars, drop = FALSE])
    df_complete = df[complete_cases_idx, , drop = FALSE]
    
    cat(
      "Outcome:",
      outcome,
      "- Sample size:",
      nrow(df_complete),
      "(",
      nrow(df) - nrow(df_complete),
      "rows removed)\n"
    )
    
    # Check for single-level factors after filtering
    if (is.factor(df_complete[[outcome]]) &&
        length(levels(droplevels(df_complete[[outcome]]))) <= 1) {
      cat("REMOVED outcome:",
          outcome,
          "- Only one level after filtering\n")
      next
    }
    
    # Check covariates for single levels and remove them
    valid_covariates = character(0)
    for (cov in covariates) {
      if (is.factor(df_complete[[cov]]) &&
          length(levels(droplevels(df_complete[[cov]]))) <= 1) {
        cat(
          "REMOVED covariate:",
          cov,
          "- Only one level after filtering (outcome:",
          outcome,
          ")\n"
        )
      } else {
        valid_covariates = c(valid_covariates, cov)
      }
    }
    
    # Determine if outcome is binary
    is_binary = is.factor(df_complete[[outcome]]) && 
                length(levels(droplevels(df_complete[[outcome]]))) == 2
    
    # For variable selection and traditional models, convert to numeric
    df_complete_numeric = df_complete
    if (is_binary) {
      # Convert binary factor/numeric to 0,1
      # Handle cases where data is already 0,1 or needs conversion from 1,2
      numeric_outcome = as.numeric(df_complete_numeric[[outcome]])
      unique_vals = sort(unique(numeric_outcome))
      
      if (all(unique_vals == c(0, 1))) {
        # Already 0,1 - keep as is
        df_complete_numeric[[outcome]] = numeric_outcome
      } else if (all(unique_vals == c(1, 2))) {
        # Convert 1,2 to 0,1
        df_complete_numeric[[outcome]] = numeric_outcome - 1
      } else {
        stop(paste("Binary outcome", outcome, "has unexpected values:", paste(unique_vals, collapse = ", "), "- expected 0,1 or 1,2"))
      }
    } else {
      df_complete_numeric[[outcome]] = as.numeric(df_complete_numeric[[outcome]])
    }
    
    # NEW VARIABLE SELECTION SCHEME
    if (selection) {
      # Step 1: Look for baseline measures of the outcome
      baseline_var = NULL
      
      # Extract outcome pattern and timing
      if (startsWith(outcome, "YP_")) {
        # For YP outcomes: YP_abc_7w -> look for X_abc_0w
        # For YP_delta outcomes: YP_delta_abc_7w -> look for X_abc_0w (skip "delta")
        outcome_parts = strsplit(outcome, "_")[[1]]
        if (length(outcome_parts) >= 3) {
          # Check if this is a delta outcome
          if (outcome_parts[2] == "delta") {
            # For YP_delta_abc_7w, extract from position 3 onwards (excluding last part which is timing)
            if (length(outcome_parts) >= 4) {
              middle_parts = outcome_parts[3:(length(outcome_parts)-1)]
              baseline_pattern = paste0("X_", paste(middle_parts, collapse = "_"), "_0")
            }
          } else {
            # For regular YP_abc_7w, extract the middle part(s) and construct baseline variable name
            middle_parts = outcome_parts[2:(length(outcome_parts)-1)]
            baseline_pattern = paste0("X_", paste(middle_parts, collapse = "_"), "_0")
          }
          
          # Look for variables that start with this pattern
          if (exists("baseline_pattern")) {
            potential_baseline = valid_covariates[startsWith(valid_covariates, baseline_pattern)]
            if (length(potential_baseline) > 0) {
              baseline_var = potential_baseline[1]  # Take the first match
              cat("Found baseline measure for", outcome, ":", baseline_var, "\n")
            }
          }
        }
      } else if (startsWith(outcome, "YS_")) {
        # For YS outcomes: YS_qwe_8m -> look for X_qwe_0m
        # For YS_delta outcomes: YS_delta_qwe_8m -> look for X_qwe_0m (skip "delta")
        outcome_parts = strsplit(outcome, "_")[[1]]
        if (length(outcome_parts) >= 3) {
          # Check if this is a delta outcome
          if (outcome_parts[2] == "delta") {
            # For YS_delta_qwe_8m, extract from position 3 onwards (excluding last part which is timing)
            if (length(outcome_parts) >= 4) {
              middle_parts = outcome_parts[3:(length(outcome_parts)-1)]
              baseline_pattern = paste0("X_", paste(middle_parts, collapse = "_"), "_0")
            }
          } else {
            # For regular YS_qwe_8m, extract the middle part(s) and construct baseline variable name
            middle_parts = outcome_parts[2:(length(outcome_parts)-1)]
            baseline_pattern = paste0("X_", paste(middle_parts, collapse = "_"), "_0")
          }
          
          # Look for variables that start with this pattern
          if (exists("baseline_pattern")) {
            potential_baseline = valid_covariates[startsWith(valid_covariates, baseline_pattern)]
            if (length(potential_baseline) > 0) {
              baseline_var = potential_baseline[1]  # Take the first match
              cat("Found baseline measure for", outcome, ":", baseline_var, "\n")
            }
          }
        }
      }
      
      # Combine baseline variable with manual covariates
      selected_covariates = character(0)
      
      # Add baseline variable if found
      if (!is.null(baseline_var)) {
        selected_covariates = c(selected_covariates, baseline_var)
      }
      
      # Add manual covariates if provided
      if (!is.null(manual_covariates)) {
        # Filter manual covariates to only include those that exist in valid_covariates
        manual_available = manual_covariates[manual_covariates %in% valid_covariates]
        selected_covariates = c(selected_covariates, manual_available)
      }
      
      # Remove duplicates
      selected_covariates = unique(selected_covariates)
      
      # Check if we have any covariates to work with
      if (length(selected_covariates) == 0) {
        cat("No valid covariates found for outcome:", outcome, "- Setting all estimates to NA\n")
        
        # Create results with NA values
        treatment_levels = levels(df_complete[[treatment_col]])[-1]  # Exclude control
        n_treat = length(treatment_levels)
        
        # Base tibble with core columns
        outcome_results = tibble(
          Outcome = rep(outcome, n_treat),
          Treatment = treatment_levels,
          Control = rep(control_level, n_treat),
          N = rep(nrow(df_complete), n_treat),
          N_Covariates = rep(0, n_treat),
          Selected_Covariates = rep("", n_treat),
          # Set all estimates and SEs to NA
          Est_UN = rep(NA_real_, n_treat),
          SE_UN = rep(NA_real_, n_treat),
          Est_AC = rep(NA_real_, n_treat),
          SE_AC = rep(NA_real_, n_treat),
          Est_RC_ANCOVA = rep(NA_real_, n_treat),
          SE_RC_ANCOVA = rep(NA_real_, n_treat),
          Est_RC_ANHECOVA = rep(NA_real_, n_treat),
          SE_RC_ANHECOVA = rep(NA_real_, n_treat),
          Est_RC_Binom = rep(NA_real_, n_treat),
          SE_RC_Binom = rep(NA_real_, n_treat),
          Est_SL = rep(NA_real_, n_treat),
          SE_SL = rep(NA_real_, n_treat)
        )
        
        # Add individual SL method columns based on what's in SL_methods (excluding SL.glm and SL.mean)
        individual_methods = SL_methods[!SL_methods %in% c("SL.glm", "SL.mean")]
        for (method in individual_methods) {
          method_clean = gsub("SL\\.", "SL_", method)
          outcome_results[[paste0("Est_", method_clean)]] = rep(NA_real_, n_treat)
          outcome_results[[paste0("SE_", method_clean)]] = rep(NA_real_, n_treat)
        }
        
        valid_outcomes = c(valid_outcomes, outcome)
        all_results[[length(valid_outcomes)]] = outcome_results
        next
      }
      
      # Use the selected covariates
      valid_covariates = selected_covariates
      cat("Selected covariates for", outcome, ":", paste(valid_covariates, collapse = ", "), "\n")
    }
    
    # Fit traditional models (using numeric version)
    coef_unadj = coef(summary(lm(
      reformulate(treatment_col, outcome), df_complete_numeric
    )))
    coef_ancova = coef(summary(lm(
      reformulate(c(treatment_col, valid_covariates), outcome), df_complete_numeric
    )))
    
    # Extract treatment effects
    treat_idx_unadj = which(startsWith(rownames(coef_unadj), treatment_col))
    treat_idx_ancova = which(startsWith(rownames(coef_ancova), treatment_col))
    
    # Create results for this outcome
    n_treat = length(treat_idx_unadj)
    treatment_levels = sub(treat_pattern, "", rownames(coef_unadj)[treat_idx_unadj])
    
    # Calculate pairwise sample sizes (control + current treatment)
    pairwise_n = sapply(treatment_levels, function(treat_level) {
      sum(df_complete[[treatment_col]] %in% c(control_level, treat_level))
    })
    
    # Create base outcome results
    outcome_results = tibble(
      Outcome = rep(outcome, n_treat),
      Treatment = treatment_levels,
      Control = rep(control_level, n_treat),
      N = pairwise_n,
      N_Covariates = rep(length(valid_covariates), n_treat),
      # Unadjusted
      Est_UN = coef_unadj[treat_idx_unadj, 1],
      SE_UN = coef_unadj[treat_idx_unadj, 2],
      # ANCOVA
      Est_AC = coef_ancova[treat_idx_ancova, 1],
      SE_AC = coef_ancova[treat_idx_ancova, 2]
    )
    
    # Add Selected_Covariates column only if selection = TRUE
    if (selection) {
      outcome_results$Selected_Covariates = rep(paste(valid_covariates, collapse = ", "), n_treat)
    }
    
    # RobinCar - run both ANCOVA and ANHECOVA (using numeric version)
    rc_fit_ancova = suppressWarnings(
      robincar_linear(
        df_complete_numeric,
        treatment_col,
        outcome,
        covariate_cols = valid_covariates,
        adj_method = "ANCOVA",
        contrast_h = "diff"
      )
    )
    rc_result_ancova = rc_fit_ancova$contrast$result
    outcome_results$Est_RC_ANCOVA = rc_result_ancova$estimate
    outcome_results$SE_RC_ANCOVA = rc_result_ancova$se
    
    rc_fit_anhecova = suppressWarnings(
      robincar_linear(
        df_complete_numeric,
        treatment_col,
        outcome,
        covariate_cols = valid_covariates,
        adj_method = "ANHECOVA",
        contrast_h = "diff"
      )
    )
    rc_result_anhecova = rc_fit_anhecova$contrast$result
    outcome_results$Est_RC_ANHECOVA = rc_result_anhecova$estimate
    outcome_results$SE_RC_ANHECOVA = rc_result_anhecova$se
    
    # RobinCar GLM for binary outcomes
    if (is_binary) {
      # Create formula for GLM: outcome ~ Treatment + covariates
      formula_terms = c(treatment_col, valid_covariates)
      glm_formula = as.formula(paste(outcome, "~", paste(formula_terms, collapse = " + ")))
      
      rc_fit_binom = suppressWarnings(
        robincar_glm(
          df_complete_numeric,  # Use numeric version (0,1 for binary outcome)
          treatment_col,
          outcome,
          formula = glm_formula,
          g_family = stats::binomial,
          contrast_h = "diff"
        )
      )
      rc_result_binom = rc_fit_binom$contrast$result
      outcome_results$Est_RC_Binom = rc_result_binom$estimate
      outcome_results$SE_RC_Binom = rc_result_binom$se
    } else {
      # For non-binary outcomes, set Binom results to NA
      outcome_results$Est_RC_Binom = rep(NA_real_, n_treat)
      outcome_results$SE_RC_Binom = rep(NA_real_, n_treat)
    }
    
    # SuperLearner - run ensemble and individual methods (using numeric version)
    tryCatch({
      sl_res = analyze_rct_sl(
        data = df_complete_numeric,
        outcome_cols = outcome,
        covariate_cols = valid_covariates,
        treatment_col = treatment_col,
        reference_arm = control_level,
        K = K,
        SL_methods = SL_methods,
        n_cores = n_cores
      )
      outcome_results$Est_SL = sl_res$Est_SL
      outcome_results$SE_SL = sl_res$SE_SL
    }, error = function(e) {
      if (grepl("All algorithms dropped from library", e$message)) {
        outcome_results$Est_SL <<- rep(NA_real_, n_treat)
        outcome_results$SE_SL <<- rep(NA_real_, n_treat)
      } else {
        stop(e)
      }
    })
    
    # Run individual SL methods
    individual_methods = SL_methods[!SL_methods %in% c("SL.glm", "SL.mean")]
    for (method in individual_methods) {
      tryCatch({
        sl_res_individual = analyze_rct_sl(
          data = df_complete_numeric,
          outcome_cols = outcome,
          covariate_cols = valid_covariates,
          treatment_col = treatment_col,
          reference_arm = control_level,
          K = K,
          SL_methods = method,
          n_cores = n_cores
        )
        # Clean method name for column naming
        method_clean = gsub("SL\\.", "SL_", method)
        outcome_results[[paste0("Est_", method_clean)]] = sl_res_individual$Est_SL
        outcome_results[[paste0("SE_", method_clean)]] = sl_res_individual$SE_SL
      }, error = function(e) {
        # For any error, set to NA
        method_clean = gsub("SL\\.", "SL_", method)
        outcome_results[[paste0("Est_", method_clean)]] <<- rep(NA_real_, n_treat)
        outcome_results[[paste0("SE_", method_clean)]] <<- rep(NA_real_, n_treat)
      })
    }
    
    valid_outcomes = c(valid_outcomes, outcome)
    all_results[[length(valid_outcomes)]] = outcome_results
  }
  
  if (length(valid_outcomes) == 0) {
    stop("No valid outcomes remaining after data cleaning")
  }
  
  # Combine all outcomes
  final_results = bind_rows(all_results[1:length(valid_outcomes)]) %>%
    # Round for cleaner output
    mutate(across(starts_with("Est_"), ~ round(.x, 5)),
           across(starts_with("SE_"), ~ round(.x, 5))) %>%
    # Reorder columns
    select(
      Outcome,
      N,
      N_Covariates,
      Treatment,
      Control,
      Est_RC_ANCOVA,
      SE_RC_ANCOVA,
      Est_RC_ANHECOVA,
      SE_RC_ANHECOVA,
      Est_RC_Binom,
      SE_RC_Binom,
      Est_AC,
      SE_AC,
      Est_UN,
      SE_UN,
      Est_SL,
      SE_SL,
      everything()
    )
  
  return(final_results)
}
```

# Setting
```{r}
SL2_lib = c("SL.glm", "SL.mean", "SL.rpart", "SL.gam", "SL.glmnet")
```



## update_df()

```{r}
update_df = function(trial_no,
                     outcome_type,
                     results1 = res1,
                     results2 = res2,
                     contrast = "diff",
                     df = df_comparison) {

  library(dplyr)

  ## ────────────────────────────────────────────────────────────────
  ## 0)  Outcome → Outcome-Type lookup
  ## ────────────────────────────────────────────────────────────────
  unique_outcomes = unique(results1$Outcome)
  stopifnot(length(outcome_type) == length(unique_outcomes))

  outcome_type_map = tibble(
    Outcome        = unique_outcomes,
    `Outcome Type` = outcome_type
  )

  ## fixed list of SL members that are run individually (glm/mean NOT included)
  sl_members = c("SL_rpart", "SL_randomForest", "SL_glmnet", "SL_gam", "SL_bartMachine")

  ## helper: safe rename if column exists
  do_rename = function(d, old, new) {
    if (old %in% names(d)) dplyr::rename(d, !!new := dplyr::all_of(old)) else d
  }

  ## ────────────────────────────────────────────────────────────────
  ## 1)  Tidy one result set (BASE or VS) with explicit SL members
  ## ────────────────────────────────────────────────────────────────
  process_results = function(results, suffix = "") {

    if (suffix == "") {
      results_renamed = results %>%
        mutate(
          ANCOVA_est            = Est_RC_ANCOVA,
          ANCOVA_robust_se      = SE_RC_ANCOVA,
          ANHECOVA_est          = Est_RC_ANHECOVA,
          ANHECOVA_robust_se    = SE_RC_ANHECOVA,
          Binom_est             = Est_RC_Binom,
          Binom_robust_se       = SE_RC_Binom,
          ANCOVA_model_based_se = SE_AC,
          Unadjust_est          = Est_UN,
          Unadjust_se           = SE_UN,
          SL_est                = Est_SL,
          SL_se                 = SE_SL
        )
    } else {
      results_renamed = results %>%
        mutate(
          ANCOVA_VS_est            = Est_RC_ANCOVA,
          ANCOVA_VS_robust_se      = SE_RC_ANCOVA,
          ANHECOVA_VS_est          = Est_RC_ANHECOVA,
          ANHECOVA_VS_robust_se    = SE_RC_ANHECOVA,
          Binom_VS_est             = Est_RC_Binom,
          Binom_VS_robust_se       = SE_RC_Binom,
          ANCOVA_VS_model_based_se = SE_AC,
          SL_VS_est                = Est_SL,
          SL_VS_se                 = SE_SL,
          Unadjust_est             = Est_UN,
          Unadjust_se              = SE_UN
        )
    }

    ## ── explicit renames for each individual SL member ─────────────
    for (m in sl_members) {
      old_est = paste0("Est_", m)
      old_se  = paste0("SE_",  m)
      new_est = if (suffix == "") paste0(m, "_est") else paste0(m, "_VS_est")
      new_se  = if (suffix == "") paste0(m, "_se")  else paste0(m, "_VS_se")
      results_renamed = do_rename(results_renamed, old_est, new_est)
      results_renamed = do_rename(results_renamed, old_se,  new_se)
    }

    ## ── attach meta data ───────────────────────────────────────────
    results_processed = results_renamed %>%
      left_join(outcome_type_map, by = "Outcome") %>%
      mutate(
        Trial_No     = trial_no,
        Sample_Size  = N,
        N_Covariates = N_Covariates,
        Contrast     = contrast
      )

    ## ── base/VS summary columns (ensemble + classical) ────────────
    if (suffix == "") {
      results_processed = results_processed %>%
        mutate(
          `How much precision gain can ANCOVA provide?`   = (ANCOVA_robust_se / Unadjust_se)^2,
          `How much precision gain can ANHECOVA provide?` = (ANHECOVA_robust_se / Unadjust_se)^2,
          `How much precision gain can Binom provide?`    = (Binom_robust_se / Unadjust_se)^2,
          `How much precision gain can SL provide?`       = (SL_se / Unadjust_se)^2,
          `ANCOVA vs ANHECOVA variance ratio`             = (ANCOVA_robust_se / ANHECOVA_robust_se)^2,
          `The ratio between robust and model-based variance estimators` =
            (ANCOVA_robust_se / ANCOVA_model_based_se)^2,
          `The difference between unadjusted and ANCOVA point estimates` =
            (ANCOVA_est - Unadjust_est) /
            sqrt((ANCOVA_robust_se^2 + Unadjust_se^2) / 2),
          `The difference between unadjusted and ANHECOVA point estimates` =
            (ANHECOVA_est - Unadjust_est) /
            sqrt((ANHECOVA_robust_se^2 + Unadjust_se^2) / 2),
          `The difference between unadjusted and Binom point estimates` =
            (Binom_est - Unadjust_est) /
            sqrt((Binom_robust_se^2 + Unadjust_se^2) / 2),
          `The difference between unadjusted and SL point estimates` =
            (SL_est - Unadjust_est) /
            sqrt((SL_se^2 + Unadjust_se^2) / 2)
        )
    } else {
      results_processed = results_processed %>%
        mutate(
          `How much precision gain can ANCOVA_VS provide?`   = (ANCOVA_VS_robust_se / Unadjust_se)^2,
          `How much precision gain can ANHECOVA_VS provide?` = (ANHECOVA_VS_robust_se / Unadjust_se)^2,
          `How much precision gain can Binom_VS provide?`    = (Binom_VS_robust_se / Unadjust_se)^2,
          `How much precision gain can SL_VS provide?`       = (SL_VS_se / Unadjust_se)^2,
          `ANCOVA_VS vs ANHECOVA_VS variance ratio`          = (ANCOVA_VS_robust_se / ANHECOVA_VS_robust_se)^2,
          `The ratio between robust and model-based variance estimators_VS` =
            (ANCOVA_VS_robust_se / ANCOVA_VS_model_based_se)^2,
          `The difference between unadjusted and ANCOVA_VS point estimates` =
            (ANCOVA_VS_est - Unadjust_est) /
            sqrt((ANCOVA_VS_robust_se^2 + Unadjust_se^2) / 2),
          `The difference between unadjusted and ANHECOVA_VS point estimates` =
            (ANHECOVA_VS_est - Unadjust_est) /
            sqrt((ANHECOVA_VS_robust_se^2 + Unadjust_se^2) / 2),
          `The difference between unadjusted and Binom_VS point estimates` =
            (Binom_VS_est - Unadjust_est) /
            sqrt((Binom_VS_robust_se^2 + Unadjust_se^2) / 2),
          `The difference between unadjusted and SL_VS point estimates` =
            (SL_VS_est - Unadjust_est) /
            sqrt((SL_VS_se^2 + Unadjust_se^2) / 2)
        )
    }

    ## ── explicit SL-member precision gains & diffs ─────────────────
    for (m in sl_members) {
      if (suffix == "") {
        se_col  = paste0(m, "_se")
        est_col = paste0(m, "_est")
        pg_col  = paste0("How much precision gain can ", m, " provide?")
        df_col  = paste0("The difference between unadjusted and ", m, " point estimates")
      } else {
        se_col  = paste0(m, "_VS_se")
        est_col = paste0(m, "_VS_est")
        pg_col  = paste0("How much precision gain can ", m, "_VS provide?")
        df_col  = paste0("The difference between unadjusted and ", m, "_VS point estimates")
      }
      if (all(c(se_col, est_col) %in% names(results_processed))) {
        results_processed = results_processed %>%
          mutate(
            !!pg_col := (.data[[se_col]] / Unadjust_se)^2,
            !!df_col := (.data[[est_col]] - Unadjust_est) /
                        sqrt((.data[[se_col]]^2 + Unadjust_se^2) / 2)
          )
      }
    }

    results_processed
  }

  ## ────────────────────────────────────────────────────────────────
  ## 2)  Process BASE and (optional) VS results
  ## ────────────────────────────────────────────────────────────────
  new_rows_base = process_results(results1, "")
  new_rows      = new_rows_base

  if (!is.null(results2)) {
    new_rows_vs = process_results(results2, "VS") %>%
      select(-N_Covariates)  # keep Selected_Covariates if present

    join_keys = c("Trial_No", "Sample_Size", "Contrast",
                  "Treatment", "Control", "Outcome",
                  "Unadjust_est", "Unadjust_se")

    new_rows = new_rows_base %>%
      left_join(new_rows_vs, by = join_keys, suffix = c("", ".vs")) %>%
      select(-dplyr::matches("\\.vs$"))
  }

  ## ────────────────────────────────────────────────────────────────
  ## 3)  Desired column order (explicit blocks)
  ## ────────────────────────────────────────────────────────────────
  base_cols = if (!is.null(results2)) {
    c("Trial_No", "Sample_Size", "N_Covariates", "Selected_Covariates",
      "Treatment", "Control", "Contrast", "Outcome", "Outcome Type")
  } else {
    c("Trial_No", "Sample_Size", "N_Covariates",
      "Treatment", "Control", "Contrast", "Outcome", "Outcome Type")
  }

  se_unadj = "Unadjust_se"

  se_base = c(
    "ANCOVA_robust_se","ANCOVA_model_based_se","ANHECOVA_robust_se",
    "Binom_robust_se","SL_se",
    "SL_rpart_se","SL_randomForest_se","SL_glmnet_se","SL_gam_se","SL_bartMachine_se"
  )
  se_vs   = c(
    "ANCOVA_VS_robust_se","ANCOVA_VS_model_based_se","ANHECOVA_VS_robust_se",
    "Binom_VS_robust_se","SL_VS_se",
    "SL_rpart_VS_se","SL_randomForest_VS_se","SL_glmnet_VS_se","SL_gam_VS_se","SL_bartMachine_VS_se"
  )

  pg_base = c(
    "How much precision gain can ANCOVA provide?",
    "How much precision gain can ANHECOVA provide?",
    "How much precision gain can Binom provide?",
    "How much precision gain can SL provide?",
    "How much precision gain can SL_rpart provide?",
    "How much precision gain can SL_randomForest provide?",
    "How much precision gain can SL_glmnet provide?",
    "How much precision gain can SL_gam provide?",
    "How much precision gain can SL_bartMachine provide?"
  )
  pg_vs = c(
    "How much precision gain can ANCOVA_VS provide?",
    "How much precision gain can ANHECOVA_VS provide?",
    "How much precision gain can Binom_VS provide?",
    "How much precision gain can SL_VS provide?",
    "How much precision gain can SL_rpart_VS provide?",
    "How much precision gain can SL_randomForest_VS provide?",
    "How much precision gain can SL_glmnet_VS provide?",
    "How much precision gain can SL_gam_VS provide?",
    "How much precision gain can SL_bartMachine_VS provide?"
  )

  ratio_base = c(
    "The ratio between robust and model-based variance estimators",
    "ANCOVA vs ANHECOVA variance ratio"
  )
  ratio_vs = c(
    "The ratio between robust and model-based variance estimators_VS",
    "ANCOVA_VS vs ANHECOVA_VS variance ratio"
  )

  est_unadj = "Unadjust_est"

  est_base = c(
    "ANCOVA_est","ANHECOVA_est","Binom_est","SL_est",
    "SL_rpart_est","SL_randomForest_est","SL_glmnet_est","SL_gam_est","SL_bartMachine_est"
  )
  est_vs = c(
    "ANCOVA_VS_est","ANHECOVA_VS_est","Binom_VS_est","SL_VS_est",
    "SL_rpart_VS_est","SL_randomForest_VS_est","SL_glmnet_VS_est","SL_gam_VS_est","SL_bartMachine_VS_est"
  )

  diff_base = c(
    "The difference between unadjusted and ANCOVA point estimates",
    "The difference between unadjusted and ANHECOVA point estimates",
    "The difference between unadjusted and Binom point estimates",
    "The difference between unadjusted and SL point estimates",
    "The difference between unadjusted and SL_rpart point estimates",
    "The difference between unadjusted and SL_randomForest point estimates",
    "The difference between unadjusted and SL_glmnet point estimates",
    "The difference between unadjusted and SL_gam point estimates",
    "The difference between unadjusted and SL_bartMachine point estimates"
  )
  diff_vs = c(
    "The difference between unadjusted and ANCOVA_VS point estimates",
    "The difference between unadjusted and ANHECOVA_VS point estimates",
    "The difference between unadjusted and Binom_VS point estimates",
    "The difference between unadjusted and SL_VS point estimates",
    "The difference between unadjusted and SL_rpart_VS point estimates",
    "The difference between unadjusted and SL_randomForest_VS point estimates",
    "The difference between unadjusted and SL_glmnet_VS point estimates",
    "The difference between unadjusted and SL_gam_VS point estimates",
    "The difference between unadjusted and SL_bartMachine_VS point estimates"
  )

  all_cols = if (!is.null(results2)) {
    c(base_cols, se_unadj, se_base, se_vs,
      pg_base, pg_vs, ratio_base, ratio_vs,
      est_unadj, est_base, est_vs, diff_base, diff_vs)
  } else {
    c(base_cols, se_unadj, se_base,
      pg_base, ratio_base, est_unadj, est_base, diff_base)
  }

  new_rows = dplyr::select(new_rows, dplyr::all_of(intersect(all_cols, names(new_rows))))

  ## ────────────────────────────────────────────────────────────────
  ## 4)  Overwrite / append in df_comparison
  ## ────────────────────────────────────────────────────────────────
  for (i in seq_len(nrow(new_rows))) {
    row_i = new_rows[i, ]

    idx = which(
      df$Trial_No == row_i$Trial_No &
      df$Outcome   == row_i$Outcome &
      df$Treatment == row_i$Treatment &
      df$Control   == row_i$Control
    )

    if (length(idx) > 0) df[idx[1], names(row_i)] = row_i
    else                 df = dplyr::bind_rows(df, row_i)
  }

  df
}



```

# Trial 1

## Load Data

```{r}
df1 = read_rds("cleaned_data/Non_Clustered_RCT/trial1.rds")
```

## Process
```{r}
res1 = analyze_rct(df1)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df1, selection = T)

df_comparison = update_df(1, rep("continuous", 15))
```

```{r}
# vs2
demo = c("X_Age_0m", "X_Weight_0m")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df1, selection = T)
```

# Trial 2

## Load Data

```{r}
df2 = read_rds("cleaned_data/Non_Clustered_RCT/trial2.rds")

df2 = df2 %>% select(-YP_early_7d, -YP_late_12d)
```

## Process
```{r}
res1 = analyze_rct(df2)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df2, selection = T)

df_comparison = update_df(2, c("time to event", "binary", "binary"))
```

```{r}
# vs2
demo = c("X_agegrp_0d", "X_sex_0d")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df2, selection = T)
```


# Trial 3

## Load Data

```{r}
df3 = read_rds("cleaned_data/Non_Clustered_RCT/trial3.rds")
```

## Process
```{r}
res1 = analyze_rct(df3)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df3, selection = T)

df_comparison = update_df(3, c("binary", "time to event", rep("binary", 4), "continuous", "binary"))
```

```{r}
# vs2
demo = c("X_age_0m", "X_sex_0m")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df3, selection = T)
```

# Trial 4

## Load Data

```{r}
df4 = read_rds("cleaned_data/Non_Clustered_RCT/trial4.rds")
```

## Process

```{r}
type = c("continuous", "continuous", "continuous", "continuous")
demo = c("X_Sex_0w", "X_Age_0w", "X_BMI_0w")
```


```{r}
# SL1
res1 = analyze_rct(df4)

df_comparison = update_df(4, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")

res2 = analyze_rct(df4, T)

df_comparison = update_df(4, type, res2, "VS1")
```

```{r}
# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")

res3 = analyze_rct(df4, T, 2, demo)

df_comparison = update_df(4, type, res3, "VS2")
```


```{r}
# SL2
res1 = analyze_rct(df4, F, 1, F, SL2_lib)

df_comparison = update_df(4, type, res1, ensemble = 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df4, T, 1, )

df_comparison = update_df(4, type, res2, "VS1", ensemble = 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df4, selection = T, manual_covariates = demo)

df_comparison = update_df(4, type, res3, "VS2", ensemble = 2)
```

# Trial 5

## Load Data

```{r}
df5 = read_rds("cleaned_data/Non_Clustered_RCT/trial5.rds")
```

## Process

```{r}
res1 = analyze_rct(df5)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df5, selection = T)

df_comparison = update_df(5, c("composite binary", "continuous", rep("binary", 10), rep("continuous", 3), "binary"))
```

```{r}
# vs2
demo = c("X_age_0m", "X_sex_0m")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df5, selection = T)
```

# Trial 6

## Load Data

```{r}
df6 = read_rds("cleaned_data/Non_Clustered_RCT/trial6.rds")
```

## Process

```{r}
res1 = analyze_rct(df6)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df6, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(6, rep("continuous", n))
```

```{r}
# vs2
demo = c("X_age_0m", "X_sex_0m")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df6, selection = T)
```

# Trial 7

## Load Data

```{r}
df7 = read_rds("cleaned_data/Non_Clustered_RCT/trial7.rds")
```

## Process

```{r}
res1 = analyze_rct(df7)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df7, selection = T)

df_comparison = update_df(7, rep("continuous", 8))
```

```{r}
# vs2
demo = c("X_Age_0h", "X_Gender_0h")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df7, selection = T)
```

# Trial 8

## Load Data

```{r}
df8 = read_rds("cleaned_data/Non_Clustered_RCT/trial8.rds")

df8 = df8 %>% select(-X_comorbidities_0d)
```

## Process

```{r}
res1 = analyze_rct(df8)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df8, selection = T)

df_comparison = update_df(8, rep("binary", 6))
```


```{r}
# vs2
demo = c("X_Age_0d", "X_Sex_0d")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df8, selection = T)
```

# Trial 9

## Load Data

```{r}
df9 = read_rds("cleaned_data/Non_Clustered_RCT/trial9.rds")
```

## Process

```{r}
res1 = analyze_rct(df9)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df9, selection = T)

df_comparison = update_df(9, c("binary", rep("continuous", 4), rep("binary", 10), "continuous",
                               rep("binary", 2), "continuous", rep("binary", 2)))
```

```{r}
# vs2
demo = c("X_age_0d")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df9, selection = T)
```

# Trial 10
## Load Data

```{r}
df10 = read_rds("cleaned_data/Non_Clustered_RCT/trial10.rds")
```

## Process

```{r}
res1 = analyze_rct(df10)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df10, selection = T)

df_comparison = update_df(10, c(rep("binary", 3), "continuous", rep("binary", 3), rep("continuous", 15)))
```

```{r}
# vs2
demo = c("X_center_0d", "X_sex_0d", "X_age_0d", "X_weight_0d")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df10, selection = T)
```
# Trial 11
## Load Data

```{r}
df11 = read_rds("cleaned_data/Non_Clustered_RCT/trial11.rds")
```

## Process

```{r}
res1 = analyze_rct(df11)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df11, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(11, rep("continuous", n))
```

```{r}
# vs2
demo = c("X_sex_0w")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df11, selection = T)
```

# Trial 12
## Load Data

```{r}
df12 = read_rds("cleaned_data/Non_Clustered_RCT/trial12.rds")
```

## Process

```{r}
res1 = analyze_rct(df12)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df12, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(12, c(rep("binary", n)))
```

```{r}
# vs2
demo = c("X_AuthorGender_0w")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df12, selection = T)
```

# Trial 13
## Load Data

```{r}
df13 = read_rds("cleaned_data/Non_Clustered_RCT/trial13.rds")
```

## Process

```{r}
res1 = analyze_rct(df13)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df13, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(13, c("continuous", "binary", rep("continuous", 8), "binary", "binary", rep("continuous", 5)))
```

```{r}
# vs2
demo = c("X_AGE_0min")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df13, selection = T)
```

# Trial 14
## Load Data

```{r}
df14 = read_rds("cleaned_data/Non_Clustered_RCT/trial14.rds")
```

## Process

```{r}
res1 = analyze_rct(df14)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df14, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(14, c(rep("continuous", n-5), rep("binary", 5)))
```

```{r}
# vs2
demo = c("X_center_0w", "X_sex_0w", "X_age_0w")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df14, selection = T)
```

# Trial 15
## Load Data

```{r}
df15 = read_rds("cleaned_data/Non_Clustered_RCT/trial15.rds")
```

## Process

```{r}
res1 = analyze_rct(df15)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df15, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(15, rep("continuous", n))
```

```{r}
# vs2
demo = c()
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df15, selection = T)
```


# Trial 16
## Load Data

```{r}
df16 = read_rds("cleaned_data/Non_Clustered_RCT/trial16.rds")
```

## Process

```{r}
res1 = analyze_rct(df16)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df16, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(16, rep("continuous", n))
```

```{r}
# vs2
demo = c("X_age_0w", "X_sex_0w")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df16, selection = T)
```


# Trial 17
## Load Data

```{r}
df17 = read_rds("cleaned_data/Non_Clustered_RCT/trial17.rds")
```

## Process

```{r}
res1 = analyze_rct(df17)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df17, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(17, rep("continuous", n))
```

```{r}
# vs2
demo = c("X_age_0w", "X_sex_0w", "X_BMI_0w")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df17, selection = T)
```


# Trial 18
## Load Data

```{r}
df18 = read_rds("cleaned_data/Non_Clustered_RCT/trial18.rds") %>% 
  select(-YP_event_disengaged_12m)
```

## Process

```{r}
res1 = analyze_rct(df18)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df18, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(18, c("time to event", rep("continuous", n-1)))
```

```{r}
# vs2
demo = c("X_AgeCat_0m", "X_Gender_0m")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df18, selection = T)
```


# Trial 19
## Load Data

```{r}
df19 = read_rds("cleaned_data/Non_Clustered_RCT/trial19.rds")
```

## Process

```{r}
res1 = analyze_rct(df19)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df19, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(19, c(rep("continuous", n-1), "binary"))
```

```{r}
# vs2
demo = c("X_RECIPIENT_AGE_YEARS_0d", "X_RECIPIENT_GENDER_0d")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df19, selection = T)
```


# Trial 20
## Load Data

```{r}
df20 = read_rds("cleaned_data/Non_Clustered_RCT/trial20.rds")
```

## Process

```{r}
res1 = analyze_rct(df20)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df20, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(20, rep("continuous", n))
```

```{r}
# vs2
demo = c("X_Age_0w", "X_Sex_0w", "X_Weight_0w")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df20, selection = T)
```


# Trial 21
## Load Data

```{r}
df21 = read_rds("cleaned_data/Non_Clustered_RCT/trial21.rds") %>% 
  select(-YP_tb_treatment_initiation)
```

## Process

```{r}
res1 = analyze_rct(df21)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df21, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(21, c("time to event", rep("binary", 4), "continuous"))
```

```{r}
# vs2
demo = c()
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df21, selection = T)
```


# Trial 22
## Load Data

```{r}
df22 = read_rds("cleaned_data/Non_Clustered_RCT/trial22.rds")
```

## Process

```{r}
res1 = analyze_rct(df22)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df22, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(22, c(rep("binary", 2), "continuous", rep("binary", 1), "continuous"))
```

```{r}
# vs2
demo = c("X_age_0w")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df22, selection = T)
```


# Trial 23
## Load Data

```{r}
df23 = read_rds("cleaned_data/Non_Clustered_RCT/trial23.rds") %>% 
  select(-YP_event_28d, -YP_event_90d)
```

## Process

```{r}
res1 = analyze_rct(df23)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df23, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(23, c("time to event", "time to event", rep("continuous", n - 2)))
```

```{r}
# vs2
demo = c()
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df23, selection = T)
```


# Trial 24
## Load Data

```{r}
df24 = read_rds("cleaned_data/Non_Clustered_RCT/trial24.rds")
```

## Process

```{r}
res1 = analyze_rct(df24)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df24, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(24, c("binary", "continuous", "continuous"))
```

```{r}
# vs2
demo = c("X_Age_0d", "X_Weight_0d")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df24, selection = T)
```


# Trial 25
## Load Data

```{r}
df25 = read_rds("cleaned_data/Non_Clustered_RCT/trial25.rds")
```

## Process

```{r}
res1 = analyze_rct(df25)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df25, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(25, c(rep("continuous", 11), "binary", rep("continuous", 5)))
```

```{r}
# vs2
demo = c("X_Sex_0w", "X_BMI_0w")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df25, selection = T)
```


# Trial 26
## Load Data

```{r}
df26 = read_rds("cleaned_data/Non_Clustered_RCT/trial26.rds")
```

## Process

```{r}
res1 = analyze_rct(df26)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df26, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(26, c("continuous", "binary", "categorical", rep("continuous", n-3)))
```

```{r}
# vs2
demo = c("X_Agecat_0m", "X_weight_0m")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df26, selection = T)
```


# Trial 27
## Load Data

```{r}
df27 = read_rds("cleaned_data/Non_Clustered_RCT/trial27.rds")
```

## Process

```{r}
res1 = analyze_rct(df27)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df27, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(27, c("categorical", "binary", "continuous", "categorical",
                                "continuous", "continuous", "binary", "continuous"))
```

```{r}
# vs2
demo = c()
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df27, selection = T)
```


# Trial 28
## Load Data

```{r}
df28 = read_rds("cleaned_data/Non_Clustered_RCT/trial28.rds")
```

## Process

```{r}
res1 = analyze_rct(df28)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df28, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(28, c("binary", rep("continuous", 7), "binary", "continuous",
                                "binary", rep("continuous", 2)))
```

```{r}
# vs2
demo = c("X_SEX_0m", "X_Age_0m", "X_BMI_0m")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df28, selection = T)
```


# Trial 29
## Load Data

```{r}
df29 = read_rds("cleaned_data/Non_Clustered_RCT/trial29.rds") %>% 
  select(-YP_death)
```

## Process

```{r}
res1 = analyze_rct(df29)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df29, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(29, c("time to event", "binary", "binary", "continuous"))
```

```{r}
# vs2
demo = c("X_age_0w", "X_sex_0w", "X_on_art_0w")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df29, selection = T)
```



# Trial 30
## Load Data

```{r}
df30 = read_rds("cleaned_data/Non_Clustered_RCT/trial30.rds")
```

## Process

```{r}
res1 = analyze_rct(df30)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df30, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(30, c(rep("continuous", 6), "binary", rep("continuous", 2)))
```

```{r}
# vs2
demo = c("X_Sex_0d", "X_Age_0d")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df30, selection = T)
```

# Trial 31
## Load Data

```{r}
df31 = read_rds("cleaned_data/Non_Clustered_RCT/trial31.rds") %>% 
  select(-YP_flu_infection)
```

## Process

```{r}
res1 = analyze_rct(df31)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df31, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(31, c("time to event", "continuous", "continuous", "binary", "binary"))
```

```{r}
# vs2
demo = c("X_age_0w")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df31, selection = T)
```


# Trial 32
## Load Data

```{r}
df32 = read_rds("cleaned_data/Non_Clustered_RCT/trial32.rds")
```

## Process

```{r}
res1 = analyze_rct(df32)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df32, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(32, c("categorical", "binary", "binary", "binary"))
```

```{r}
# vs2
demo = c("X_gender_0w")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df32, selection = T)
```

# Trial 33
## Load Data

```{r}
df33 = read_rds("cleaned_data/Non_Clustered_RCT/trial33.rds")
```

## Process

```{r}
res1 = analyze_rct(df33)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df33, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(33, c("continuous", "binary"))
```

```{r}
# vs2
demo = c("X_age_0w", "X_Gender_0w", "X_DiseaseGroup_0w")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df33, selection = T)
```

# Trial 34
## Load Data

```{r}
df34 = read_rds("cleaned_data/Non_Clustered_RCT/trial34.rds")
```

## Process

```{r}
res1 = analyze_rct(df34)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df34, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(34, c("binary", "continuous", rep("binary", 6)))
```

```{r}
# vs2
demo = c("X_wt_0d", "X_sex_0d")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df34, selection = T)
```

# Trial 35
## Load Data

```{r}
df35 = read_rds("cleaned_data/Non_Clustered_RCT/trial35.rds")
```

## Process

```{r}
res1 = analyze_rct(df35)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df35, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(35, c("continuous", "continuous", "continuous", "binary",
                                rep("continuous", 6)))
```

```{r}
# vs2
demo = c("X_BMI_0w")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df35, selection = T)
```

# Trial 36
## Load Data

```{r}
df36 = read_rds("cleaned_data/Non_Clustered_RCT/trial36.rds")
```

## Process

```{r}
res1 = analyze_rct(df36)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df36, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(36, rep("continuous", n))
```

```{r}
# vs2
demo = c()
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df36, selection = T)
```

# Trial 37
## Load Data

```{r}
df37 = read_rds("cleaned_data/Non_Clustered_RCT/trial37.rds")
```

## Process

```{r}
res1 = analyze_rct(df37)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df37, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(37, rep("binary", n))
```

```{r}
# vs2
demo = c("X_site_0d", "X_age_0d", "X_gender_0d")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df37, selection = T)
```

# Trial 38
## Load Data

```{r}
df38 = read_rds("cleaned_data/Non_Clustered_RCT/trial38.rds") %>% 
  select(-YP_event_flag)
```

## Process

```{r}
res1 = analyze_rct(df38)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df38, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(38, c("time to event", "continuous", "continuous"))
```

```{r}
# vs2
demo = c("X_age_0w", "X_weight_0w", "X_gender_0w")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df38, selection = T)
```


# Trial 39
## Load Data

```{r}
df39 = read_rds("cleaned_data/Non_Clustered_RCT/trial39.rds") %>% 
  select(-YP_event_flag)
```


## Process

```{r}
res1 = analyze_rct(df39)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df39, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(39, c("time to event"))
```

```{r}
# vs2
demo = c("X_age_0w", "X_sex_0w", "X_substance_0w")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df39, selection = T)
```

# Trial 40
## Load Data

```{r}
df40 = read_rds("cleaned_data/Non_Clustered_RCT/trial40.rds") %>% 
  select(-YP_success_flag,  -YS_attempt1_time, -YS_attempt2_time, -YS_attempt3_time,
         -YS_attempt1_success, -YS_attempt2_success, -YS_attempt3_success, -YS_attempt2_assigned,-YS_attempt3_assigned)
```


## Process

```{r}
res1 = analyze_rct(df40)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df40, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(40, c("time to event", "continuous", "continuous", "binary", "continuous",
                                "continuous", "binary"))
```

```{r}
# vs2
demo = c("X_age_0d", "X_gender_0d", "X_BMI_0d")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df40, selection = T)
```

# Trial 41
## Load Data

```{r}
df41 = read_rds("cleaned_data/Non_Clustered_RCT/trial41.rds")
```


## Process

```{r}
res1 = analyze_rct(df41)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df41, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(41, c(rep("binary", 5)))
```

```{r}
# vs2
demo = c("X_gender_0h", "X_BMI_0h", "X_age_0h")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df41, selection = T)
```


# Trial 42
## Load Data

```{r}
df42 = read_rds("cleaned_data/Non_Clustered_RCT/trial42.rds") %>% 
  select(-YP_onset_sensory_censor, -YS_med_duration, -YS_med_duration_censor)
```


## Process

```{r}
res1 = analyze_rct(df42)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df42, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(42, c("time to event", rep("continuous", n-1)))
```

```{r}
# vs2
demo = c("X_gender_0h", "X_bmi_0h", "X_age_0h")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df42, selection = T)
```

# Trial 43
## Load Data

```{r}
df43 = read_rds("cleaned_data/Non_Clustered_RCT/trial43.rds") %>% 
  select(-YP_preterm_flag)
```


## Process

```{r}
res1 = analyze_rct(df43)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df43, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(43, c("time to event", rep("continuous", 3), "binary"))
```

```{r}
# vs2
demo = c("X_Age_0d", "X_BMI_0d")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df43, selection = T)
```

# Trial 44
## Load Data

```{r}
df44 = read_rds("cleaned_data/Non_Clustered_RCT/trial44.rds")
```


## Process

```{r}
res1 = analyze_rct(df44)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df44, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(44, c("binary", rep("continuous", 3)))
```

```{r}
# vs2
demo = c("X_Age_0m", "X_Sex_0m", "X_Wt_0m")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df44, selection = T)
```

# Trial 45
## Load Data

```{r}
df45 = read_rds("cleaned_data/Non_Clustered_RCT/trial45.rds") %>% 
  select(-YS_delta_icedtea_24w, -YS_delta_alcohol_24w, -YS_delta_salty_24w,
         -YS_delta_fats_24w, -YS_delta_ldl_24w, -YS_delta_tg_24w, -YS_delta_hba1c_24w)
```


## Process

```{r}
res1 = analyze_rct(df45)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df45, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(45, c(rep("continuous", n)))
```

```{r}
# vs2
demo = c("X_weight_8w", "X_store_0w", )
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df45, selection = T)
```

# Trial 46
## Load Data

```{r}
df46 = read_rds("cleaned_data/Non_Clustered_RCT/trial46.rds")
```

## Process

```{r}
res1 = analyze_rct(df46)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df46, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(46, c(rep("continuous", n)))
```

```{r}
# vs2
demo = c("X_Age_0y")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df46, selection = T)
```


# Trial 47
## Load Data

```{r}
df47 = read_rds("cleaned_data/Non_Clustered_RCT/trial47.rds")
```



## Process

```{r}
res1 = analyze_rct(df47)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df47, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(47, c(rep("binary", 1), "continuous", "binary", "binary"))
```

```{r}
# vs2
demo = c("X_gender_0h", "X_age_range_0h", "X_weight_range_0h")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df47, selection = T)
```

# Trial 48
## Load Data

```{r}
df48 = read_rds("cleaned_data/Non_Clustered_RCT/trial48.rds")
```


## Process

```{r}
res1 = analyze_rct(df48)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df48, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(48, c("binary", rep("continuous", 6), rep("binary", 2)))
```

```{r}
# vs2
demo = c("X_age_group", "X_sex")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df48, selection = T)
```


# Trial 49
## Load Data

```{r}
df49 = read_rds("cleaned_data/Non_Clustered_RCT/trial49.rds") %>% 
    select(-YS_t_sondad, -YS_full_oral)
```

## Process

```{r}
res1 = analyze_rct(df49)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df49, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(49, c(rep("continuous", 4), rep("binary", 4), rep("continuous", 9)))
```

```{r}
# vs2
demo = c("X_gestAge_0w", "X_birthWt_0d")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df49, selection = T)
```

# Trial 50
## Load Data

```{r}
df50 = read_rds("cleaned_data/Non_Clustered_RCT/trial50.rds") %>% 
  select(-YP_first_infection_event)
```


## Process

```{r}
res1 = analyze_rct(df50)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df50, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(50, c("time to event", "continuous"))
```

```{r}
# vs2
demo = c("X_sex_0w", "X_center_0w", "X_age_0w", "X_weight_0w")
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct2(df50, selection = T)
```


# Export

```{r}
write_xlsx(df_comparison, "cleaned_data/meta_data_comparison.xlsx")
```


# Summary Data
```{r}
# Create outcome_group variable
df_new = df_comparison %>%
  mutate(
    outcome_group = case_when(
      `Outcome Type` %in% c("continuous", "continuous proportion") ~ "continuous",
      `Outcome Type` %in% c("ordinal", "categorical") ~ "categorical", 
      `Outcome Type` %in% c("binary", "composite binary") ~ "binary",
      `Outcome Type` == "time to event" ~ "time_to_event",
      TRUE ~ "other"
    )
  )

# Rename all precision gain and variance ratio columns
df_new = df_new %>%
  rename(
    # Precision gain columns
    precision_gain_ANCOVA = `How much precision gain can ANCOVA provide?`,
    precision_gain_ANHECOVA = `How much precision gain can ANHECOVA provide?`,
    precision_gain_Binom = `How much precision gain can Binom provide?`,
    precision_gain_SL = `How much precision gain can SL provide?`,
    precision_gain_SL_rpart = `How much precision gain can SL_rpart provide?`,
    precision_gain_SL_randomForest = `How much precision gain can SL_randomForest provide?`,
    precision_gain_SL_glmnet = `How much precision gain can SL_glmnet provide?`,
    precision_gain_SL_gam = `How much precision gain can SL_gam provide?`,
    precision_gain_SL_bartMachine = `How much precision gain can SL_bartMachine provide?`,
    precision_gain_ANCOVA_VS = `How much precision gain can ANCOVA_VS provide?`,
    precision_gain_ANHECOVA_VS = `How much precision gain can ANHECOVA_VS provide?`,
    precision_gain_Binom_VS = `How much precision gain can Binom_VS provide?`,
    precision_gain_SL_VS = `How much precision gain can SL_VS provide?`,
    precision_gain_SL_rpart_VS = `How much precision gain can SL_rpart_VS provide?`,
    precision_gain_SL_randomForest_VS = `How much precision gain can SL_randomForest_VS provide?`,
    precision_gain_SL_glmnet_VS = `How much precision gain can SL_glmnet_VS provide?`,
    precision_gain_SL_gam_VS = `How much precision gain can SL_gam_VS provide?`,
    precision_gain_SL_bartMachine_VS = `How much precision gain can SL_bartMachine_VS provide?`,
    
    # Variance ratio columns
    variance_ratio_robust_model = `The ratio between robust and model-based variance estimators`,
    variance_ratio_ANCOVA_ANHECOVA = `ANCOVA vs ANHECOVA variance ratio`,
    variance_ratio_robust_model_VS = `The ratio between robust and model-based variance estimators_VS`,
    variance_ratio_ANCOVA_ANHECOVA_VS = `ANCOVA_VS vs ANHECOVA_VS variance ratio`
  )
```



## Variance Summary
```{r}
df_summary = df_new %>%
  group_by(outcome_group) %>%
  summarise(
    # ANCOVA precision-gain
    mean_prec_gain_ANCOVA     = mean(precision_gain_ANCOVA, na.rm = TRUE),
    sd_prec_gain_ANCOVA       = sd(precision_gain_ANCOVA,   na.rm = TRUE),
    
    # ANCOVA robust vs model-based variance ratio (original)
    mean_var_ratio_robust_model     = mean(variance_ratio_robust_model, na.rm = TRUE),
    sd_var_ratio_robust_model       = sd(variance_ratio_robust_model,   na.rm = TRUE),
    
    # ── ANCOVA vs ANHECOVA variance ratio *low outlier removed* ─────────────────────
    mean_var_ratio_ANCOVA_ANHECOVA = {
      v  = variance_ratio_ANCOVA_ANHECOVA
      lb = quantile(v, 0.25, na.rm = TRUE) - 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v >= lb], na.rm = TRUE)
    },
    sd_var_ratio_ANCOVA_ANHECOVA   = {
      v  = variance_ratio_ANCOVA_ANHECOVA
      lb = quantile(v, 0.25, na.rm = TRUE) - 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v >= lb], na.rm = TRUE)
    },
    # ANCOVA vs ANHECOVA variance ratio (full)
    mean_var_ratio_ANCOVA_ANHECOVA_full  = mean(variance_ratio_ANCOVA_ANHECOVA, na.rm = TRUE),
    sd_var_ratio_ANCOVA_ANHECOVA_full    = sd(variance_ratio_ANCOVA_ANHECOVA,   na.rm = TRUE),
    
    # ── ANHECOVA precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_ANHECOVA = {
      v  = precision_gain_ANHECOVA
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_ANHECOVA   = {
      v  = precision_gain_ANHECOVA
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    # ANHECOVA precision-gain (full)
    mean_prec_gain_ANHECOVA_full  = mean(precision_gain_ANHECOVA, na.rm = TRUE),
    sd_prec_gain_ANHECOVA_full    = sd(precision_gain_ANHECOVA,   na.rm = TRUE),
    
    # ── Binom precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_Binom = {
      v  = precision_gain_Binom
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_Binom   = {
      v  = precision_gain_Binom
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    # Binom precision-gain (full)
    mean_prec_gain_Binom_full  = mean(precision_gain_Binom, na.rm = TRUE),
    sd_prec_gain_Binom_full    = sd(precision_gain_Binom,   na.rm = TRUE),
    
    # ── SuperLearner precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_SL = {
      v  = precision_gain_SL
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_SL   = {
      v  = precision_gain_SL
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    # SuperLearner precision-gain (full)
    mean_prec_gain_SL_full     = mean(precision_gain_SL,  na.rm = TRUE),
    sd_prec_gain_SL_full       = sd(precision_gain_SL,    na.rm = TRUE),
    
    # ── SL_rpart precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_SL_rpart = {
      v  = precision_gain_SL_rpart
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_SL_rpart   = {
      v  = precision_gain_SL_rpart
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    # SL_rpart precision-gain (full)
    mean_prec_gain_SL_rpart_full  = mean(precision_gain_SL_rpart, na.rm = TRUE),
    sd_prec_gain_SL_rpart_full    = sd(precision_gain_SL_rpart,   na.rm = TRUE),
    
    # ── SL_randomForest precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_SL_randomForest = {
      v  = precision_gain_SL_randomForest
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_SL_randomForest   = {
      v  = precision_gain_SL_randomForest
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    # SL_randomForest precision-gain (full)
    mean_prec_gain_SL_randomForest_full  = mean(precision_gain_SL_randomForest, na.rm = TRUE),
    sd_prec_gain_SL_randomForest_full    = sd(precision_gain_SL_randomForest,   na.rm = TRUE),
    
    # ── SL_glmnet precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_SL_glmnet = {
      v  = precision_gain_SL_glmnet
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_SL_glmnet   = {
      v  = precision_gain_SL_glmnet
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    # SL_glmnet precision-gain (full)
    mean_prec_gain_SL_glmnet_full  = mean(precision_gain_SL_glmnet, na.rm = TRUE),
    sd_prec_gain_SL_glmnet_full    = sd(precision_gain_SL_glmnet,   na.rm = TRUE),
    
    # ── SL_gam precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_SL_gam = {
      v  = precision_gain_SL_gam
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_SL_gam   = {
      v  = precision_gain_SL_gam
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    # SL_gam precision-gain (full)
    mean_prec_gain_SL_gam_full  = mean(precision_gain_SL_gam, na.rm = TRUE),
    sd_prec_gain_SL_gam_full    = sd(precision_gain_SL_gam,   na.rm = TRUE),
    
    # ── SL_bartMachine precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_SL_bartMachine = {
      v  = precision_gain_SL_bartMachine
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_SL_bartMachine   = {
      v  = precision_gain_SL_bartMachine
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    # SL_bartMachine precision-gain (full)
    mean_prec_gain_SL_bartMachine_full  = mean(precision_gain_SL_bartMachine, na.rm = TRUE),
    sd_prec_gain_SL_bartMachine_full    = sd(precision_gain_SL_bartMachine,   na.rm = TRUE),
    
    # ── ANCOVA_VS precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_ANCOVA_VS = {
      v  = precision_gain_ANCOVA_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_ANCOVA_VS   = {
      v  = precision_gain_ANCOVA_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    # ANCOVA_VS precision-gain (full)
    mean_prec_gain_ANCOVA_VS_full  = mean(precision_gain_ANCOVA_VS, na.rm = TRUE),
    sd_prec_gain_ANCOVA_VS_full    = sd(precision_gain_ANCOVA_VS,   na.rm = TRUE),
    
    # ── ANHECOVA_VS precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_ANHECOVA_VS = {
      v  = precision_gain_ANHECOVA_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_ANHECOVA_VS   = {
      v  = precision_gain_ANHECOVA_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    # ANHECOVA_VS precision-gain (full)
    mean_prec_gain_ANHECOVA_VS_full  = mean(precision_gain_ANHECOVA_VS, na.rm = TRUE),
    sd_prec_gain_ANHECOVA_VS_full    = sd(precision_gain_ANHECOVA_VS,   na.rm = TRUE),
    
    # ── Binom_VS precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_Binom_VS = {
      v  = precision_gain_Binom_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_Binom_VS   = {
      v  = precision_gain_Binom_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    # Binom_VS precision-gain (full)
    mean_prec_gain_Binom_VS_full  = mean(precision_gain_Binom_VS, na.rm = TRUE),
    sd_prec_gain_Binom_VS_full    = sd(precision_gain_Binom_VS,   na.rm = TRUE),
    
    # ── SL_VS precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_SL_VS = {
      v  = precision_gain_SL_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_SL_VS   = {
      v  = precision_gain_SL_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    # SL_VS precision-gain (full)
    mean_prec_gain_SL_VS_full  = mean(precision_gain_SL_VS, na.rm = TRUE),
    sd_prec_gain_SL_VS_full    = sd(precision_gain_SL_VS,   na.rm = TRUE),
    
    # ── SL_rpart_VS precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_SL_rpart_VS = {
      v  = precision_gain_SL_rpart_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_SL_rpart_VS   = {
      v  = precision_gain_SL_rpart_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    # SL_rpart_VS precision-gain (full)
    mean_prec_gain_SL_rpart_VS_full  = mean(precision_gain_SL_rpart_VS, na.rm = TRUE),
    sd_prec_gain_SL_rpart_VS_full    = sd(precision_gain_SL_rpart_VS,   na.rm = TRUE),
    
    # ── SL_randomForest_VS precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_SL_randomForest_VS = {
      v  = precision_gain_SL_randomForest_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_SL_randomForest_VS   = {
      v  = precision_gain_SL_randomForest_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    # SL_randomForest_VS precision-gain (full)
    mean_prec_gain_SL_randomForest_VS_full  = mean(precision_gain_SL_randomForest_VS, na.rm = TRUE),
    sd_prec_gain_SL_randomForest_VS_full    = sd(precision_gain_SL_randomForest_VS,   na.rm = TRUE),
    
    # ── SL_glmnet_VS precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_SL_glmnet_VS = {
      v  = precision_gain_SL_glmnet_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_SL_glmnet_VS   = {
      v  = precision_gain_SL_glmnet_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    # SL_glmnet_VS precision-gain (full)
    mean_prec_gain_SL_glmnet_VS_full  = mean(precision_gain_SL_glmnet_VS, na.rm = TRUE),
    sd_prec_gain_SL_glmnet_VS_full    = sd(precision_gain_SL_glmnet_VS,   na.rm = TRUE),
    
    # ── SL_gam_VS precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_SL_gam_VS = {
      v  = precision_gain_SL_gam_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_SL_gam_VS   = {
      v  = precision_gain_SL_gam_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    # SL_gam_VS precision-gain (full)
    mean_prec_gain_SL_gam_VS_full  = mean(precision_gain_SL_gam_VS, na.rm = TRUE),
    sd_prec_gain_SL_gam_VS_full    = sd(precision_gain_SL_gam_VS,   na.rm = TRUE),
    
    # ── SL_bartMachine_VS precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_SL_bartMachine_VS = {
      v  = precision_gain_SL_bartMachine_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_SL_bartMachine_VS   = {
      v  = precision_gain_SL_bartMachine_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    # SL_bartMachine_VS precision-gain (full)
    mean_prec_gain_SL_bartMachine_VS_full  = mean(precision_gain_SL_bartMachine_VS, na.rm = TRUE),
    sd_prec_gain_SL_bartMachine_VS_full    = sd(precision_gain_SL_bartMachine_VS,   na.rm = TRUE),
    
    # ── Additional variance ratio variables ─────────────────────
    # Robust vs model-based variance ratio VS (with outlier removal)
    mean_var_ratio_robust_model_VS = {
      v  = variance_ratio_robust_model_VS
      lb = quantile(v, 0.25, na.rm = TRUE) - 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v >= lb], na.rm = TRUE)
    },
    sd_var_ratio_robust_model_VS   = {
      v  = variance_ratio_robust_model_VS
      lb = quantile(v, 0.25, na.rm = TRUE) - 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v >= lb], na.rm = TRUE)
    },
    # Robust vs model-based variance ratio VS (full)
    mean_var_ratio_robust_model_VS_full  = mean(variance_ratio_robust_model_VS, na.rm = TRUE),
    sd_var_ratio_robust_model_VS_full    = sd(variance_ratio_robust_model_VS,   na.rm = TRUE),
    
    # ANCOVA_VS vs ANHECOVA_VS variance ratio (with outlier removal)
    mean_var_ratio_ANCOVA_ANHECOVA_VS = {
      v  = variance_ratio_ANCOVA_ANHECOVA_VS
      lb = quantile(v, 0.25, na.rm = TRUE) - 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v >= lb], na.rm = TRUE)
    },
    sd_var_ratio_ANCOVA_ANHECOVA_VS   = {
      v  = variance_ratio_ANCOVA_ANHECOVA_VS
      lb = quantile(v, 0.25, na.rm = TRUE) - 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v >= lb], na.rm = TRUE)
    },
    # ANCOVA_VS vs ANHECOVA_VS variance ratio (full)
    mean_var_ratio_ANCOVA_ANHECOVA_VS_full  = mean(variance_ratio_ANCOVA_ANHECOVA_VS, na.rm = TRUE),
    sd_var_ratio_ANCOVA_ANHECOVA_VS_full    = sd(variance_ratio_ANCOVA_ANHECOVA_VS,   na.rm = TRUE)
    
  ) %>%
  ungroup()

print(df_summary)
```
### Outlier Removed Table
```{r}
df_summary_filtered = df_new %>%
  group_by(outcome_group) %>%
  summarise(
    # ANCOVA precision-gain (no outlier removal)
    mean_prec_gain_ANCOVA     = mean(precision_gain_ANCOVA, na.rm = TRUE),
    sd_prec_gain_ANCOVA       = sd(precision_gain_ANCOVA,   na.rm = TRUE),
    
    # ANCOVA robust vs model-based variance ratio (no outlier removal)
    mean_var_ratio_robust_model     = mean(variance_ratio_robust_model, na.rm = TRUE),
    sd_var_ratio_robust_model       = sd(variance_ratio_robust_model,   na.rm = TRUE),
    
    # ── ANCOVA vs ANHECOVA variance ratio *low outlier removed* ─────────────────────
    mean_var_ratio_ANCOVA_ANHECOVA = {
      v  = variance_ratio_ANCOVA_ANHECOVA
      lb = quantile(v, 0.25, na.rm = TRUE) - 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v >= lb], na.rm = TRUE)
    },
    sd_var_ratio_ANCOVA_ANHECOVA   = {
      v  = variance_ratio_ANCOVA_ANHECOVA
      lb = quantile(v, 0.25, na.rm = TRUE) - 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v >= lb], na.rm = TRUE)
    },
    
    # ── ANHECOVA precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_ANHECOVA = {
      v  = precision_gain_ANHECOVA
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_ANHECOVA   = {
      v  = precision_gain_ANHECOVA
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    
    # ── Binom precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_Binom = {
      v  = precision_gain_Binom
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_Binom   = {
      v  = precision_gain_Binom
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    
    # ── SuperLearner precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_SL = {
      v  = precision_gain_SL
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_SL   = {
      v  = precision_gain_SL
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    
    # ── SL_rpart precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_SL_rpart = {
      v  = precision_gain_SL_rpart
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_SL_rpart   = {
      v  = precision_gain_SL_rpart
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    
    # ── SL_randomForest precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_SL_randomForest = {
      v  = precision_gain_SL_randomForest
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_SL_randomForest   = {
      v  = precision_gain_SL_randomForest
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    
    # ── SL_glmnet precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_SL_glmnet = {
      v  = precision_gain_SL_glmnet
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_SL_glmnet   = {
      v  = precision_gain_SL_glmnet
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    
    # ── SL_gam precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_SL_gam = {
      v  = precision_gain_SL_gam
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_SL_gam   = {
      v  = precision_gain_SL_gam
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    
    # ── SL_bartMachine precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_SL_bartMachine = {
      v  = precision_gain_SL_bartMachine
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_SL_bartMachine   = {
      v  = precision_gain_SL_bartMachine
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    
    # ── ANCOVA_VS precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_ANCOVA_VS = {
      v  = precision_gain_ANCOVA_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_ANCOVA_VS   = {
      v  = precision_gain_ANCOVA_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    
    # ── ANHECOVA_VS precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_ANHECOVA_VS = {
      v  = precision_gain_ANHECOVA_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_ANHECOVA_VS   = {
      v  = precision_gain_ANHECOVA_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    
    # ── Binom_VS precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_Binom_VS = {
      v  = precision_gain_Binom_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_Binom_VS   = {
      v  = precision_gain_Binom_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    
    # ── SL_VS precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_SL_VS = {
      v  = precision_gain_SL_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_SL_VS   = {
      v  = precision_gain_SL_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    
    # ── SL_rpart_VS precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_SL_rpart_VS = {
      v  = precision_gain_SL_rpart_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_SL_rpart_VS   = {
      v  = precision_gain_SL_rpart_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    
    # ── SL_randomForest_VS precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_SL_randomForest_VS = {
      v  = precision_gain_SL_randomForest_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_SL_randomForest_VS   = {
      v  = precision_gain_SL_randomForest_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    
    # ── SL_glmnet_VS precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_SL_glmnet_VS = {
      v  = precision_gain_SL_glmnet_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_SL_glmnet_VS   = {
      v  = precision_gain_SL_glmnet_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    
    # ── SL_gam_VS precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_SL_gam_VS = {
      v  = precision_gain_SL_gam_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_SL_gam_VS   = {
      v  = precision_gain_SL_gam_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    
    # ── SL_bartMachine_VS precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_SL_bartMachine_VS = {
      v  = precision_gain_SL_bartMachine_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_SL_bartMachine_VS   = {
      v  = precision_gain_SL_bartMachine_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    
    # ── Additional variance ratio variables *outlier removed* ─────────────────────
    # Robust vs model-based variance ratio VS
    mean_var_ratio_robust_model_VS = {
      v  = variance_ratio_robust_model_VS
      lb = quantile(v, 0.25, na.rm = TRUE) - 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v >= lb], na.rm = TRUE)
    },
    sd_var_ratio_robust_model_VS   = {
      v  = variance_ratio_robust_model_VS
      lb = quantile(v, 0.25, na.rm = TRUE) - 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v >= lb], na.rm = TRUE)
    },
    
    # ANCOVA_VS vs ANHECOVA_VS variance ratio
    mean_var_ratio_ANCOVA_ANHECOVA_VS = {
      v  = variance_ratio_ANCOVA_ANHECOVA_VS
      lb = quantile(v, 0.25, na.rm = TRUE) - 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v >= lb], na.rm = TRUE)
    },
    sd_var_ratio_ANCOVA_ANHECOVA_VS   = {
      v  = variance_ratio_ANCOVA_ANHECOVA_VS
      lb = quantile(v, 0.25, na.rm = TRUE) - 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v >= lb], na.rm = TRUE)
    }
    
  ) %>%
  ungroup()

print(df_summary_filtered)
```


## Violin Plot
### Full(n)
```{r}
# Create sample size categories for better visualization
df_new = df_new %>%
  mutate(
    sample_size_cat = case_when(
      Sample_Size < 50 ~ "<50",
      Sample_Size < 100 ~ "50-99", 
      Sample_Size < 500 ~ "100-499",
      TRUE ~ "≥500"
    ),
    sample_size_cat = factor(sample_size_cat, 
                           levels = c("<50", "50-99", "100-499", "≥500")),
    # Log-transform for size mapping (less skewed)
    log_sample_size = log10(Sample_Size)
  )

# Color palette for sample size categories
size_colors = c("<50" = "#d73027", "50-99" = "#fc8d59", 
                "100-499" = "#74c476", "≥500" = "#4575b4")

# Reshape data for plotting all methods together
library(tidyr)

##################################
## Apply outlier removal for each method (except ANCOVA)
##################################

# Function to remove upper outliers
# remove_upper_outliers = function(x) {
#   ub = quantile(x, 0.75, na.rm = TRUE) + 1.5 * IQR(x, na.rm = TRUE)
#   ifelse(x <= ub, x, NA)
# }

remove_upper_outliers = function(x) {
  ifelse(x >= 2, NA, x)
}

# Apply outlier removal to all methods except ANCOVA
df_outlier_removed = df_new %>%
  mutate(
    precision_gain_ANHECOVA = remove_upper_outliers(precision_gain_ANHECOVA),
    precision_gain_Binom = remove_upper_outliers(precision_gain_Binom),
    precision_gain_SL = remove_upper_outliers(precision_gain_SL),
    precision_gain_SL_rpart = remove_upper_outliers(precision_gain_SL_rpart),
    precision_gain_SL_randomForest = remove_upper_outliers(precision_gain_SL_randomForest),
    precision_gain_SL_glmnet = remove_upper_outliers(precision_gain_SL_glmnet),
    precision_gain_SL_gam = remove_upper_outliers(precision_gain_SL_gam),
    precision_gain_SL_bartMachine = remove_upper_outliers(precision_gain_SL_bartMachine),
    precision_gain_ANCOVA_VS = remove_upper_outliers(precision_gain_ANCOVA_VS),
    precision_gain_ANHECOVA_VS = remove_upper_outliers(precision_gain_ANHECOVA_VS),
    precision_gain_Binom_VS = remove_upper_outliers(precision_gain_Binom_VS),
    precision_gain_SL_VS = remove_upper_outliers(precision_gain_SL_VS),
    precision_gain_SL_rpart_VS = remove_upper_outliers(precision_gain_SL_rpart_VS),
    precision_gain_SL_randomForest_VS = remove_upper_outliers(precision_gain_SL_randomForest_VS),
    precision_gain_SL_glmnet_VS = remove_upper_outliers(precision_gain_SL_glmnet_VS),
    precision_gain_SL_gam_VS = remove_upper_outliers(precision_gain_SL_gam_VS),
    precision_gain_SL_bartMachine_VS = remove_upper_outliers(precision_gain_SL_bartMachine_VS)
    # Note: precision_gain_ANCOVA is kept as-is (no outlier removal)
  )

# Create long format data with outlier-removed precision gain methods
df_long_outlier_removed = df_outlier_removed %>%
  select(outcome_group, sample_size_cat, 
         precision_gain_ANCOVA, precision_gain_ANHECOVA, precision_gain_Binom, precision_gain_SL,
         precision_gain_SL_rpart, precision_gain_SL_randomForest, precision_gain_SL_glmnet, 
         precision_gain_SL_gam, precision_gain_SL_bartMachine,
         precision_gain_ANCOVA_VS, precision_gain_ANHECOVA_VS, precision_gain_Binom_VS,
         precision_gain_SL_VS, precision_gain_SL_rpart_VS, precision_gain_SL_randomForest_VS,
         precision_gain_SL_glmnet_VS, precision_gain_SL_gam_VS, precision_gain_SL_bartMachine_VS) %>%
  pivot_longer(cols = starts_with("precision_gain_"), 
               names_to = "method", 
               values_to = "precision_gain") %>%
  filter(!is.na(precision_gain)) %>%  # Remove NA values explicitly
  mutate(
    method = case_when(
      method == "precision_gain_ANCOVA" ~ "ANCOVA",
      method == "precision_gain_ANHECOVA" ~ "ANHECOVA", 
      method == "precision_gain_Binom" ~ "Binom",
      method == "precision_gain_SL" ~ "SL",
      method == "precision_gain_SL_rpart" ~ "SL_rpart",
      method == "precision_gain_SL_randomForest" ~ "SL_randomForest",
      method == "precision_gain_SL_glmnet" ~ "SL_glmnet",
      method == "precision_gain_SL_gam" ~ "SL_gam",
      method == "precision_gain_SL_bartMachine" ~ "SL_bartMachine",
      method == "precision_gain_ANCOVA_VS" ~ "ANCOVA_VS",
      method == "precision_gain_ANHECOVA_VS" ~ "ANHECOVA_VS",
      method == "precision_gain_Binom_VS" ~ "Binom_VS",
      method == "precision_gain_SL_VS" ~ "SL_VS",
      method == "precision_gain_SL_rpart_VS" ~ "SL_rpart_VS",
      method == "precision_gain_SL_randomForest_VS" ~ "SL_randomForest_VS",
      method == "precision_gain_SL_glmnet_VS" ~ "SL_glmnet_VS",
      method == "precision_gain_SL_gam_VS" ~ "SL_gam_VS",
      method == "precision_gain_SL_bartMachine_VS" ~ "SL_bartMachine_VS"
    ),
    method = factor(method, levels = c("ANCOVA", "ANHECOVA", "Binom", "SL", "SL_rpart", "SL_randomForest", 
                                     "SL_glmnet", "SL_gam", "SL_bartMachine",
                                     "ANCOVA_VS", "ANHECOVA_VS", "Binom_VS", "SL_VS", "SL_rpart_VS", 
                                     "SL_randomForest_VS", "SL_glmnet_VS", "SL_gam_VS", "SL_bartMachine_VS"))
  )

# Color palette for methods
method_colors = c("ANCOVA" = "#1f77b4", "ANHECOVA" = "#ff7f0e", "Binom" = "#2ca02c", "SL" = "#d62728",
                  "SL_rpart" = "#9467bd", "SL_randomForest" = "#8c564b", "SL_glmnet" = "#e377c2", 
                  "SL_gam" = "#7f7f7f", "SL_bartMachine" = "#bcbd22",
                  "ANCOVA_VS" = "#17becf", "ANHECOVA_VS" = "#ff9896", "Binom_VS" = "#98df8a",
                  "SL_VS" = "#ffbb78", "SL_rpart_VS" = "#c5b0d5", "SL_randomForest_VS" = "#c49c94", 
                  "SL_glmnet_VS" = "#f7b6d3", "SL_gam_VS" = "#c7c7c7", "SL_bartMachine_VS" = "#dbdb8d")

##################################
## All Methods Together (Outlier Removed) - By Outcome Type
##################################

# 1. Binary Outcome Group - All Methods (Outlier Removed)
df_binary_or = df_long_outlier_removed %>% filter(outcome_group == "binary")

ggplot(df_binary_or, aes(x = method, y = precision_gain)) +
  geom_violin(aes(fill = method), trim = FALSE, alpha = 0.6) +
  geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_fill_manual(values = method_colors, guide = "none") +
  scale_color_manual(values = size_colors, name = "Sample Size") +
  labs(
    title = "Precision Gain vs Unadjusted - Binary \n(Outlier Removed)",
    subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
    x = "",
    y = "Variance Ratio"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
        axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
        panel.grid.minor = element_blank(),
        legend.position = "right",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 9),
        legend.key.size = unit(0.4, "cm"))

# 2. Continuous Outcome Group - All Methods (Outlier Removed)
df_continuous_or = df_long_outlier_removed %>% filter(outcome_group == "continuous")

ggplot(df_continuous_or, aes(x = method, y = precision_gain)) +
  geom_violin(aes(fill = method), trim = FALSE, alpha = 0.6) +
  geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_fill_manual(values = method_colors, guide = "none") +
  scale_color_manual(values = size_colors, name = "Sample Size") +
  labs(
    title = "Precision Gain vs Unadjusted - Continuous \n(Outlier Removed)",
    subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
    x = "",
    y = "Variance Ratio"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
        axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
        panel.grid.minor = element_blank(),
        legend.position = "right",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 9),
        legend.key.size = unit(0.4, "cm"))

# 3. Categorical Outcome Group - All Methods (Outlier Removed)
df_categorical_or = df_long_outlier_removed %>% filter(outcome_group == "categorical")

ggplot(df_categorical_or, aes(x = method, y = precision_gain)) +
  geom_violin(aes(fill = method), trim = FALSE, alpha = 0.6) +
  geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_fill_manual(values = method_colors, guide = "none") +
  scale_color_manual(values = size_colors, name = "Sample Size") +
  labs(
    title = "Precision Gain vs Unadjusted - Categorical \n(Outlier Removed)",
    subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
    x = "",
    y = "Variance Ratio"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
        axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
        panel.grid.minor = element_blank(),
        legend.position = "right",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 9),
        legend.key.size = unit(0.4, "cm"))

# 4. Time-to-Event Outcome Group - All Methods (Outlier Removed)
df_time_to_event_or = df_long_outlier_removed %>% filter(outcome_group == "time_to_event")

ggplot(df_time_to_event_or, aes(x = method, y = precision_gain)) +
  geom_violin(aes(fill = method), trim = FALSE, alpha = 0.6) +
  geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_fill_manual(values = method_colors, guide = "none") +
  scale_color_manual(values = size_colors, name = "Sample Size") +
  labs(
    title = "Precision Gain vs Unadjusted - Time-to-Event\n (Outlier Removed)",
    subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
    x = "",
    y = "Variance Ratio"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
        axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
        panel.grid.minor = element_blank(),
        legend.position = "right",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 9),
        legend.key.size = unit(0.4, "cm"))

##################################
## Individual Method Plots (No Outlier Removal)
##################################

# ANCOVA (already no outlier removal)
ggplot(df_new %>% filter(!is.na(precision_gain_ANCOVA)), aes(x = outcome_group, y = precision_gain_ANCOVA)) +
  geom_violin(trim = FALSE, fill = "#1f77b4", alpha = 0.6) +
  geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_color_manual(values = size_colors, name = "Sample Size") +
  labs(
    title = "ANCOVA Precision Gain vs Unadjusted (Full Data)",
    subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
    x = "Outcome Group",
    y = "Variance Ratio"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
        panel.grid.minor = element_blank(),
        legend.position = "right",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 9),
        legend.key.size = unit(0.4, "cm"))

# ANHECOVA (full data)
ggplot(df_new %>% filter(!is.na(precision_gain_ANHECOVA)), aes(x = outcome_group, y = precision_gain_ANHECOVA)) +
  geom_violin(trim = FALSE, fill = "#ff7f0e", alpha = 0.6) +
  geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_color_manual(values = size_colors, name = "Sample Size") +
  labs(
    title = "ANHECOVA Precision Gain vs Unadjusted (Full Data)",
    subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
    x = "Outcome Group",
    y = "Variance Ratio"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
        panel.grid.minor = element_blank(),
        legend.position = "right",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 9),
        legend.key.size = unit(0.4, "cm"))

# Binom (full data)
ggplot(df_new %>% filter(!is.na(precision_gain_Binom)), aes(x = outcome_group, y = precision_gain_Binom)) +
  geom_violin(trim = FALSE, fill = "#2ca02c", alpha = 0.6) +
  geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_color_manual(values = size_colors, name = "Sample Size") +
  labs(
    title = "Binom Precision Gain vs Unadjusted (Full Data)",
    subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
    x = "Outcome Group",
    y = "Variance Ratio"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
        panel.grid.minor = element_blank(),
        legend.position = "right",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 9),
        legend.key.size = unit(0.4, "cm"))

# Super Learner (full data)
ggplot(df_new %>% filter(!is.na(precision_gain_SL)), aes(x = outcome_group, y = precision_gain_SL)) +
  geom_violin(trim = FALSE, fill = "#d62728", alpha = 0.6) +
  geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_color_manual(values = size_colors, name = "Sample Size") +
  labs(
    title = "Super Learner Precision Gain vs Unadjusted (Full Data)",
    subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
    x = "Outcome Group",
    y = "Variance Ratio"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
        panel.grid.minor = element_blank(),
        legend.position = "right",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 9),
        legend.key.size = unit(0.4, "cm"))

# SL_rpart (full data)
ggplot(df_new %>% filter(!is.na(precision_gain_SL_rpart)), aes(x = outcome_group, y = precision_gain_SL_rpart)) +
  geom_violin(trim = FALSE, fill = "#9467bd", alpha = 0.6) +
  geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_color_manual(values = size_colors, name = "Sample Size") +
  labs(
    title = "SL_rpart Precision Gain vs Unadjusted (Full Data)",
    subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
    x = "Outcome Group",
    y = "Variance Ratio"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
        panel.grid.minor = element_blank(),
        legend.position = "right",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 9),
        legend.key.size = unit(0.4, "cm"))

# SL_randomForest (full data)
ggplot(df_new %>% filter(!is.na(precision_gain_SL_randomForest)), aes(x = outcome_group, y = precision_gain_SL_randomForest)) +
  geom_violin(trim = FALSE, fill = "#8c564b", alpha = 0.6) +
  geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_color_manual(values = size_colors, name = "Sample Size") +
  labs(
    title = "SL_randomForest Precision Gain vs Unadjusted (Full Data)",
    subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
    x = "Outcome Group",
    y = "Variance Ratio"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
        panel.grid.minor = element_blank(),
        legend.position = "right",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 9),
        legend.key.size = unit(0.4, "cm"))

# SL_glmnet (full data)
ggplot(df_new %>% filter(!is.na(precision_gain_SL_glmnet)), aes(x = outcome_group, y = precision_gain_SL_glmnet)) +
  geom_violin(trim = FALSE, fill = "#e377c2", alpha = 0.6) +
  geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_color_manual(values = size_colors, name = "Sample Size") +
  labs(
    title = "SL_glmnet Precision Gain vs Unadjusted (Full Data)",
    subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
    x = "Outcome Group",
    y = "Variance Ratio"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
        panel.grid.minor = element_blank(),
        legend.position = "right",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 9),
        legend.key.size = unit(0.4, "cm"))

# SL_gam (full data)
ggplot(df_new %>% filter(!is.na(precision_gain_SL_gam)), aes(x = outcome_group, y = precision_gain_SL_gam)) +
  geom_violin(trim = FALSE, fill = "#7f7f7f", alpha = 0.6) +
  geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_color_manual(values = size_colors, name = "Sample Size") +
  labs(
    title = "SL_gam Precision Gain vs Unadjusted (Full Data)",
    subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
    x = "Outcome Group",
    y = "Variance Ratio"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
        panel.grid.minor = element_blank(),
        legend.position = "right",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 9),
        legend.key.size = unit(0.4, "cm"))

# SL_bartMachine (full data)
ggplot(df_new %>% filter(!is.na(precision_gain_SL_bartMachine)), aes(x = outcome_group, y = precision_gain_SL_bartMachine)) +
  geom_violin(trim = FALSE, fill = "#bcbd22", alpha = 0.6) +
  geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_color_manual(values = size_colors, name = "Sample Size") +
  labs(
    title = "SL_bartMachine Precision Gain vs Unadjusted (Full Data)",
    subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
    x = "Outcome Group",
    y = "Variance Ratio"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
        panel.grid.minor = element_blank(),
        legend.position = "right",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 9),
        legend.key.size = unit(0.4, "cm"))

# ANCOVA_VS (full data)
ggplot(df_new %>% filter(!is.na(precision_gain_ANCOVA_VS)), aes(x = outcome_group, y = precision_gain_ANCOVA_VS)) +
  geom_violin(trim = FALSE, fill = "#17becf", alpha = 0.6) +
  geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_color_manual(values = size_colors, name = "Sample Size") +
  labs(
    title = "ANCOVA_VS Precision Gain vs Unadjusted (Full Data)",
    subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
    x = "Outcome Group",
    y = "Variance Ratio"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
        panel.grid.minor = element_blank(),
        legend.position = "right",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 9),
        legend.key.size = unit(0.4, "cm"))

# ANHECOVA_VS (full data)
ggplot(df_new %>% filter(!is.na(precision_gain_ANHECOVA_VS)), aes(x = outcome_group, y = precision_gain_ANHECOVA_VS)) +
  geom_violin(trim = FALSE, fill = "#ff9896", alpha = 0.6) +
  geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_color_manual(values = size_colors, name = "Sample Size") +
  labs(
    title = "ANHECOVA_VS Precision Gain vs Unadjusted (Full Data)",
    subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
    x = "Outcome Group",
    y = "Variance Ratio"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
        panel.grid.minor = element_blank(),
        legend.position = "right",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 9),
        legend.key.size = unit(0.4, "cm"))

# Binom_VS (full data)
ggplot(df_new %>% filter(!is.na(precision_gain_Binom_VS)), aes(x = outcome_group, y = precision_gain_Binom_VS)) +
  geom_violin(trim = FALSE, fill = "#98df8a", alpha = 0.6) +
  geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_color_manual(values = size_colors, name = "Sample Size") +
  labs(
    title = "Binom_VS Precision Gain vs Unadjusted (Full Data)",
    subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
    x = "Outcome Group",
    y = "Variance Ratio"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
        panel.grid.minor = element_blank(),
        legend.position = "right",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 9),
        legend.key.size = unit(0.4, "cm"))

# SL_VS (full data)
ggplot(df_new %>% filter(!is.na(precision_gain_SL_VS)), aes(x = outcome_group, y = precision_gain_SL_VS)) +
  geom_violin(trim = FALSE, fill = "#ffbb78", alpha = 0.6) +
  geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_color_manual(values = size_colors, name = "Sample Size") +
  labs(
    title = "SL_VS Precision Gain vs Unadjusted (Full Data)",
    subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
    x = "Outcome Group",
    y = "Variance Ratio"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
        panel.grid.minor = element_blank(),
        legend.position = "right",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 9),
        legend.key.size = unit(0.4, "cm"))

# SL_rpart_VS (full data)
ggplot(df_new %>% filter(!is.na(precision_gain_SL_rpart_VS)), aes(x = outcome_group, y = precision_gain_SL_rpart_VS)) +
  geom_violin(trim = FALSE, fill = "#c5b0d5", alpha = 0.6) +
  geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_color_manual(values = size_colors, name = "Sample Size") +
  labs(
    title = "SL_rpart_VS Precision Gain vs Unadjusted (Full Data)",
    subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
    x = "Outcome Group",
    y = "Variance Ratio"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
        panel.grid.minor = element_blank(),
        legend.position = "right",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 9),
        legend.key.size = unit(0.4, "cm"))

# SL_randomForest_VS (full data)
ggplot(df_new %>% filter(!is.na(precision_gain_SL_randomForest_VS)), aes(x = outcome_group, y = precision_gain_SL_randomForest_VS)) +
  geom_violin(trim = FALSE, fill = "#c49c94", alpha = 0.6) +
  geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_color_manual(values = size_colors, name = "Sample Size") +
  labs(
    title = "SL_randomForest_VS Precision Gain vs Unadjusted (Full Data)",
    subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
    x = "Outcome Group",
    y = "Variance Ratio"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
        panel.grid.minor = element_blank(),
        legend.position = "right",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 9),
        legend.key.size = unit(0.4, "cm"))

# SL_glmnet_VS (full data)
ggplot(df_new %>% filter(!is.na(precision_gain_SL_glmnet_VS)), aes(x = outcome_group, y = precision_gain_SL_glmnet_VS)) +
  geom_violin(trim = FALSE, fill = "#f7b6d3", alpha = 0.6) +
  geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_color_manual(values = size_colors, name = "Sample Size") +
  labs(
    title = "SL_glmnet_VS Precision Gain vs Unadjusted (Full Data)",
    subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
    x = "Outcome Group",
    y = "Variance Ratio"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
        panel.grid.minor = element_blank(),
        legend.position = "right",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 9),
        legend.key.size = unit(0.4, "cm"))

# SL_gam_VS (full data)
ggplot(df_new %>% filter(!is.na(precision_gain_SL_gam_VS)), aes(x = outcome_group, y = precision_gain_SL_gam_VS)) +
  geom_violin(trim = FALSE, fill = "#c7c7c7", alpha = 0.6) +
  geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_color_manual(values = size_colors, name = "Sample Size") +
  labs(
    title = "SL_gam_VS Precision Gain vs Unadjusted (Full Data)",
    subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
    x = "Outcome Group",
    y = "Variance Ratio"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
        panel.grid.minor = element_blank(),
        legend.position = "right",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 9),
        legend.key.size = unit(0.4, "cm"))

# SL_bartMachine_VS (full data)
ggplot(df_new %>% filter(!is.na(precision_gain_SL_bartMachine_VS)), aes(x = outcome_group, y = precision_gain_SL_bartMachine_VS)) +
  geom_violin(trim = FALSE, fill = "#dbdb8d", alpha = 0.6) +
  geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_color_manual(values = size_colors, name = "Sample Size") +
  labs(
    title = "SL_bartMachine_VS Precision Gain vs Unadjusted (Full Data)",
    subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
    x = "Outcome Group",
    y = "Variance Ratio"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
        panel.grid.minor = element_blank(),
        legend.position = "right",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 9),
        legend.key.size = unit(0.4, "cm"))
```

# More Plots
```{r}
###############################################################################
##  0.  Long data BEFORE trimming --------------------------------------------
###############################################################################
df_long_full = df_new %>%       # df_new in your workspace
  select(outcome_group, starts_with("precision_gain_")) %>%
  pivot_longer(cols      = starts_with("precision_gain_"),
               names_to  = "method_raw",
               values_to = "pg") %>%
  mutate(method = dplyr::case_match(
    method_raw,
    "precision_gain_ANCOVA"                  ~ "ANCOVA",
    "precision_gain_ANHECOVA"                ~ "ANHECOVA",
    "precision_gain_Binom"                   ~ "Binom",
    "precision_gain_SL"                      ~ "SL",
    "precision_gain_SL_rpart"                ~ "SL_rpart",
    "precision_gain_SL_randomForest"         ~ "SL_randomForest",
    "precision_gain_SL_glmnet"               ~ "SL_glmnet",
    "precision_gain_SL_gam"                  ~ "SL_gam",
    "precision_gain_SL_bartMachine"          ~ "SL_bartMachine",
    "precision_gain_ANCOVA_VS"               ~ "ANCOVA_VS",
    "precision_gain_ANHECOVA_VS"             ~ "ANHECOVA_VS",
    "precision_gain_Binom_VS"                ~ "Binom_VS",
    "precision_gain_SL_VS"                   ~ "SL_VS",
    "precision_gain_SL_rpart_VS"             ~ "SL_rpart_VS",
    "precision_gain_SL_randomForest_VS"      ~ "SL_randomForest_VS",
    "precision_gain_SL_glmnet_VS"            ~ "SL_glmnet_VS",
    "precision_gain_SL_gam_VS"               ~ "SL_gam_VS",
    "precision_gain_SL_bartMachine_VS"       ~ "SL_bartMachine_VS"
  ))

###############################################################################
##  1.  Caption builder for ONE outcome type and method type -----------------
###############################################################################
build_caption = function(outcome_type, is_vs = FALSE) {

  ## Filter methods based on VS or non-VS
  method_filter = if (is_vs) {
    function(methods) methods[grepl("_VS$", methods)]
  } else {
    function(methods) methods[!grepl("_VS$", methods)]
  }

  ## ---- counts of outliers (pg ≥ 2) ---------------------------
  outliers = df_long_full %>%
    filter(outcome_group == outcome_type, !is.na(pg)) %>%
    mutate(outlier = pg >= 2) %>%
    group_by(method) %>%
    summarise(outliers_removed = sum(outlier), .groups = "drop") %>%
    filter(method %in% method_filter(method))

  ## ---- counts of original NA ----------------------------
  nas = df_long_full %>%
    filter(outcome_group == outcome_type) %>%
    group_by(method) %>%
    summarise(na_removed = sum(is.na(pg)), .groups = "drop") %>%
    filter(method %in% method_filter(method))

  ## For *continuous* outcome, drop Binom + Binom_VS from NA line
  if (outcome_type == "continuous") {
    binom_methods = if (is_vs) "Binom_VS" else "Binom"
    nas = nas %>% filter(!method %in% binom_methods)
  }

  fmt = function(df, val_col)
    paste(df$method, df[[val_col]], sep = "=", collapse = ", ")

  cap1 = paste0("• Outliers removed (≥2): ", fmt(outliers, "outliers_removed"))
  cap2 = paste0("• NA removed: ",             fmt(nas,      "na_removed"))
  paste(cap1, cap2, sep = "\n")
}

###############################################################################
##  2.  Style constants -------------------------------------------------------
###############################################################################
size_colors = c("<50"     = "#E41A1C",
                "50-99"   = "#377EB8",
                "100-499" = "#4DAF4A",
                "≥500"    = "#984EA3")

make_plot = function(data, title_txt, caption_txt) {
  ggplot(data, aes(method, precision_gain)) +
    geom_violin(fill = "grey75", colour = "grey25", alpha = .30, width = 1) +
    geom_jitter(aes(colour = sample_size_cat),
                width = .12, size = .6, alpha = .65) +
    geom_hline(yintercept = 1, linetype = "dashed", colour = "grey40") +
    scale_colour_manual(values = size_colors, name = "Sample Size") +
    labs(title    = title_txt,
         subtitle = "Variance-ratio < 1 → higher precision than unadjusted",
         caption  = caption_txt,
         x = NULL, y = "Variance Ratio") +
    theme_minimal(base_size = 14) +
    theme(
      plot.title    = element_text(hjust = .5, face = "bold"),       # centred
      plot.subtitle = element_text(hjust = .5, colour = "grey60"),   # centred, light grey
      plot.caption  = element_text(hjust = 0,  colour = "grey50", size = 7), # left-aligned
      axis.text.x   = element_text(angle = 45, hjust = 1, size = 8),
      panel.grid.minor = element_blank()
    )
}

###############################################################################
##  3.  Binary plots ----------------------------------------------------------
###############################################################################
# Base methods (non-VS)
df_binary_base = df_long_outlier_removed %>% 
  filter(outcome_group == "binary", !grepl("_VS$", method))
cap_binary_base = build_caption("binary", is_vs = FALSE)

p_binary_base = make_plot(
  df_binary_base,
  "Precision Gain vs Unadjusted – Binary (Base Methods)",
  cap_binary_base
)
ggsave("cleaned_data/Plot/precision_gain_binary_base.png", p_binary_base, width = 12, height = 6, dpi = 1200)

# VS methods
df_binary_vs = df_long_outlier_removed %>% 
  filter(outcome_group == "binary", grepl("_VS$", method))
cap_binary_vs = build_caption("binary", is_vs = TRUE)

p_binary_vs = make_plot(
  df_binary_vs,
  "Precision Gain vs Unadjusted – Binary (VS Methods)",
  cap_binary_vs
)
ggsave("cleaned_data/Plot/precision_gain_binary_vs.png", p_binary_vs, width = 12, height = 6, dpi = 1200)

###############################################################################
##  4.  Continuous plots ------------------------------------------------------
###############################################################################
# Base methods (non-VS)
df_continuous_base = df_long_outlier_removed %>% 
  filter(outcome_group == "continuous", !grepl("_VS$", method))
cap_cont_base = build_caption("continuous", is_vs = FALSE)

p_cont_base = make_plot(
  df_continuous_base,
  "Precision Gain vs Unadjusted – Continuous (Base Methods)",
  cap_cont_base
)
ggsave("cleaned_data/Plot/precision_gain_continuous_base.png", p_cont_base, width = 12, height = 6, dpi = 1200)

# VS methods
df_continuous_vs = df_long_outlier_removed %>% 
  filter(outcome_group == "continuous", grepl("_VS$", method))
cap_cont_vs = build_caption("continuous", is_vs = TRUE)

p_cont_vs = make_plot(
  df_continuous_vs,
  "Precision Gain vs Unadjusted – Continuous (VS Methods)",
  cap_cont_vs
)
ggsave("cleaned_data/Plot/precision_gain_continuous_vs.png", p_cont_vs, width = 12, height = 6, dpi = 1200)

# Display plots
p_binary_base
p_binary_vs
p_cont_base
p_cont_vs
```

