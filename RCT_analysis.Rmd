---
title: "RCT_analysis"
author: "Yulin Shao"
date: "2025-06-02"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rio)
library(janitor)
library(readxl)
library(striprtf)
library(stringr)
library(tibble)
library(tidyr)
library(stringi)
library(haven)
library(purrr)
library(DescTools)
library(RobinCar)
library(ggplot2)
library(writexl)
library(kableExtra)
library(scales)
```

# Load Data

```{r}
df_comparison = read_xlsx("cleaned_data/meta_data_comparison.xlsx")
df_meta = read_xlsx("cleaned_data/meta_data.xlsx")
```

# Function

## variable_selection_correlation()
```{r}
variable_selection_correlation = function(outcome, valid_covariates, df_complete_numeric, n_select = 3) {
  if (length(valid_covariates) > n_select) {
    # Get correlations between this outcome and ALL covariates (convert factors to numeric temporarily)
    cov_values = numeric(length(valid_covariates))
    names(cov_values) = valid_covariates
    
    for (cov in valid_covariates) {
      # Convert covariate to numeric temporarily for correlation computation
      cov_numeric = as.numeric(df_complete_numeric[[cov]])
      cov_values[cov] = cor(df_complete_numeric[[outcome]], cov_numeric, use = "complete.obs")
    }
    
    # Select top n_select by absolute correlation magnitude
    top_idx = order(abs(cov_values), decreasing = TRUE)[1:n_select]
    selected_covariates = valid_covariates[top_idx]
    return(selected_covariates)
  }
  # If ≤n_select valid covariates, use all of them
  return(valid_covariates)
}
```

## variable_selection_manual()
```{r}
variable_selection_manual = function(outcome, valid_covariates, manual_covariates = NULL) {
  # Step 1: Look for baseline measures of the outcome
  baseline_var = NULL
  
  # Extract outcome pattern and timing
  if (startsWith(outcome, "YP_")) {
    # For YP outcomes: YP_abc_7w -> look for X_abc_0w
    # For YP_delta outcomes: YP_delta_abc_7w -> look for X_abc_0w (skip "delta")
    outcome_parts = strsplit(outcome, "_")[[1]]
    if (length(outcome_parts) >= 3) {
      # Check if this is a delta outcome
      if (outcome_parts[2] == "delta") {
        # For YP_delta_abc_7w, extract from position 3 onwards (excluding last part which is timing)
        if (length(outcome_parts) >= 4) {
          middle_parts = outcome_parts[3:(length(outcome_parts)-1)]
          baseline_pattern = paste0("X_", paste(middle_parts, collapse = "_"), "_0")
        }
      } else {
        # For regular YP_abc_7w, extract the middle part(s) and construct baseline variable name
        middle_parts = outcome_parts[2:(length(outcome_parts)-1)]
        baseline_pattern = paste0("X_", paste(middle_parts, collapse = "_"), "_0")
      }
      
      # Look for variables that start with this pattern (case-insensitive)
      if (exists("baseline_pattern")) {
        # Case-insensitive search using grepl
        pattern_regex = paste0("^", gsub("_", "_", baseline_pattern, fixed = TRUE))
        potential_baseline = valid_covariates[grepl(pattern_regex, valid_covariates, ignore.case = TRUE)]
        if (length(potential_baseline) > 0) {
          baseline_var = potential_baseline[1]  # Take the first match
          cat("Found baseline measure for", outcome, ":", baseline_var, "\n")
        }
      }
    }
  } else if (startsWith(outcome, "YS_")) {
    # For YS outcomes: YS_qwe_8m -> look for X_qwe_0m
    # For YS_delta outcomes: YS_delta_qwe_8m -> look for X_qwe_0m (skip "delta")
    outcome_parts = strsplit(outcome, "_")[[1]]
    if (length(outcome_parts) >= 3) {
      # Check if this is a delta outcome
      if (outcome_parts[2] == "delta") {
        # For YS_delta_qwe_8m, extract from position 3 onwards (excluding last part which is timing)
        if (length(outcome_parts) >= 4) {
          middle_parts = outcome_parts[3:(length(outcome_parts)-1)]
          baseline_pattern = paste0("X_", paste(middle_parts, collapse = "_"), "_0")
        }
      } else {
        # For regular YS_qwe_8m, extract the middle part(s) and construct baseline variable name
        middle_parts = outcome_parts[2:(length(outcome_parts)-1)]
        baseline_pattern = paste0("X_", paste(middle_parts, collapse = "_"), "_0")
      }
      
      # Look for variables that start with this pattern (case-insensitive)
      if (exists("baseline_pattern")) {
        # Case-insensitive search using grepl
        pattern_regex = paste0("^", gsub("_", "_", baseline_pattern, fixed = TRUE))
        potential_baseline = valid_covariates[grepl(pattern_regex, valid_covariates, ignore.case = TRUE)]
        if (length(potential_baseline) > 0) {
          baseline_var = potential_baseline[1]  # Take the first match
          cat("Found baseline measure for", outcome, ":", baseline_var, "\n")
        }
      }
    }
  }
  
  # Combine baseline variable with manual covariates
  selected_covariates = character(0)
  
  # Add baseline variable if foundíxs
  if (!is.null(baseline_var)) {
    selected_covariates = c(selected_covariates, baseline_var)
  }
  
  # Add manual covariates if provided
  if (!is.null(manual_covariates)) {
    # Filter manual covariates to only include those that exist in valid_covariates
    manual_available = manual_covariates[manual_covariates %in% valid_covariates]
    selected_covariates = c(selected_covariates, manual_available)
  }
  
  # Remove duplicates
  selected_covariates = unique(selected_covariates)
  
  return(selected_covariates)
}
```


## analyze_rct_sl()

```{r}
analyze_rct_sl = function(data,
                          treatment_col  = "Treatment",
                          outcome_cols,
                          covariate_cols,
                          reference_arm  = NULL,
                          K              = 5,
                          SL_methods     = c("SL.glm", "SL.mean", "SL.glmnet", "SL.rpart", "SL.randomForest", "SL.gam", "SL.bartMachine"),
                          n_cores        = parallel::detectCores() - 2) {
  require(dplyr)
  require(SuperLearner)
  require(foreach)
  require(doSNOW)
  require(doRNG)
  
  n  = nrow(data)
  
  ## ── set up inner cluster ────────────────────────────────────────────────
  cl = makeCluster(n_cores)
  registerDoSNOW(cl)
  registerDoRNG()
  on.exit(stopCluster(cl), add = TRUE)
  
  arms = levels(data[[treatment_col]])
  if (is.null(reference_arm))
    reference_arm = arms[1]
  if (!(reference_arm %in% arms))
    stop("reference_arm must be one of: ", paste(arms, collapse = ", "))
  
  pi_tab = prop.table(table(data[[treatment_col]]))
  
  ## CV splits — handle K = 1 specially
  if (K == 1) {
    splits = list(seq_len(n))
  } else {
    split_ix = sample(rep(1:K, length.out = n))
    splits   = split(seq_len(n), split_ix)
  }
  
  combos = expand.grid(
    Outcome   = outcome_cols,
    Treatment = setdiff(arms, reference_arm),
    stringsAsFactors = FALSE
  )
  
  results = foreach(
    i = seq_len(nrow(combos)),
    .combine = dplyr::bind_rows,
    .packages = c("dplyr", "SuperLearner")
  ) %dopar% {
    Y   = combos$Outcome[i]
    arm = combos$Treatment[i]
    pair_arms = c(reference_arm, arm)
    pi_pair   = pi_tab[pair_arms]
    
    ## matrix to hold EIF contributions for all n rows
    full_preds = matrix(
      NA_real_,
      nrow = n,
      ncol = 2,
      dimnames = list(NULL, pair_arms)
    )
    
    for (k in seq_along(splits)) {
      val_ix   = splits[[k]]
      train_ix = if (K == 1)
        val_ix
      else
        setdiff(seq_len(n), val_ix)
      
      for (a in pair_arms) {
        sel_tr = train_ix[data[[treatment_col]][train_ix] == a]
        
        fit = SuperLearner(
          Y          = data[[Y]][sel_tr],
          X          = data[sel_tr, covariate_cols, drop = FALSE],
          newX       = data[val_ix, covariate_cols, drop = FALSE],
          family     = gaussian(),
          cvControl  = list(V = min(10, length(sel_tr))),
          SL.library = SL_methods
        )
        
        eta_hat = fit$SL.predict
        A_k     = as.integer(data[[treatment_col]][val_ix] == a)
        full_preds[val_ix, a] =
          A_k / pi_pair[a] * (data[[Y]][val_ix] - eta_hat) + eta_hat
      }
    }
    
    D_i = full_preds[, arm] - full_preds[, reference_arm]
    tibble(
      Outcome   = Y,
      Treatment = arm,
      Control   = reference_arm,
      Est_SL    = mean(D_i),
      SE_SL     = sqrt(var(D_i) / n)
    )
  }
  
  results
}
```

## analyze_rct()

```{r}
analyze_rct = function(df,
                       selection = FALSE,
                       variable_selection_type = 1,  # 1: correlation, 2: manual
                       manual_covariates = NULL,
                       run_individual_SL = TRUE,  # Whether to run individual SL methods after ensemble
                       SL_methods = c("SL.glm", "SL.mean", "SL.glmnet", "SL.rpart", "SL.randomForest", "SL.gam", "SL.bartMachine"),
                       n_cores = parallel::detectCores() - 2,
                       seed = 123,
                       outcome_cols = NULL,
                       covariate_col = NULL,
                       treatment_col = "Treatment",
                       K = 5,
                       n_select = 3) {
  require(dplyr)
  require(RobinCar)
  require(tidyr)
  require(DescTools)
  
  # Set seed once at the beginning for reproducibility
  set.seed(seed)
  
  # Auto-detect outcome columns if not specified
  if (is.null(outcome_cols)) {
    # All YP columns
    yp_cols = names(df)[startsWith(names(df), "YP")]
    
    # Numeric and binary YS columns
    ys_cols = names(df)[startsWith(names(df), "YS")]
    ys_valid = character(0)
    for (col in ys_cols) {
      if (is.numeric(df[[col]]) ||
          (is.factor(df[[col]]) &&
           length(levels(df[[col]])) == 2)) {
        ys_valid = c(ys_valid, col)
      }
    }
    
    outcome_cols = c(yp_cols, ys_valid)
    cat(
      "Auto-detected",
      length(outcome_cols),
      "outcome columns:",
      paste(outcome_cols, collapse = ", "),
      "\n"
    )
  }
  
  # Setup covariates
  if (is.null(covariate_col)) {
    covariates = names(df)[startsWith(names(df), "X_")]
    # Add n_participants if it exists
    if ("n_participants" %in% names(df)) {
      covariates = c(covariates, "n_participants")
    }
  } else {
    covariates = covariate_col
  }
  
  # Fill missing values in covariates
  df = df %>%
    mutate(across(all_of(covariates), ~ if (is.numeric(.)) {
      replace(., is.na(.), mean(., na.rm = TRUE))
    } else if (is.factor(.)) {
      replace(., is.na(.), Mode(., na.rm = TRUE)[1])
    }))
  
  control_level = levels(df[[treatment_col]])[1]
  treat_pattern = paste0("^", treatment_col)
  
  # Process each outcome
  all_results = vector("list", length(outcome_cols))
  valid_outcomes = character(0)
  
  for (i in seq_along(outcome_cols)) {
    outcome = outcome_cols[i]
    
    # Check missing proportion for outcome
    missing_prop = mean(is.na(df[[outcome]]))
    if (missing_prop > 0.4) {
      cat(
        "REMOVED outcome:",
        outcome,
        "- Missing proportion:",
        round(missing_prop, 3),
        "(> 0.4)\n"
      )
      next
    }
    
    # Filter complete cases for this outcome
    complete_vars = c(outcome, treatment_col, covariates)
    complete_cases_idx = complete.cases(df[, complete_vars, drop = FALSE])
    df_complete = df[complete_cases_idx, , drop = FALSE]
    
    cat(
      "Outcome:",
      outcome,
      "- Sample size:",
      nrow(df_complete),
      "(",
      nrow(df) - nrow(df_complete),
      "rows removed)\n"
    )
    
    # Check for single-level factors after filtering
    if (is.factor(df_complete[[outcome]]) &&
        length(levels(droplevels(df_complete[[outcome]]))) <= 1) {
      cat("REMOVED outcome:",
          outcome,
          "- Only one level after filtering\n")
      next
    }
    
    # Check covariates for single levels and remove them
    valid_covariates = character(0)
    for (cov in covariates) {
      if (is.factor(df_complete[[cov]]) &&
          length(levels(droplevels(df_complete[[cov]]))) <= 1) {
        cat(
          "REMOVED covariate:",
          cov,
          "- Only one level after filtering (outcome:",
          outcome,
          ")\n"
        )
      } else {
        valid_covariates = c(valid_covariates, cov)
      }
    }
    
    # Determine if outcome is binary
    is_binary = is.factor(df_complete[[outcome]]) && 
                length(levels(droplevels(df_complete[[outcome]]))) == 2
    
    # For variable selection and traditional models, convert to numeric
    df_complete_numeric = df_complete
    if (is_binary) {
      # Convert binary factor/numeric to 0,1
      # Handle cases where data is already 0,1 or needs conversion from 1,2
      numeric_outcome = as.numeric(df_complete_numeric[[outcome]])
      unique_vals = sort(unique(numeric_outcome))
      
      if (all(unique_vals == c(0, 1))) {
        # Already 0,1 - keep as is
        df_complete_numeric[[outcome]] = numeric_outcome
      } else if (all(unique_vals == c(1, 2))) {
        # Convert 1,2 to 0,1
        df_complete_numeric[[outcome]] = numeric_outcome - 1
      } else {
        stop(paste("Binary outcome", outcome, "has unexpected values:", paste(unique_vals, collapse = ", "), "- expected 0,1 or 1,2"))
      }
    } else {
      df_complete_numeric[[outcome]] = as.numeric(df_complete_numeric[[outcome]])
    }
    
    # Variable selection based on type
    if (selection && length(valid_covariates) > 0) {
      if (variable_selection_type == 1) {
        # Correlation-based selection
        selected_covariates = variable_selection_correlation(outcome, valid_covariates, df_complete_numeric, n_select)
      } else if (variable_selection_type == 2) {
        # Manual + baseline selection
        selected_covariates = variable_selection_manual(outcome, valid_covariates, manual_covariates)
        
        # Check if we have any covariates to work with for manual selection
        if (length(selected_covariates) == 0) {
          cat("No valid covariates found for outcome:", outcome, "- Setting all estimates to NA\n")
          
          # Create results with NA values
          treatment_levels = levels(df_complete[[treatment_col]])[-1]  # Exclude control
          n_treat = length(treatment_levels)
          
          # Base tibble with core columns
          outcome_results = tibble(
            Outcome = rep(outcome, n_treat),
            Treatment = treatment_levels,
            Control = rep(control_level, n_treat),
            N = rep(nrow(df_complete), n_treat),
            N_Covariates = rep(0, n_treat),
            Selected_Covariates = rep("", n_treat),
            # Set all estimates and SEs to NA
            Est_UN = rep(NA_real_, n_treat),
            SE_UN = rep(NA_real_, n_treat),
            Est_AC = rep(NA_real_, n_treat),
            SE_AC = rep(NA_real_, n_treat),
            Est_RC_ANCOVA = rep(NA_real_, n_treat),
            SE_RC_ANCOVA = rep(NA_real_, n_treat),
            Est_RC_ANHECOVA = rep(NA_real_, n_treat),
            SE_RC_ANHECOVA = rep(NA_real_, n_treat),
            Est_RC_Logistic_G_Computation = rep(NA_real_, n_treat),
            SE_RC_Logistic_G_Computation = rep(NA_real_, n_treat),
            Est_SL = rep(NA_real_, n_treat),
            SE_SL = rep(NA_real_, n_treat)
          )
          
          # Add individual SL method columns based on what's in SL_methods (excluding SL.glm and SL.mean)
          individual_methods = SL_methods[!SL_methods %in% c("SL.glm", "SL.mean")]
          for (method in individual_methods) {
            method_clean = gsub("SL\\.", "SL_", method)
            outcome_results[[paste0("Est_", method_clean)]] = rep(NA_real_, n_treat)
            outcome_results[[paste0("SE_", method_clean)]] = rep(NA_real_, n_treat)
          }
          
          valid_outcomes = c(valid_outcomes, outcome)
          all_results[[length(valid_outcomes)]] = outcome_results
          next
        }
      }
      
      # Use the selected covariates
      valid_covariates = selected_covariates
      cat("Selected covariates for", outcome, ":", paste(valid_covariates, collapse = ", "), "\n")
    }
    
    # Fit traditional models (using numeric version)
    coef_unadj = coef(summary(lm(
      reformulate(treatment_col, outcome), df_complete_numeric
    )))
    coef_ancova = coef(summary(lm(
      reformulate(c(treatment_col, valid_covariates), outcome), df_complete_numeric
    )))
    
    # Extract treatment effects
    treat_idx_unadj = which(startsWith(rownames(coef_unadj), treatment_col))
    treat_idx_ancova = which(startsWith(rownames(coef_ancova), treatment_col))
    
    # Create results for this outcome
    n_treat = length(treat_idx_unadj)
    treatment_levels = sub(treat_pattern, "", rownames(coef_unadj)[treat_idx_unadj])
    
    # Calculate pairwise sample sizes (control + current treatment)
    pairwise_n = sapply(treatment_levels, function(treat_level) {
      sum(df_complete[[treatment_col]] %in% c(control_level, treat_level))
    })
    
    # Create base outcome results
    outcome_results = tibble(
      Outcome = rep(outcome, n_treat),
      Treatment = treatment_levels,
      Control = rep(control_level, n_treat),
      N = pairwise_n,
      N_Covariates = rep(length(valid_covariates), n_treat),
      # Unadjusted
      Est_UN = coef_unadj[treat_idx_unadj, 1],
      SE_UN = coef_unadj[treat_idx_unadj, 2],
      # ANCOVA
      Est_AC = coef_ancova[treat_idx_ancova, 1],
      SE_AC = coef_ancova[treat_idx_ancova, 2]
    )
    
    # Add Selected_Covariates column only if selection = TRUE
    if (selection) {
      outcome_results$Selected_Covariates = rep(paste(valid_covariates, collapse = ", "), n_treat)
    }
    
    # RobinCar - run both ANCOVA and ANHECOVA (using numeric version)
    rc_fit_ancova = suppressWarnings(
      robincar_linear(
        df_complete_numeric,
        treatment_col,
        outcome,
        covariate_cols = valid_covariates,
        adj_method = "ANCOVA",
        contrast_h = "diff"
      )
    )
    rc_result_ancova = rc_fit_ancova$contrast$result
    outcome_results$Est_RC_ANCOVA = rc_result_ancova$estimate
    outcome_results$SE_RC_ANCOVA = rc_result_ancova$se
    
    rc_fit_anhecova = suppressWarnings(
      robincar_linear(
        df_complete_numeric,
        treatment_col,
        outcome,
        covariate_cols = valid_covariates,
        adj_method = "ANHECOVA",
        contrast_h = "diff"
      )
    )
    rc_result_anhecova = rc_fit_anhecova$contrast$result
    outcome_results$Est_RC_ANHECOVA = rc_result_anhecova$estimate
    outcome_results$SE_RC_ANHECOVA = rc_result_anhecova$se
    
    # RobinCar GLM for binary outcomes
    if (is_binary) {
      # Create formula for GLM: outcome ~ Treatment + covariates
      formula_terms = c(treatment_col, valid_covariates)
      glm_formula = as.formula(paste(outcome, "~", paste(formula_terms, collapse = " + ")))
      
      rc_fit_logistic_g_computation = suppressWarnings(
        robincar_glm(
          df_complete_numeric,  # Use numeric version (0,1 for binary outcome)
          treatment_col,
          outcome,
          formula = glm_formula,
          g_family = stats::binomial,
          contrast_h = "diff"
        )
      )
      rc_result_logistic_g_computation = rc_fit_logistic_g_computation$contrast$result
      outcome_results$Est_RC_Logistic_G_Computation = rc_result_logistic_g_computation$estimate
      outcome_results$SE_RC_Logistic_G_Computation = rc_result_logistic_g_computation$se
    } else {
      # For non-binary outcomes, set Logistic G-Computation results to NA
      outcome_results$Est_RC_Logistic_G_Computation = rep(NA_real_, n_treat)
      outcome_results$SE_RC_Logistic_G_Computation = rep(NA_real_, n_treat)
    }
    
    # SuperLearner - run ensemble and individual methods (using numeric version)
    tryCatch({
      sl_res = analyze_rct_sl(
        data = df_complete_numeric,
        outcome_cols = outcome,
        covariate_cols = valid_covariates,
        treatment_col = treatment_col,
        reference_arm = control_level,
        K = K,
        SL_methods = SL_methods,
        n_cores = n_cores
      )
      outcome_results$Est_SL = sl_res$Est_SL
      outcome_results$SE_SL = sl_res$SE_SL
    }, error = function(e) {
      if (grepl("All algorithms dropped from library", e$message)) {
        outcome_results$Est_SL <<- rep(NA_real_, n_treat)
        outcome_results$SE_SL <<- rep(NA_real_, n_treat)
      } else {
        stop(e)
      }
    })
    
    # Run individual SL methods (only if run_individual_SL = TRUE)
    if (run_individual_SL) {
      individual_methods = SL_methods[!SL_methods %in% c("SL.glm", "SL.mean")]
      for (method in individual_methods) {
        tryCatch({
          sl_res_individual = analyze_rct_sl(
            data = df_complete_numeric,
            outcome_cols = outcome,
            covariate_cols = valid_covariates,
            treatment_col = treatment_col,
            reference_arm = control_level,
            K = K,
            SL_methods = method,
            n_cores = n_cores
          )
          # Clean method name for column naming
          method_clean = gsub("SL\\.", "SL_", method)
          outcome_results[[paste0("Est_", method_clean)]] = sl_res_individual$Est_SL
          outcome_results[[paste0("SE_", method_clean)]] = sl_res_individual$SE_SL
        }, error = function(e) {
          # For any error, set to NA
          method_clean = gsub("SL\\.", "SL_", method)
          outcome_results[[paste0("Est_", method_clean)]] <<- rep(NA_real_, n_treat)
          outcome_results[[paste0("SE_", method_clean)]] <<- rep(NA_real_, n_treat)
        })
      }
    }
    
    valid_outcomes = c(valid_outcomes, outcome)
    all_results[[length(valid_outcomes)]] = outcome_results
  }
  
  if (length(valid_outcomes) == 0) {
    stop("No valid outcomes remaining after data cleaning")
  }
  
  # Combine all outcomes
  final_results = bind_rows(all_results[1:length(valid_outcomes)]) %>%
    # Round for cleaner output
    mutate(across(starts_with("Est_"), ~ round(.x, 5)),
           across(starts_with("SE_"), ~ round(.x, 5))) %>%
    # Reorder columns
    select(
      Outcome,
      N,
      N_Covariates,
      Treatment,
      Control,
      Est_RC_ANCOVA,
      SE_RC_ANCOVA,
      Est_RC_ANHECOVA,
      SE_RC_ANHECOVA,
      Est_RC_Logistic_G_Computation,
      SE_RC_Logistic_G_Computation,
      Est_AC,
      SE_AC,
      Est_UN,
      SE_UN,
      Est_SL,
      SE_SL,
      everything()
    )
  
  return(final_results)
}
```

## update_df()

```{r}
update_df = function(trial_no,
                     outcome_type,
                     results,
                     suffix = "",
                     ensemble = 1,
                     contrast = "diff",
                     df = df_comparison) {

  library(dplyr)

  ## ────────────────────────────────────────────────────────────────
  ## 0) Check if all N_Covariates are 0 - if so, skip update entirely
  ## ────────────────────────────────────────────────────────────────
  if (all(results$N_Covariates == 0)) {
    cat("Skipping update for trial", trial_no, "- All outcomes have N_Covariates = 0\n")
    return(df)
  }

  ## ────────────────────────────────────────────────────────────────
  ## 1)  Outcome → Outcome-Type lookup
  ## ────────────────────────────────────────────────────────────────
  unique_outcomes = unique(results$Outcome)
  stopifnot(length(outcome_type) == length(unique_outcomes))

  outcome_type_map = tibble(
    Outcome        = unique_outcomes,
    `Outcome Type` = outcome_type
  )

  ## Dynamically detect SL members from results columns (excluding glm/mean)
  est_cols = names(results)[grepl("^Est_SL_", names(results))]
  sl_members = gsub("^Est_", "", est_cols)
  
  # Remove any glm or mean methods if they exist
  sl_members = sl_members[!grepl("^SL_glm$|^SL_mean$", sl_members, ignore.case = TRUE)]

  ## ────────────────────────────────────────────────────────────────
  ## 2)  Process results with the given suffix
  ## ────────────────────────────────────────────────────────────────
  
  # Start with core columns that we want to keep
  core_cols = c("Outcome", "Treatment", "Control")
  results_processed = results[, core_cols, drop = FALSE]
  
  # Add Selected_Covariates with suffix if it exists
  if ("Selected_Covariates" %in% names(results)) {
    if (suffix == "") {
      results_processed$Selected_Covariates = results$Selected_Covariates
    } else {
      results_processed[[paste0("Selected_Covariates_", suffix)]] = results$Selected_Covariates
    }
  }
  
  # Determine SL column names based on ensemble argument
  if (ensemble == 1) {
    sl_base_name = paste0("SL", ensemble)
  } else if (ensemble == 2) {
    sl_base_name = "DML"
  } else {
    sl_base_name = paste0("SL", ensemble)
  }
  
  if (suffix == "") {
    results_processed = results_processed %>%
      mutate(
        ANCOVA_est                         = results$Est_RC_ANCOVA,
        ANCOVA_robust_se                   = results$SE_RC_ANCOVA,
        ANHECOVA_est                       = results$Est_RC_ANHECOVA,
        ANHECOVA_robust_se                 = results$SE_RC_ANHECOVA,
        Logistic_G_Computation_est         = results$Est_RC_Logistic_G_Computation,
        Logistic_G_Computation_robust_se   = results$SE_RC_Logistic_G_Computation,
        ANCOVA_model_based_se              = results$SE_AC,
        Unadjust_est                       = results$Est_UN,
        Unadjust_se                        = results$SE_UN,
        !!paste0(sl_base_name, "_est") := results$Est_SL,
        !!paste0(sl_base_name, "_se")  := results$SE_SL
      )
  } else {
    # For suffixed version, add suffix to method names
    suffix_clean = paste0("_", suffix)
    results_processed = results_processed %>%
      mutate(
        !!paste0("ANCOVA", suffix_clean, "_est")                         := results$Est_RC_ANCOVA,
        !!paste0("ANCOVA", suffix_clean, "_robust_se")                   := results$SE_RC_ANCOVA,
        !!paste0("ANHECOVA", suffix_clean, "_est")                       := results$Est_RC_ANHECOVA,
        !!paste0("ANHECOVA", suffix_clean, "_robust_se")                 := results$SE_RC_ANHECOVA,
        !!paste0("Logistic_G_Computation", suffix_clean, "_est")         := results$Est_RC_Logistic_G_Computation,
        !!paste0("Logistic_G_Computation", suffix_clean, "_robust_se")   := results$SE_RC_Logistic_G_Computation,
        !!paste0("ANCOVA", suffix_clean, "_model_based_se")              := results$SE_AC,
        !!paste0(sl_base_name, suffix_clean, "_est")                     := results$Est_SL,
        !!paste0(sl_base_name, suffix_clean, "_se")                      := results$SE_SL,
        Unadjust_est                                                     := results$Est_UN,
        Unadjust_se                                                      := results$SE_UN
      )
  }

  ## ── Add individual SL member columns ─────────────────────────────
  for (m in sl_members) {
    old_est = paste0("Est_", m)
    old_se  = paste0("SE_",  m)
    
    if (suffix == "") {
      new_est = paste0(m, "_est")
      new_se  = paste0(m, "_se")
    } else {
      new_est = paste0(m, "_", suffix, "_est")
      new_se  = paste0(m, "_", suffix, "_se")
    }
    
    # Only add if the original columns exist in results
    if (old_est %in% names(results)) {
      results_processed[[new_est]] = results[[old_est]]
    }
    if (old_se %in% names(results)) {
      results_processed[[new_se]] = results[[old_se]]
    }
  }

  ## ── attach meta data ───────────────────────────────────────────
  results_processed = results_processed %>%
    left_join(outcome_type_map, by = "Outcome") %>%
    mutate(
      Trial_No     = trial_no,
      Sample_Size  = results$N,  # Use results$N for Sample_Size but don't keep N column
      !!ifelse(suffix == "", "N_Covariates", paste0("N_Covariates_", suffix)) := results$N_Covariates,
      Contrast     = contrast
    )

  ## ── precision gain and difference calculations ────────────────
  # Get the appropriate SL column names for calculations
  if (suffix == "") {
    sl_se_col = paste0(sl_base_name, "_se")
    sl_est_col = paste0(sl_base_name, "_est")
  } else {
    suffix_clean = paste0("_", suffix)
    sl_se_col = paste0(sl_base_name, suffix_clean, "_se")
    sl_est_col = paste0(sl_base_name, suffix_clean, "_est")
  }
  
  if (suffix == "") {
    results_processed = results_processed %>%
      mutate(
        `How much precision gain can ANCOVA provide?`                 = (ANCOVA_robust_se / Unadjust_se)^2,
        `How much precision gain can ANHECOVA provide?`               = (ANHECOVA_robust_se / Unadjust_se)^2,
        `How much precision gain can Logistic G-Computation provide?` = (Logistic_G_Computation_robust_se / Unadjust_se)^2,
        !!paste0("How much precision gain can ", sl_base_name, " provide?") := 
          (.data[[sl_se_col]] / Unadjust_se)^2,
        `ANCOVA vs ANHECOVA variance ratio`             = (ANCOVA_robust_se / ANHECOVA_robust_se)^2,
        `The ratio between robust and model-based variance estimators` =
          (ANCOVA_robust_se / ANCOVA_model_based_se)^2,
        `The difference between unadjusted and ANCOVA point estimates` =
          (ANCOVA_est - Unadjust_est) /
          sqrt((ANCOVA_robust_se^2 + Unadjust_se^2) / 2),
        `The difference between unadjusted and ANHECOVA point estimates` =
          (ANHECOVA_est - Unadjust_est) /
          sqrt((ANHECOVA_robust_se^2 + Unadjust_se^2) / 2),
        `The difference between unadjusted and Logistic G-Computation point estimates` =
          (Logistic_G_Computation_est - Unadjust_est) /
          sqrt((Logistic_G_Computation_robust_se^2 + Unadjust_se^2) / 2),
        !!paste0("The difference between unadjusted and ", sl_base_name, " point estimates") :=
          (.data[[sl_est_col]] - Unadjust_est) /
          sqrt((.data[[sl_se_col]]^2 + Unadjust_se^2) / 2)
      )
  } else {
    # For suffixed version
    suffix_clean = paste0("_", suffix)
    ancova_se_col = paste0("ANCOVA", suffix_clean, "_robust_se")
    anhecova_se_col = paste0("ANHECOVA", suffix_clean, "_robust_se")
    logistic_g_computation_se_col = paste0("Logistic_G_Computation", suffix_clean, "_robust_se")
    ancova_model_se_col = paste0("ANCOVA", suffix_clean, "_model_based_se")
    
    ancova_est_col = paste0("ANCOVA", suffix_clean, "_est")
    anhecova_est_col = paste0("ANHECOVA", suffix_clean, "_est")
    logistic_g_computation_est_col = paste0("Logistic_G_Computation", suffix_clean, "_est")
    
    results_processed = results_processed %>%
      mutate(
        !!paste0("How much precision gain can ANCOVA", suffix_clean, " provide?") := 
          (.data[[ancova_se_col]] / Unadjust_se)^2,
        !!paste0("How much precision gain can ANHECOVA", suffix_clean, " provide?") := 
          (.data[[anhecova_se_col]] / Unadjust_se)^2,
        !!paste0("How much precision gain can Logistic G-Computation", suffix_clean, " provide?") := 
          (.data[[logistic_g_computation_se_col]] / Unadjust_se)^2,
        !!paste0("How much precision gain can ", sl_base_name, suffix_clean, " provide?") := 
          (.data[[sl_se_col]] / Unadjust_se)^2,
        !!paste0("ANCOVA", suffix_clean, " vs ANHECOVA", suffix_clean, " variance ratio") := 
          (.data[[ancova_se_col]] / .data[[anhecova_se_col]])^2,
        !!paste0("The ratio between robust and model-based variance estimators", suffix_clean) := 
          (.data[[ancova_se_col]] / .data[[ancova_model_se_col]])^2,
        !!paste0("The difference between unadjusted and ANCOVA", suffix_clean, " point estimates") := 
          (.data[[ancova_est_col]] - Unadjust_est) /
          sqrt((.data[[ancova_se_col]]^2 + Unadjust_se^2) / 2),
        !!paste0("The difference between unadjusted and ANHECOVA", suffix_clean, " point estimates") := 
          (.data[[anhecova_est_col]] - Unadjust_est) /
          sqrt((.data[[anhecova_se_col]]^2 + Unadjust_se^2) / 2),
        !!paste0("The difference between unadjusted and Logistic G-Computation", suffix_clean, " point estimates") := 
          (.data[[logistic_g_computation_est_col]] - Unadjust_est) /
          sqrt((.data[[logistic_g_computation_se_col]]^2 + Unadjust_se^2) / 2),
        !!paste0("The difference between unadjusted and ", sl_base_name, suffix_clean, " point estimates") := 
          (.data[[sl_est_col]] - Unadjust_est) /
          sqrt((.data[[sl_se_col]]^2 + Unadjust_se^2) / 2)
      )
  }

  ## ── explicit SL-member precision gains & diffs ─────────────────
  for (m in sl_members) {
    if (suffix == "") {
      se_col  = paste0(m, "_se")
      est_col = paste0(m, "_est")
      pg_col  = paste0("How much precision gain can ", m, " provide?")
      df_col  = paste0("The difference between unadjusted and ", m, " point estimates")
    } else {
      suffix_clean = paste0("_", suffix)
      se_col  = paste0(m, suffix_clean, "_se")
      est_col = paste0(m, suffix_clean, "_est")
      pg_col  = paste0("How much precision gain can ", m, suffix_clean, " provide?")
      df_col  = paste0("The difference between unadjusted and ", m, suffix_clean, " point estimates")
    }
    
    if (all(c(se_col, est_col) %in% names(results_processed))) {
      results_processed = results_processed %>%
        mutate(
          !!pg_col := (.data[[se_col]] / Unadjust_se)^2,
          !!df_col := (.data[[est_col]] - Unadjust_est) /
                      sqrt((.data[[se_col]]^2 + Unadjust_se^2) / 2)
        )
    }
  }

  ## ────────────────────────────────────────────────────────────────
  ## 3)  Overwrite / append in df_comparison (with column addition support)
  ## ────────────────────────────────────────────────────────────────
  new_rows = results_processed
  
  for (i in seq_len(nrow(new_rows))) {
    row_i = new_rows[i, ]

    idx = which(
      df$Trial_No == row_i$Trial_No &
      df$Outcome   == row_i$Outcome &
      df$Treatment == row_i$Treatment &
      df$Control   == row_i$Control
    )

    if (length(idx) > 0) {
      # Update existing row - add new columns if they don't exist
      for (col_name in names(row_i)) {
        if (!col_name %in% names(df)) {
          df[[col_name]] = NA  # Add new column with NA values
        }
        df[idx[1], col_name] = row_i[[col_name]]
      }
    } else {
      # Append new row - add missing columns with NA values
      for (col_name in names(df)) {
        if (!col_name %in% names(row_i)) {
          row_i[[col_name]] = NA
        }
      }
      df = dplyr::bind_rows(df, row_i)
    }
  }

  df
}
```

# Setting
```{r}
SL2_lib = c("SL.glm", "SL.mean", "SL.rpart", "SL.gam", "SL.glmnet")
```

# Trial 1

## Load Data

```{r}
df1 = read_rds("cleaned_data/Non_Clustered_RCT/trial1.rds")
```

## Process

```{r}
type = rep("continuous", 15)
demo = c("X_Age_0m", "X_Weight_0m")
```

```{r}
# SL1
res1 = analyze_rct(df1)
df_comparison = update_df(1, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df1, T)
df_comparison = update_df(1, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df1, T, 2, demo)
df_comparison = update_df(1, type, res3, "VS2")
```


```{r}
# SL2
res1 = analyze_rct(df1, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(1, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df1, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(1, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df1, T, 2, demo, F, SL2_lib)
df_comparison = update_df(1, type, res3, "VS2", 2)
```

# Trial 2

## Load Data

```{r}
df2 = read_rds("cleaned_data/Non_Clustered_RCT/trial2.rds")

df2 = df2 %>% select(-YP_early_7d, -YP_late_12d)
```

## Process

```{r}
type = c("time to event", "binary", "binary")
demo = c("X_agegrp_0d", "X_sex_0d")
```

```{r}
# SL1
res1 = analyze_rct(df2)
df_comparison = update_df(2, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df2, T)
df_comparison = update_df(2, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df2, T, 2, demo)
df_comparison = update_df(2, type, res3, "VS2")
```


```{r}
# SL2
res1 = analyze_rct(df2, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(2, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df2, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(2, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df2, T, 2, demo, F, SL2_lib)
df_comparison = update_df(2, type, res3, "VS2", 2)
```


# Trial 3

## Load Data

```{r}
df3 = read_rds("cleaned_data/Non_Clustered_RCT/trial3.rds")
```

## Process

```{r}
type = c("binary", "time to event", rep("binary", 4), "continuous", "binary")
demo = c("X_age_0m", "X_sex_0m")
```

```{r}
# SL1
res1 = analyze_rct(df3)
df_comparison = update_df(3, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df3, T)
df_comparison = update_df(3, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df3, T, 2, demo)
df_comparison = update_df(3, type, res3, "VS2")
```


```{r}
# SL2
res1 = analyze_rct(df3, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(3, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df3, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(3, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df3, T, 2, demo, F, SL2_lib)
df_comparison = update_df(3, type, res3, "VS2", 2)
```

# Trial 4

## Load Data

```{r}
df4 = read_rds("cleaned_data/Non_Clustered_RCT/trial4.rds")
```

## Process

```{r}
type = c("continuous", "continuous", "continuous", "continuous")
demo = c("X_Sex_0w", "X_Age_0w", "X_BMI_0w")
```


```{r}
# SL1
res1 = analyze_rct(df4)
df_comparison = update_df(4, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df4, T)
df_comparison = update_df(4, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df4, T, 2, demo)
df_comparison = update_df(4, type, res3, "VS2")
```


```{r}
# SL2
res1 = analyze_rct(df4, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(4, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df4, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(4, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df4, T, 2, demo, F, SL2_lib)
df_comparison = update_df(4, type, res3, "VS2", 2)
```

# Trial 5

## Load Data

```{r}
df5 = read_rds("cleaned_data/Non_Clustered_RCT/trial5.rds")
```

## Process

```{r}
type = c("composite binary", "continuous", rep("binary", 10), rep("continuous", 3), "binary")
demo = c("X_age_0m", "X_sex_0m")
```

```{r}
# SL1
res1 = analyze_rct(df5)
df_comparison = update_df(5, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df5, T)
df_comparison = update_df(5, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df5, T, 2, demo)
df_comparison = update_df(5, type, res3, "VS2")
```


```{r}
# SL2
res1 = analyze_rct(df5, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(5, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df5, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(5, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df5, T, 2, demo, F, SL2_lib)
df_comparison = update_df(5, type, res3, "VS2", 2)
```

# Trial 6

## Load Data

```{r}
df6 = read_rds("cleaned_data/Non_Clustered_RCT/trial6.rds")
```

## Process

```{r}
n = 21
type = rep("continuous", n)
demo = c("X_age_0m", "X_sex_0m")
```

```{r}
# SL1
res1 = analyze_rct(df6)
df_comparison = update_df(6, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df6, T)
df_comparison = update_df(6, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df6, T, 2, demo)
df_comparison = update_df(6, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df6, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(6, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df6, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(6, type, res2, "VS1", 2)í

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df6, T, 2, demo, F, SL2_lib)
df_comparison = update_df(6, type, res3, "VS2", 2)
```


# Trial 7

## Load Data

```{r}
df7 = read_rds("cleaned_data/Non_Clustered_RCT/trial7.rds")
```

## Process

```{r}
type = rep("continuous", 8)
demo = c("X_Age_0h", "X_Gender_0h")
```

```{r}
# SL1
res1 = analyze_rct(df7)
df_comparison = update_df(7, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df7, T)
df_comparison = update_df(7, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df7, T, 2, demo)
df_comparison = update_df(7, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df7, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(7, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df7, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(7, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df7, T, 2, demo, F, SL2_lib)
df_comparison = update_df(7, type, res3, "VS2", 2)
```

# Trial 8

## Load Data

```{r}
df8 = read_rds("cleaned_data/Non_Clustered_RCT/trial8.rds")

df8 = df8 %>% select(-X_comorbidities_0d)
```

## Process

```{r}
type = rep("binary", 6)
demo = c("X_Age_0d", "X_Sex_0d")
```

```{r}
# SL1
res1 = analyze_rct(df8)
df_comparison = update_df(8, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df8, T)
df_comparison = update_df(8, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df8, T, 2, demo)
df_comparison = update_df(8, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df8, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(8, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df8, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(8, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df8, T, 2, demo, F, SL2_lib)
df_comparison = update_df(8, type, res3, "VS2", 2)
```

# Trial 9

## Load Data

```{r}
df9 = read_rds("cleaned_data/Non_Clustered_RCT/trial9.rds")
```

## Process

```{r}
type = c("binary", rep("continuous", 4), rep("binary", 10), "continuous", rep("binary", 2), "continuous", rep("binary", 2))
demo = c("X_age_0d")
```

```{r}
# SL1
res1 = analyze_rct(df9)
df_comparison = update_df(9, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df9, T)
df_comparison = update_df(9, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df9, T, 2, demo)
df_comparison = update_df(9, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df9, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(9, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df9, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(9, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df9, T, 2, demo, F, SL2_lib)
df_comparison = update_df(9, type, res3, "VS2", 2)
```

# Trial 10

## Load Data

```{r}
df10 = read_rds("cleaned_data/Non_Clustered_RCT/trial10.rds")
```

## Process

```{r}
type = c(rep("binary", 3), "continuous", rep("binary", 3), rep("continuous", 15))
demo = c("X_center_0d", "X_sex_0d", "X_age_0d", "X_weight_0d")
```

```{r}
# SL1
res1 = analyze_rct(df10)
df_comparison = update_df(10, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df10, T)
df_comparison = update_df(10, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df10, T, 2, demo)
df_comparison = update_df(10, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df10, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(10, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df10, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(10, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df10, T, 2, demo, F, SL2_lib)
df_comparison = update_df(10, type, res3, "VS2", 2)
```

# Trial 11

## Load Data

```{r}
df11 = read_rds("cleaned_data/Non_Clustered_RCT/trial11.rds")
```

## Process

```{r}
type = rep("continuous", 11)
demo = c("X_sex_0w")
```

```{r}
# SL1
res1 = analyze_rct(df11)
df_comparison = update_df(11, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df11, T)
df_comparison = update_df(11, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df11, T, 2, demo)
df_comparison = update_df(11, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df11, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(11, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df11, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(11, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df11, T, 2, demo, F, SL2_lib)
df_comparison = update_df(11, type, res3, "VS2", 2)
```

# Trial 12

## Load Data

```{r}
df12 = read_rds("cleaned_data/Non_Clustered_RCT/trial12.rds")
```

## Process

```{r}
type = rep("binary", 3)
demo = c("X_AuthorGender_0w")
```

```{r}
# SL1
res1 = analyze_rct(df12)
df_comparison = update_df(12, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df12, T)
df_comparison = update_df(12, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df12, T, 2, demo)
df_comparison = update_df(12, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df12, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(12, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df12, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(12, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df12, T, 2, demo, F, SL2_lib)
df_comparison = update_df(12, type, res3, "VS2", 2)
```

# Trial 13

## Load Data

```{r}
df13 = read_rds("cleaned_data/Non_Clustered_RCT/trial13.rds")
```

## Process

```{r}
type = c("continuous", "binary", rep("continuous", 8), "binary", "binary", rep("continuous", 5))
demo = c("X_AGE_0min")
```

```{r}
# SL1
res1 = analyze_rct(df13)
df_comparison = update_df(13, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df13, T)
df_comparison = update_df(13, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df13, T, 2, demo)
df_comparison = update_df(13, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df13, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(13, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df13, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(13, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df13, T, 2, demo, F, SL2_lib)
df_comparison = update_df(13, type, res3, "VS2", 2)
```

# Trial 14

## Load Data

```{r}
df14 = read_rds("cleaned_data/Non_Clustered_RCT/trial14.rds")
```

## Process

```{r}
n = 23
type = c(rep("continuous", n-5), rep("binary", 5))
demo = c("X_center_0w", "X_sex_0w", "X_age_0w")
```

```{r}
# SL1
res1 = analyze_rct(df14)
df_comparison = update_df(14, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df14, T)
df_comparison = update_df(14, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df14, T, 2, demo)
df_comparison = update_df(14, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df14, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(14, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df14, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(14, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df14, T, 2, demo, F, SL2_lib)
df_comparison = update_df(14, type, res3, "VS2", 2)
```

# Trial 15

## Load Data

```{r}
df15 = read_rds("cleaned_data/Non_Clustered_RCT/trial15.rds")
```

## Process

```{r}
type = rep("continuous", 14)
demo = c()
```

```{r}
# SL1
res1 = analyze_rct(df15)
df_comparison = update_df(15, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df15, T)
df_comparison = update_df(15, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df15, T, 2, demo)
df_comparison = update_df(15, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df15, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(15, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df15, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(15, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df15, T, 2, demo, F, SL2_lib)
df_comparison = update_df(15, type, res3, "VS2", 2)
```

# Trial 16

## Load Data

```{r}
df16 = read_rds("cleaned_data/Non_Clustered_RCT/trial16.rds")
```

## Process

```{r}
type = rep("continuous", 5)
demo = c("X_age_0w", "X_sex_0w")
```

```{r}
# SL1
res1 = analyze_rct(df16)
df_comparison = update_df(16, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df16, T)
df_comparison = update_df(16, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df16, T, 2, demo)
df_comparison = update_df(16, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df16, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(16, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df16, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(16, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df16, T, 2, demo, F, SL2_lib)
df_comparison = update_df(16, type, res3, "VS2", 2)
```

# Trial 17

## Load Data

```{r}
df17 = read_rds("cleaned_data/Non_Clustered_RCT/trial17.rds")
```

## Process

```{r}
type = rep("continuous", 4)
demo = c("X_age_0w", "X_sex_0w", "X_BMI_0w")
```

```{r}
# SL1
res1 = analyze_rct(df17)
df_comparison = update_df(17, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df17, T)
df_comparison = update_df(17, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df17, T, 2, demo)
df_comparison = update_df(17, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df17, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(17, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df17, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(17, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df17, T, 2, demo, F, SL2_lib)
df_comparison = update_df(17, type, res3, "VS2", 2)
```

# Trial 18

## Load Data

```{r}
df18 = read_rds("cleaned_data/Non_Clustered_RCT/trial18.rds") %>% 
  select(-YP_event_disengaged_12m)
```

## Process

```{r}
n = 12
type = c("time to event", rep("continuous", n-1))
demo = c("X_AgeCat_0m", "X_Gender_0m")
```

```{r}
# SL1
res1 = analyze_rct(df18)
df_comparison = update_df(18, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df18, T)
df_comparison = update_df(18, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df18, T, 2, demo)
df_comparison = update_df(18, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df18, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(18, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df18, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(18, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df18, T, 2, demo, F, SL2_lib)
df_comparison = update_df(18, type, res3, "VS2", 2)
```

# Trial 19

## Load Data

```{r}
df19 = read_rds("cleaned_data/Non_Clustered_RCT/trial19.rds")
```

## Process

```{r}
n = 11
type = c(rep("continuous", n-1), "binary")
demo = c("X_RECIPIENT_AGE_YEARS_0d", "X_RECIPIENT_GENDER_0d")
```

```{r}
# SL1
res1 = analyze_rct(df19)
df_comparison = update_df(19, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df19, T)
df_comparison = update_df(19, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df19, T, 2, demo)
df_comparison = update_df(19, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df19, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(19, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df19, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(19, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df19, T, 2, demo, F, SL2_lib)
df_comparison = update_df(19, type, res3, "VS2", 2)
```

# Trial 20

## Load Data

```{r}
df20 = read_rds("cleaned_data/Non_Clustered_RCT/trial20.rds")
```

## Process

```{r}
type = rep("continuous", 10)
demo = c("X_Age_0w", "X_Sex_0w", "X_Weight_0w")
```

```{r}
# SL1
res1 = analyze_rct(df20)
df_comparison = update_df(20, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df20, T)
df_comparison = update_df(20, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df20, T, 2, demo)
df_comparison = update_df(20, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df20, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(20, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df20, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(20, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df20, T, 2, demo, F, SL2_lib)
df_comparison = update_df(20, type, res3, "VS2", 2)
```

# Trial 21

## Load Data

```{r}
df21 = read_rds("cleaned_data/Non_Clustered_RCT/trial21.rds") %>% 
  select(-YP_tb_treatment_initiation)
```

## Process

```{r}
type = c("time to event", rep("binary", 4), "continuous")
demo = c()
```

```{r}
# SL1
res1 = analyze_rct(df21)
df_comparison = update_df(21, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df21, T)
df_comparison = update_df(21, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df21, T, 2, demo)
df_comparison = update_df(21, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df21, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(21, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df21, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(21, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df21, T, 2, demo, F, SL2_lib)
df_comparison = update_df(21, type, res3, "VS2", 2)
```

# Trial 22

## Load Data

```{r}
df22 = read_rds("cleaned_data/Non_Clustered_RCT/trial22.rds")
```

## Process

```{r}
type = c(rep("binary", 2), "continuous", rep("binary", 1), "continuous")
demo = c("X_age_0w")
```

```{r}
# SL1
res1 = analyze_rct(df22)
df_comparison = update_df(22, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df22, T)
df_comparison = update_df(22, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df22, T, 2, demo, F, SL2_lib)
df_comparison = update_df(22, type, res3, "VS2", 2)
```

# Trial 23

## Load Data

```{r}
df23 = read_rds("cleaned_data/Non_Clustered_RCT/trial23.rds") %>% 
  select(-YP_event_28d, -YP_event_90d)
```

## Process

```{r}
n = 14
type = c("time to event", "time to event", rep("continuous", n - 2))
demo = c()
```

```{r}
# SL1
res1 = analyze_rct(df23)
df_comparison = update_df(23, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df23, T)
df_comparison = update_df(23, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df23, T, 2, demo)
df_comparison = update_df(23, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df23, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(23, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df23, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(23, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df23, T, 2, demo, F, SL2_lib)
df_comparison = update_df(23, type, res3, "VS2", 2)
```

# Trial 24

## Load Data

```{r}
df24 = read_rds("cleaned_data/Non_Clustered_RCT/trial24.rds")
```

## Process

```{r}
type = c("binary", "continuous", "continuous")
demo = c("X_Age_0d", "X_Weight_0d")
```

```{r}
# SL1
res1 = analyze_rct(df24)
df_comparison = update_df(24, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df24, T)
df_comparison = update_df(24, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df24, T, 2, demo)
df_comparison = update_df(24, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df24, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(24, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df24, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(24, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df24, T, 2, demo, F, SL2_lib)
df_comparison = update_df(24, type, res3, "VS2", 2)
```

# Trial 25

## Load Data

```{r}
df25 = read_rds("cleaned_data/Non_Clustered_RCT/trial25.rds")
```

## Process

```{r}
type = c(rep("continuous", 11), "binary", rep("continuous", 5))
demo = c("X_Sex_0w", "X_BMI_0w")
```

```{r}
# SL1
res1 = analyze_rct(df25)
df_comparison = update_df(25, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df25, T)
df_comparison = update_df(25, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df25, T, 2, demo)
df_comparison = update_df(25, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df25, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(25, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df25, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(25, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df25, T, 2, demo, F, SL2_lib)
df_comparison = update_df(25, type, res3, "VS2", 2)
```

# Trial 26

## Load Data

```{r}
df26 = read_rds("cleaned_data/Non_Clustered_RCT/trial26.rds")
```

## Process

```{r}
n = 7
type = c("continuous", "binary", "categorical", rep("continuous", n-3))
demo = c("X_Agecat_0m", "X_weight_0m")
```

```{r}
# SL1
res1 = analyze_rct(df26)
df_comparison = update_df(26, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df26, T)
df_comparison = update_df(26, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df26, T, 2, demo)
df_comparison = update_df(26, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df26, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(26, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df26, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(26, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df26, T, 2, demo, F, SL2_lib)
df_comparison = update_df(26, type, res3, "VS2", 2)
```

# Trial 27

## Load Data

```{r}
df27 = read_rds("cleaned_data/Non_Clustered_RCT/trial27.rds")
```

## Process

```{r}
type = c("categorical", "binary", "continuous", "categorical", "continuous", "continuous", "binary", "continuous")
demo = c()
```

```{r}
# SL1
res1 = analyze_rct(df27)
df_comparison = update_df(27, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df27, T)
df_comparison = update_df(27, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df27, T, 2, demo)
df_comparison = update_df(27, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df27, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(27, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df27, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(27, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df27, T, 2, demo, F, SL2_lib)
df_comparison = update_df(27, type, res3, "VS2", 2)
```

# Trial 28

## Load Data

```{r}
df28 = read_rds("cleaned_data/Non_Clustered_RCT/trial28.rds")
```

## Process

```{r}
type = c("binary", rep("continuous", 7), "binary", "continuous", "binary", rep("continuous", 2))
demo = c("X_SEX_0m", "X_Age_0m", "X_BMI_0m")
```

```{r}
# SL1
res1 = analyze_rct(df28)
df_comparison = update_df(28, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df28, T)
df_comparison = update_df(28, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df28, T, 2, demo)
df_comparison = update_df(28, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df28, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(28, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df28, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(28, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df28, T, 2, demo, F, SL2_lib)
df_comparison = update_df(28, type, res3, "VS2", 2)
```

# Trial 29

## Load Data

```{r}
df29 = read_rds("cleaned_data/Non_Clustered_RCT/trial29.rds") %>% 
  select(-YP_death)
```

## Process

```{r}
type = c("time to event", "binary", "binary", "continuous")
demo = c("X_age_0w", "X_sex_0w", "X_on_art_0w")
```

```{r}
# SL1
res1 = analyze_rct(df29)
df_comparison = update_df(29, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df29, T)
df_comparison = update_df(29, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df29, T, 2, demo)
df_comparison = update_df(29, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df29, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(29, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df29, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(29, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df29, T, 2, demo, F, SL2_lib)
df_comparison = update_df(29, type, res3, "VS2", 2)
```

# Trial 30

## Load Data

```{r}
df30 = read_rds("cleaned_data/Non_Clustered_RCT/trial30.rds")
```

## Process

```{r}
type = c(rep("continuous", 6), "binary", rep("continuous", 2))
demo = c("X_Sex_0d", "X_Age_0d")
```

```{r}
# SL1
res1 = analyze_rct(df30)
df_comparison = update_df(30, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df30, T)
df_comparison = update_df(30, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df30, T, 2, demo)
df_comparison = update_df(30, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df30, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(30, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df30, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(30, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df30, T, 2, demo, F, SL2_lib)
df_comparison = update_df(30, type, res3, "VS2", 2)
```

# Trial 31

## Load Data

```{r}
df31 = read_rds("cleaned_data/Non_Clustered_RCT/trial31.rds") %>% 
  select(-YP_flu_infection)
```

## Process

```{r}
type = c("time to event", "continuous", "continuous", "binary", "binary")
demo = c("X_age_0w")
```

```{r}
# SL1
res1 = analyze_rct(df31)
df_comparison = update_df(31, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df31, T)
df_comparison = update_df(31, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df31, T, 2, demo)
df_comparison = update_df(31, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df31, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(31, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df31, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(31, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df31, T, 2, demo, F, SL2_lib)
df_comparison = update_df(31, type, res3, "VS2", 2)
```

# Trial 32

## Load Data

```{r}
df32 = read_rds("cleaned_data/Non_Clustered_RCT/trial32.rds")
```

## Process

```{r}
type = c(rep("continuous", 4), "binary", "continuous", rep("binary", 3))
demo = c("X_sex_0m", "X_age_0m")
```

```{r}
# SL1
res1 = analyze_rct(df32)
df_comparison = update_df(32, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df32, T)
df_comparison = update_df(32, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df32, T, 2, demo)
df_comparison = update_df(32, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df32, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(32, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df32, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(32, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df32, T, 2, demo, F, SL2_lib)
df_comparison = update_df(32, type, res3, "VS2", 2)
```

# Trial 33

## Load Data

```{r}
df33 = read_rds("cleaned_data/Non_Clustered_RCT/trial33.rds")
```

## Process

```{r}
type = c("continuous", "binary")
demo = c("X_age_0w", "X_Gender_0w", "X_DiseaseGroup_0w")
```

```{r}
# SL1
res1 = analyze_rct(df33)
df_comparison = update_df(33, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df33, T)
df_comparison = update_df(33, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df33, T, 2, demo)
df_comparison = update_df(33, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df33, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(33, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df33, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(33, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df33, T, 2, demo, F, SL2_lib)
df_comparison = update_df(33, type, res3, "VS2", 2)
```

# Trial 34

## Load Data

```{r}
df34 = read_rds("cleaned_data/Non_Clustered_RCT/trial34.rds")
```

## Process

```{r}
type = c("binary", "continuous", rep("binary", 6))
demo = c("X_wt_0d", "X_sex_0d")
```

```{r}
# SL1
res1 = analyze_rct(df34)
df_comparison = update_df(34, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df34, T)
df_comparison = update_df(34, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df34, T, 2, demo)
df_comparison = update_df(34, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df34, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(34, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df34, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(34, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df34, T, 2, demo, F, SL2_lib)
df_comparison = update_df(34, type, res3, "VS2", 2)
```

# Trial 35

## Load Data

```{r}
df35 = read_rds("cleaned_data/Non_Clustered_RCT/trial35.rds")
```

## Process

```{r}
type = c("continuous", "continuous", "continuous", "binary", rep("continuous", 6))
demo = c("X_BMI_0w")
```

```{r}
# SL1
res1 = analyze_rct(df35)
df_comparison = update_df(35, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df35, T)
df_comparison = update_df(35, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df35, T, 2, demo)
df_comparison = update_df(35, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df35, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(35, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df35, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(35, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df35, T, 2, demo, F, SL2_lib)
df_comparison = update_df(35, type, res3, "VS2", 2)
```

# Trial 36

## Load Data

```{r}
df36 = read_rds("cleaned_data/Non_Clustered_RCT/trial36.rds")
```

## Process

```{r}
type = rep("continuous", 11)
demo = c()
```

```{r}
# SL1
res1 = analyze_rct(df36)
df_comparison = update_df(36, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df36, T)
df_comparison = update_df(36, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df36, T, 2, demo)
df_comparison = update_df(36, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df36, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(36, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df36, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(36, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df36, T, 2, demo, F, SL2_lib)
df_comparison = update_df(36, type, res3, "VS2", 2)
```

# Trial 37

## Load Data

```{r}
df37 = read_rds("cleaned_data/Non_Clustered_RCT/trial37.rds")
```

## Process

```{r}
type = rep("binary", 1)
demo = c("X_site_0d", "X_age_0d", "X_gender_0d")
```

```{r}
# SL1
res1 = analyze_rct(df37)
df_comparison = update_df(37, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df37, T)
df_comparison = update_df(37, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df37, T, 2, demo)
df_comparison = update_df(37, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df37, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(37, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df37, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(37, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df37, T, 2, demo, F, SL2_lib)
df_comparison = update_df(37, type, res3, "VS2", 2)
```

# Trial 38

## Load Data

```{r}
df38 = read_rds("cleaned_data/Non_Clustered_RCT/trial38.rds") %>% 
  select(-YP_event_flag)
```

## Process

```{r}
type = c("time to event", "continuous", "continuous")
demo = c("X_age_0w", "X_weight_0w", "X_gender_0w")
```

```{r}
# SL1
res1 = analyze_rct(df38)
df_comparison = update_df(38, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df38, T)
df_comparison = update_df(38, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df38, T, 2, demo)
df_comparison = update_df(38, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df38, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(38, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df38, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(38, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df38, T, 2, demo, F, SL2_lib)
df_comparison = update_df(38, type, res3, "VS2", 2)
```

# Trial 39

## Load Data

```{r}
df39 = read_rds("cleaned_data/Non_Clustered_RCT/trial39.rds") %>% 
  select(-YP_event_flag)
```

## Process

```{r}
type = c("time to event")
demo = c("X_age_0w", "X_sex_0w", "X_substance_0w")
```

```{r}
# SL1
res1 = analyze_rct(df39)
df_comparison = update_df(39, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df39, T)
df_comparison = update_df(39, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df39, T, 2, demo)
df_comparison = update_df(39, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df39, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(39, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df39, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(39, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df39, T, 2, demo, F, SL2_lib)
df_comparison = update_df(39, type, res3, "VS2", 2)
```

# Trial 40

## Load Data

```{r}
df40 = read_rds("cleaned_data/Non_Clustered_RCT/trial40.rds") %>% 
  select(-YP_success_flag,  -YS_attempt1_time, -YS_attempt2_time, -YS_attempt3_time,
         -YS_attempt1_success, -YS_attempt2_success, -YS_attempt3_success, -YS_attempt2_assigned,-YS_attempt3_assigned)
```

## Process

```{r}
type = c("time to event", "continuous", "continuous", "binary", "continuous", "continuous", "binary")
demo = c("X_age_0d", "X_gender_0d", "X_BMI_0d")
```

```{r}
# SL1
res1 = analyze_rct(df40)
df_comparison = update_df(40, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df40, T)
df_comparison = update_df(40, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df40, T, 2, demo)
df_comparison = update_df(40, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df40, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(40, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df40, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(40, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df40, T, 2, demo, F, SL2_lib)
df_comparison = update_df(40, type, res3, "VS2", 2)
```

# Trial 41

## Load Data

```{r}
df41 = read_rds("cleaned_data/Non_Clustered_RCT/trial41.rds")
```

## Process

```{r}
type = rep("binary", 5)
demo = c("X_gender_0h", "X_BMI_0h", "X_age_0h")
```

```{r}
# SL1
res1 = analyze_rct(df41)
df_comparison = update_df(41, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df41, T)
df_comparison = update_df(41, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df41, T, 2, demo)
df_comparison = update_df(41, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df41, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(41, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df41, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(41, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df41, T, 2, demo, F, SL2_lib)
df_comparison = update_df(41, type, res3, "VS2", 2)
```

# Trial 42

## Load Data

```{r}
df42 = read_rds("cleaned_data/Non_Clustered_RCT/trial42.rds") %>% 
  select(-YP_onset_sensory_censor, -YS_med_duration, -YS_med_duration_censor)
```

## Process

```{r}
n = 6
type = c("time to event", rep("continuous", n-1))
demo = c("X_gender_0h", "X_bmi_0h", "X_age_0h")
```

```{r}
# SL1
res1 = analyze_rct(df42)
df_comparison = update_df(42, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df42, T)
df_comparison = update_df(42, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df42, T, 2, demo)
df_comparison = update_df(42, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df42, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(42, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df42, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(42, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df42, T, 2, demo, F, SL2_lib)
df_comparison = update_df(42, type, res3, "VS2", 2)
```

# Trial 43

## Load Data

```{r}
df43 = read_rds("cleaned_data/Non_Clustered_RCT/trial43.rds") %>% 
  select(-YP_preterm_flag)
```

## Process

```{r}
type = c("time to event", rep("continuous", 3), "binary")
demo = c("X_Age_0d", "X_BMI_0d")
```

```{r}
# SL1
res1 = analyze_rct(df43)
df_comparison = update_df(43, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df43, T)
df_comparison = update_df(43, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df43, T, 2, demo)
df_comparison = update_df(43, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df43, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(43, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df43, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(43, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df43, T, 2, demo, F, SL2_lib)
df_comparison = update_df(43, type, res3, "VS2", 2)
```

# Trial 44

## Load Data

```{r}
df44 = read_rds("cleaned_data/Non_Clustered_RCT/trial44.rds")
```

## Process

```{r}
type = c("binary", rep("continuous", 3))
demo = c("X_Age_0m", "X_Sex_0m", "X_Wt_0m")
```

```{r}
# SL1
res1 = analyze_rct(df44)
df_comparison = update_df(44, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df44, T)
df_comparison = update_df(44, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df44, T, 2, demo)
df_comparison = update_df(44, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df44, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(44, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df44, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(44, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df44, T, 2, demo, F, SL2_lib)
df_comparison = update_df(44, type, res3, "VS2", 2)
```

# Trial 45

## Load Data

```{r}
df45 = read_rds("cleaned_data/Non_Clustered_RCT/trial45.rds") %>% 
  select(-YS_delta_icedtea_24w, -YS_delta_alcohol_24w, -YS_delta_salty_24w,
         -YS_delta_fats_24w, -YS_delta_ldl_24w, -YS_delta_tg_24w, -YS_delta_hba1c_24w)
```

## Process

```{r}
type = rep("continuous", 27)
demo = c("X_weight_8w", "X_store_0w")
```

```{r}
# SL1
res1 = analyze_rct(df45)
df_comparison = update_df(45, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df45, T)
df_comparison = update_df(45, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df45, T, 2, demo)
df_comparison = update_df(45, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df45, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(45, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df45, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(45, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df45, T, 2, demo, F, SL2_lib)
df_comparison = update_df(45, type, res3, "VS2", 2)
```

# Trial 46

## Load Data

```{r}
df46 = read_rds("cleaned_data/Non_Clustered_RCT/trial46.rds")
```

## Process

```{r}
type = rep("continuous", 6)
demo = c("X_Age_0y")
```

```{r}
# SL1
res1 = analyze_rct(df46)
df_comparison = update_df(46, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df46, T)
df_comparison = update_df(46, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df46, T, 2, demo)
df_comparison = update_df(46, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df46, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(46, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df46, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(46, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df46, T, 2, demo, F, SL2_lib)
df_comparison = update_df(46, type, res3, "VS2", 2)
```

# Trial 47

## Load Data

```{r}
df47 = read_rds("cleaned_data/Non_Clustered_RCT/trial47.rds")
```

## Process

```{r}
type = c("binary", "continuous", "binary", "binary")
demo = c("X_gender_0h", "X_age_range_0h", "X_weight_range_0h")
```

```{r}
# SL1
res1 = analyze_rct(df47)
df_comparison = update_df(47, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df47, T)
df_comparison = update_df(47, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df47, T, 2, demo)
df_comparison = update_df(47, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df47, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(47, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df47, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(47, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df47, T, 2, demo, F, SL2_lib)
df_comparison = update_df(47, type, res3, "VS2", 2)
```

# Trial 48

## Load Data

```{r}
df48 = read_rds("cleaned_data/Non_Clustered_RCT/trial48.rds")
```

## Process

```{r}
type = c("binary", rep("continuous", 6), rep("binary", 2))
demo = c("X_age_group", "X_sex")
```

```{r}
# SL1
res1 = analyze_rct(df48)
df_comparison = update_df(48, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df48, T)
df_comparison = update_df(48, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df48, T, 2, demo)
df_comparison = update_df(48, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df48, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(48, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df48, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(48, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df48, T, 2, demo, F, SL2_lib)
df_comparison = update_df(48, type, res3, "VS2", 2)
```

# Trial 49

## Load Data

```{r}
df49 = read_rds("cleaned_data/Non_Clustered_RCT/trial49.rds") %>% 
  select(-YS_t_sondad, -YS_full_oral)
```

## Process

```{r}
type = c(rep("continuous", 4), rep("binary", 4), rep("continuous", 9))
demo = c("X_gestAge_0w", "X_birthWt_0d")
```

```{r}
# SL1
res1 = analyze_rct(df49)
df_comparison = update_df(49, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df49, T)
df_comparison = update_df(49, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df49, T, 2, demo)
df_comparison = update_df(49, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df49, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(49, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df49, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(49, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df49, T, 2, demo, F, SL2_lib)
df_comparison = update_df(49, type, res3, "VS2", 2)
```

# Trial 50

## Load Data

```{r}
df50 = read_rds("cleaned_data/Non_Clustered_RCT/trial50.rds") %>% 
  select(-YP_first_infection_event)
```

## Process

```{r}
type = c("time to event", "continuous")
demo = c("X_sex_0w", "X_inherit_0w", "X_age_0w", "X_weight_0w")
```

```{r}
# SL1
res1 = analyze_rct(df50)
df_comparison = update_df(50, type, res1)

# SL1, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df50, T)
df_comparison = update_df(50, type, res2, "VS1")

# SL1, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df50, T, 2, demo)
df_comparison = update_df(50, type, res3, "VS2")
```

```{r}
# SL2
res1 = analyze_rct(df50, F, 1, NULL, F, SL2_lib)
df_comparison = update_df(50, type, res1, "", 2)

# SL2, VS1
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df50, T, 1, NULL, F, SL2_lib)
df_comparison = update_df(50, type, res2, "VS1", 2)

# SL2, VS2
cat("\n<------------------Variable Seclection 2------------->\n\n")
res3 = analyze_rct(df50, T, 2, demo, F, SL2_lib)
df_comparison = update_df(50, type, res3, "VS2", 2)
```


# Export
```{r}
write_xlsx(df_comparison, "cleaned_data/meta_data_comparison.xlsx")
```


# Summary Data
```{r}
# Create outcome_group variable
df_new = df_comparison %>%
  mutate(
    outcome_group = case_when(
      `Outcome Type` %in% c("continuous", "continuous proportion") ~ "continuous",
      `Outcome Type` %in% c("ordinal", "categorical") ~ "categorical", 
      `Outcome Type` %in% c("binary", "composite binary") ~ "binary",
      `Outcome Type` == "time to event" ~ "time_to_event",
      TRUE ~ "other"
    )
  )

# Rename all precision gain and variance ratio columns
df_new = df_new %>%
  rename(
    # All (base) precision gain columns
    precision_gain_ANCOVA = `How much precision gain can ANCOVA provide?`,
    precision_gain_ANHECOVA = `How much precision gain can ANHECOVA provide?`,
    precision_gain_G_Logistic = `How much precision gain can Logistic G-Computation provide?`,
    precision_gain_SL1 = `How much precision gain can SL1 provide?`,
    precision_gain_SL_rpart = `How much precision gain can SL_rpart provide?`,
    precision_gain_SL_randomForest = `How much precision gain can SL_randomForest provide?`,
    precision_gain_SL_glmnet = `How much precision gain can SL_glmnet provide?`,
    precision_gain_SL_gam = `How much precision gain can SL_gam provide?`,
    precision_gain_SL_bartMachine = `How much precision gain can SL_bartMachine provide?`,
    precision_gain_DML = `How much precision gain can DML provide?`,
    precision_gain_TMLE = `How much precision gain can TMLE provide?`,
    
    # Top-3 (VS1) precision gain columns
    `precision_gain_ANCOVA_Top-3` = `How much precision gain can ANCOVA_VS1 provide?`,
    `precision_gain_ANHECOVA_Top-3` = `How much precision gain can ANHECOVA_VS1 provide?`,
    `precision_gain_G_Logistic_Top-3` = `How much precision gain can Logistic G-Computation_VS1 provide?`,
    `precision_gain_SL1_Top-3` = `How much precision gain can SL1_VS1 provide?`,
    `precision_gain_SL_rpart_Top-3` = `How much precision gain can SL_rpart_VS1 provide?`,
    `precision_gain_SL_randomForest_Top-3` = `How much precision gain can SL_randomForest_VS1 provide?`,
    `precision_gain_SL_glmnet_Top-3` = `How much precision gain can SL_glmnet_VS1 provide?`,
    `precision_gain_SL_gam_Top-3` = `How much precision gain can SL_gam_VS1 provide?`,
    `precision_gain_SL_bartMachine_Top-3` = `How much precision gain can SL_bartMachine_VS1 provide?`,
    `precision_gain_DML_Top-3` = `How much precision gain can DML_VS1 provide?`,
    `precision_gain_TMLE_Top-3` = `How much precision gain can TMLE_VS1 provide?`,
    
    # Baseline+ (VS2) precision gain columns
    `precision_gain_ANCOVA_Baseline+` = `How much precision gain can ANCOVA_VS2 provide?`,
    `precision_gain_ANHECOVA_Baseline+` = `How much precision gain can ANHECOVA_VS2 provide?`,
    `precision_gain_G_Logistic_Baseline+` = `How much precision gain can Logistic G-Computation_VS2 provide?`,
    `precision_gain_SL1_Baseline+` = `How much precision gain can SL1_VS2 provide?`,
    `precision_gain_SL_rpart_Baseline+` = `How much precision gain can SL_rpart_VS2 provide?`,
    `precision_gain_SL_randomForest_Baseline+` = `How much precision gain can SL_randomForest_VS2 provide?`,
    `precision_gain_SL_glmnet_Baseline+` = `How much precision gain can SL_glmnet_VS2 provide?`,
    `precision_gain_SL_gam_Baseline+` = `How much precision gain can SL_gam_VS2 provide?`,
    `precision_gain_SL_bartMachine_Baseline+` = `How much precision gain can SL_bartMachine_VS2 provide?`,
    `precision_gain_DML_Baseline+` = `How much precision gain can DML_VS2 provide?`,
    `precision_gain_TMLE_Baseline+` = `How much precision gain can TMLE_VS2 provide?`,
    
    # All (base) variance ratio columns
    variance_ratio_robust_model = `The ratio between robust and model-based variance estimators`,
    variance_ratio_ANCOVA_ANHECOVA = `ANCOVA vs ANHECOVA variance ratio`,
    
    # Top-3 (VS1) variance ratio columns  
    `variance_ratio_robust_model_Top-3` = `The ratio between robust and model-based variance estimators_VS1`,
    `variance_ratio_ANCOVA_ANHECOVA_Top-3` = `ANCOVA_VS1 vs ANHECOVA_VS1 variance ratio`,
    
    # Baseline+ (VS2) variance ratio columns
    `variance_ratio_robust_model_Baseline+` = `The ratio between robust and model-based variance estimators_VS2`,
    `variance_ratio_ANCOVA_ANHECOVA_Baseline+` = `ANCOVA_VS2 vs ANHECOVA_VS2 variance ratio`
  )
```


## Violin Plot
### Full(n)
```{r}
# Create sample size categories for better visualization
df_new = df_new %>%
  mutate(
    sample_size_cat = case_when(
      Sample_Size < 50 ~ "<50",
      Sample_Size < 100 ~ "50-99", 
      Sample_Size < 500 ~ "100-499",
      TRUE ~ "≥500"
    ),
    sample_size_cat = factor(sample_size_cat, 
                           levels = c("<50", "50-99", "100-499", "≥500")),
    # Log-transform for size mapping (less skewed)
    log_sample_size = log10(Sample_Size)
  )

# Color palette for sample size categories
size_colors = c("<50" = "#d73027", "50-99" = "#fc8d59", 
                "100-499" = "#74c476", "≥500" = "#4575b4")

# Reshape data for plotting all methods together
library(tidyr)

##################################
## Apply outlier removal for each method (except ANCOVA)
##################################

# Function to remove upper outliers
remove_upper_outliers = function(x) {
  ifelse(x >= 2, NA, x)
}

# Apply outlier removal to all methods except ANCOVA (base methods)
df_outlier_removed = df_new %>%
  mutate(
    # Base methods - no outlier removal for ANCOVA
    precision_gain_ANHECOVA = remove_upper_outliers(precision_gain_ANHECOVA),
    precision_gain_Logistic_G_Computation = remove_upper_outliers(precision_gain_Logistic_G_Computation),
    precision_gain_SL1 = remove_upper_outliers(precision_gain_SL1),
    precision_gain_SL_rpart = remove_upper_outliers(precision_gain_SL_rpart),
    precision_gain_SL_randomForest = remove_upper_outliers(precision_gain_SL_randomForest),
    precision_gain_SL_glmnet = remove_upper_outliers(precision_gain_SL_glmnet),
    precision_gain_SL_gam = remove_upper_outliers(precision_gain_SL_gam),
    precision_gain_SL_bartMachine = remove_upper_outliers(precision_gain_SL_bartMachine),
    precision_gain_DML = remove_upper_outliers(precision_gain_DML),
    precision_gain_TMLE = remove_upper_outliers(precision_gain_TMLE),
    
    # VS1 methods - no outlier removal for ANCOVA_VS1
    precision_gain_ANHECOVA_VS1 = remove_upper_outliers(precision_gain_ANHECOVA_VS1),
    precision_gain_Logistic_G_Computation_VS1 = remove_upper_outliers(precision_gain_Logistic_G_Computation_VS1),
    precision_gain_SL1_VS1 = remove_upper_outliers(precision_gain_SL1_VS1),
    precision_gain_SL_rpart_VS1 = remove_upper_outliers(precision_gain_SL_rpart_VS1),
    precision_gain_SL_randomForest_VS1 = remove_upper_outliers(precision_gain_SL_randomForest_VS1),
    precision_gain_SL_glmnet_VS1 = remove_upper_outliers(precision_gain_SL_glmnet_VS1),
    precision_gain_SL_gam_VS1 = remove_upper_outliers(precision_gain_SL_gam_VS1),
    precision_gain_SL_bartMachine_VS1 = remove_upper_outliers(precision_gain_SL_bartMachine_VS1),
    precision_gain_DML_VS1 = remove_upper_outliers(precision_gain_DML_VS1),
    precision_gain_TMLE_VS1 = remove_upper_outliers(precision_gain_TMLE_VS1),
    
    # VS2 methods - no outlier removal for ANCOVA_VS2
    precision_gain_ANHECOVA_VS2 = remove_upper_outliers(precision_gain_ANHECOVA_VS2),
    precision_gain_Logistic_G_Computation_VS2 = remove_upper_outliers(precision_gain_Logistic_G_Computation_VS2),
    precision_gain_SL1_VS2 = remove_upper_outliers(precision_gain_SL1_VS2),
    precision_gain_SL_rpart_VS2 = remove_upper_outliers(precision_gain_SL_rpart_VS2),
    precision_gain_SL_randomForest_VS2 = remove_upper_outliers(precision_gain_SL_randomForest_VS2),
    precision_gain_SL_glmnet_VS2 = remove_upper_outliers(precision_gain_SL_glmnet_VS2),  # ADDED THIS LINE
    precision_gain_SL_gam_VS2 = remove_upper_outliers(precision_gain_SL_gam_VS2),
    precision_gain_SL_bartMachine_VS2 = remove_upper_outliers(precision_gain_SL_bartMachine_VS2),
    precision_gain_DML_VS2 = remove_upper_outliers(precision_gain_DML_VS2),
    precision_gain_TMLE_VS2 = remove_upper_outliers(precision_gain_TMLE_VS2)  # ADDED THIS LINE
    # Note: precision_gain_ANCOVA, precision_gain_ANCOVA_VS1, precision_gain_ANCOVA_VS2 kept as-is (no outlier removal)
  )

# Create long format data with outlier-removed precision gain methods
df_long_outlier_removed = df_outlier_removed %>%
  select(outcome_group, sample_size_cat, 
         # Base methods
         precision_gain_ANCOVA, precision_gain_ANHECOVA, precision_gain_Logistic_G_Computation, precision_gain_SL1,
         precision_gain_SL_rpart, precision_gain_SL_randomForest, precision_gain_SL_glmnet, 
         precision_gain_SL_gam, precision_gain_SL_bartMachine, precision_gain_DML, precision_gain_TMLE,
         # VS1 methods
         precision_gain_ANCOVA_VS1, precision_gain_ANHECOVA_VS1, precision_gain_Logistic_G_Computation_VS1, precision_gain_SL1_VS1,
         precision_gain_SL_rpart_VS1, precision_gain_SL_randomForest_VS1, precision_gain_SL_glmnet_VS1,
         precision_gain_SL_gam_VS1, precision_gain_SL_bartMachine_VS1, precision_gain_DML_VS1, precision_gain_TMLE_VS1,
         # VS2 methods
         precision_gain_ANCOVA_VS2, precision_gain_ANHECOVA_VS2, precision_gain_Logistic_G_Computation_VS2, precision_gain_SL1_VS2,
         precision_gain_SL_rpart_VS2, precision_gain_SL_randomForest_VS2, precision_gain_SL_glmnet_VS2,  # ADDED THIS
         precision_gain_SL_gam_VS2, precision_gain_SL_bartMachine_VS2, precision_gain_DML_VS2, precision_gain_TMLE_VS2) %>%  # ADDED TMLE_VS2
  pivot_longer(cols = starts_with("precision_gain_"), 
               names_to = "method", 
               values_to = "precision_gain") %>%
  filter(!is.na(precision_gain)) %>%  # Remove NA values explicitly
  mutate(
    method = case_when(
      # Base methods
      method == "precision_gain_ANCOVA" ~ "ANCOVA",
      method == "precision_gain_ANHECOVA" ~ "ANHECOVA", 
      method == "precision_gain_Logistic_G_Computation" ~ "Logistic_G_Computation",
      method == "precision_gain_SL1" ~ "SL1",
      method == "precision_gain_SL_rpart" ~ "SL_rpart",
      method == "precision_gain_SL_randomForest" ~ "SL_randomForest",
      method == "precision_gain_SL_glmnet" ~ "SL_glmnet",
      method == "precision_gain_SL_gam" ~ "SL_gam",
      method == "precision_gain_SL_bartMachine" ~ "SL_bartMachine",
      method == "precision_gain_DML" ~ "DML",
      method == "precision_gain_TMLE" ~ "TMLE",
      # VS1 methods
      method == "precision_gain_ANCOVA_VS1" ~ "ANCOVA_VS1",
      method == "precision_gain_ANHECOVA_VS1" ~ "ANHECOVA_VS1",
      method == "precision_gain_Logistic_G_Computation_VS1" ~ "Logistic_G_Computation_VS1",
      method == "precision_gain_SL1_VS1" ~ "SL1_VS1",
      method == "precision_gain_SL_rpart_VS1" ~ "SL_rpart_VS1",
      method == "precision_gain_SL_randomForest_VS1" ~ "SL_randomForest_VS1",
      method == "precision_gain_SL_glmnet_VS1" ~ "SL_glmnet_VS1",
      method == "precision_gain_SL_gam_VS1" ~ "SL_gam_VS1",
      method == "precision_gain_SL_bartMachine_VS1" ~ "SL_bartMachine_VS1",
      method == "precision_gain_DML_VS1" ~ "DML_VS1",
      method == "precision_gain_TMLE_VS1" ~ "TMLE_VS1",
      # VS2 methods
      method == "precision_gain_ANCOVA_VS2" ~ "ANCOVA_VS2",
      method == "precision_gain_ANHECOVA_VS2" ~ "ANHECOVA_VS2",
      method == "precision_gain_Logistic_G_Computation_VS2" ~ "Logistic_G_Computation_VS2",
      method == "precision_gain_SL1_VS2" ~ "SL1_VS2",
      method == "precision_gain_SL_rpart_VS2" ~ "SL_rpart_VS2",
      method == "precision_gain_SL_randomForest_VS2" ~ "SL_randomForest_VS2",
      method == "precision_gain_SL_glmnet_VS2" ~ "SL_glmnet_VS2",  # ADDED THIS LINE
      method == "precision_gain_SL_gam_VS2" ~ "SL_gam_VS2",
      method == "precision_gain_SL_bartMachine_VS2" ~ "SL_bartMachine_VS2",
      method == "precision_gain_DML_VS2" ~ "DML_VS2",
      method == "precision_gain_TMLE_VS2" ~ "TMLE_VS2"  # ADDED THIS LINE
    ),
    method = factor(method, levels = c(
      # Base methods
      "ANCOVA", "ANHECOVA", "Logistic_G_Computation", "SL1", "SL_rpart", "SL_randomForest", 
      "SL_glmnet", "SL_gam", "SL_bartMachine", "DML", "TMLE",
      # VS1 methods
      "ANCOVA_VS1", "ANHECOVA_VS1", "Logistic_G_Computation_VS1", "SL1_VS1", "SL_rpart_VS1", 
      "SL_randomForest_VS1", "SL_glmnet_VS1", "SL_gam_VS1", "SL_bartMachine_VS1", "DML_VS1", "TMLE_VS1",
      # VS2 methods
      "ANCOVA_VS2", "ANHECOVA_VS2", "Logistic_G_Computation_VS2", "SL1_VS2", "SL_rpart_VS2", 
      "SL_randomForest_VS2", "SL_glmnet_VS2", "SL_gam_VS2", "SL_bartMachine_VS2", "DML_VS2", "TMLE_VS2"))  # ADDED SL_glmnet_VS2 and TMLE_VS2
  )

# Color palette for methods (expanded for VS1 and VS2)
method_colors = c(
  # Base methods
  "ANCOVA" = "#1f77b4", "ANHECOVA" = "#ff7f0e", "Logistic_G_Computation" = "#2ca02c", "SL1" = "#d62728",
  "SL_rpart" = "#9467bd", "SL_randomForest" = "#8c564b", "SL_glmnet" = "#e377c2", 
  "SL_gam" = "#7f7f7f", "SL_bartMachine" = "#bcbd22", "DML" = "#17becf", "TMLE" = "#aec7e8",
  # VS1 methods
  "ANCOVA_VS1" = "#1f77b4", "ANHECOVA_VS1" = "#ff9896", "Logistic_G_Computation_VS1" = "#98df8a", "SL1_VS1" = "#ffbb78",
  "SL_rpart_VS1" = "#c5b0d5", "SL_randomForest_VS1" = "#c49c94", "SL_glmnet_VS1" = "#f7b6d3", 
  "SL_gam_VS1" = "#c7c7c7", "SL_bartMachine_VS1" = "#dbdb8d", "DML_VS1" = "#9edae5", "TMLE_VS1" = "#393b79",
  # VS2 methods  
  "ANCOVA_VS2" = "#637939", "ANHECOVA_VS2" = "#8c6d31", "Logistic_G_Computation_VS2" = "#843c39", "SL1_VS2" = "#7b4173",
  "SL_rpart_VS2" = "#5254a3", "SL_randomForest_VS2" = "#6b6ecf", "SL_glmnet_VS2" = "#ce6dbd",  # ADDED COLOR FOR SL_glmnet_VS2
  "SL_gam_VS2" = "#9c9ede", "SL_bartMachine_VS2" = "#637939", "DML_VS2" = "#8ca252", "TMLE_VS2" = "#de9ed6"  # ADDED COLOR FOR TMLE_VS2
)

##################################
## All Methods Together (Outlier Removed) - By Outcome Type with VS Split
##################################

# Function to create plots for each outcome group and VS type
create_outcome_plot = function(outcome_type, vs_type = "none", title_suffix = "") {
  
  # Filter data based on VS type
  if (vs_type == "none") {
    data_filtered = df_long_outlier_removed %>% 
      filter(outcome_group == outcome_type, !grepl("_VS[12]$", method))
  } else if (vs_type == "VS1") {
    data_filtered = df_long_outlier_removed %>% 
      filter(outcome_group == outcome_type, grepl("_VS1$", method))
  } else if (vs_type == "VS2") {
    data_filtered = df_long_outlier_removed %>% 
      filter(outcome_group == outcome_type, grepl("_VS2$", method))
  }
  
  # Create title
  vs_label = ifelse(vs_type == "none", "Base Methods", paste0(vs_type, " Methods"))
  plot_title = paste0("Precision Gain vs Unadjusted - ", stringr::str_to_title(outcome_type), 
                     " (", vs_label, ")", title_suffix)
  
  ggplot(data_filtered, aes(x = method, y = precision_gain)) +
    geom_violin(aes(fill = method), trim = FALSE, alpha = 0.6) +
    geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
    geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
    scale_fill_manual(values = method_colors, guide = "none") +
    scale_color_manual(values = size_colors, name = "Sample Size") +
    labs(
      title = plot_title,
      subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
      x = "",
      y = "Variance Ratio"
    ) +
    theme_minimal(base_size = 14) +
    theme(plot.title = element_text(hjust = 0.5, face = "bold"),
          plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
          axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
          panel.grid.minor = element_blank(),
          legend.position = "right",
          legend.title = element_text(size = 10),
          legend.text = element_text(size = 9),
          legend.key.size = unit(0.4, "cm"))
}

# Create all 12 plots (4 outcome types × 3 VS types)
outcomes = c("binary", "continuous", "categorical", "time_to_event")
vs_types = c("none", "VS1", "VS2")

# Binary plots
p_binary_base = create_outcome_plot("binary", "none", "\n(Outlier Removed)")
p_binary_vs1 = create_outcome_plot("binary", "VS1", "\n(Outlier Removed)")
p_binary_vs2 = create_outcome_plot("binary", "VS2", "\n(Outlier Removed)")

# Continuous plots  
p_continuous_base = create_outcome_plot("continuous", "none", "\n(Outlier Removed)")
p_continuous_vs1 = create_outcome_plot("continuous", "VS1", "\n(Outlier Removed)")
p_continuous_vs2 = create_outcome_plot("continuous", "VS2", "\n(Outlier Removed)")

# Categorical plots
p_categorical_base = create_outcome_plot("categorical", "none", "\n(Outlier Removed)")
p_categorical_vs1 = create_outcome_plot("categorical", "VS1", "\n(Outlier Removed)")
p_categorical_vs2 = create_outcome_plot("categorical", "VS2", "\n(Outlier Removed)")

# Time-to-event plots
p_time_to_event_base = create_outcome_plot("time_to_event", "none", "\n(Outlier Removed)")
p_time_to_event_vs1 = create_outcome_plot("time_to_event", "VS1", "\n(Outlier Removed)")
p_time_to_event_vs2 = create_outcome_plot("time_to_event", "VS2", "\n(Outlier Removed)")

# Display all plots
p_binary_base
p_binary_vs1  
p_binary_vs2
p_continuous_base
p_continuous_vs1
p_continuous_vs2
p_categorical_base
p_categorical_vs1
p_categorical_vs2
p_time_to_event_base
p_time_to_event_vs1
p_time_to_event_vs2

##################################
## Individual Method Plots (Full Data - No Outlier Removal)
##################################

# Function to create individual method plots
create_individual_method_plot = function(method_name, color_val) {
  var_name = paste0("precision_gain_", method_name)
  
  ggplot(df_new %>% filter(!is.na(.data[[var_name]])), 
         aes(x = outcome_group, y = .data[[var_name]])) +
    geom_violin(trim = FALSE, fill = color_val, alpha = 0.6) +
    geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
    geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
    scale_color_manual(values = size_colors, name = "Sample Size") +
    labs(
      title = paste(method_name, "Precision Gain vs Unadjusted (Full Data)"),
      subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
      x = "Outcome Group",
      y = "Variance Ratio"
    ) +
    theme_minimal(base_size = 14) +
    theme(plot.title = element_text(hjust = 0.5, face = "bold"),
          plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
          panel.grid.minor = element_blank(),
          legend.position = "right",
          legend.title = element_text(size = 10),
          legend.text = element_text(size = 9),
          legend.key.size = unit(0.4, "cm"))
}

# Create individual plots for each method (example for key methods)
p_ancova_individual = create_individual_method_plot("ANCOVA", "#1f77b4")
p_anhecova_individual = create_individual_method_plot("ANHECOVA", "#ff7f0e") 
p_sl1_individual = create_individual_method_plot("SL1", "#d62728")
p_tmle_individual = create_individual_method_plot("TMLE", "#aec7e8")

# VS1 methods
p_ancova_vs1_individual = create_individual_method_plot("ANCOVA_VS1", "#1f77b4")
p_anhecova_vs1_individual = create_individual_method_plot("ANHECOVA_VS1", "#ff9896")
p_sl1_vs1_individual = create_individual_method_plot("SL1_VS1", "#ffbb78")
p_tmle_vs1_individual = create_individual_method_plot("TMLE_VS1", "#393b79")

# VS2 methods
p_ancova_vs2_individual = create_individual_method_plot("ANCOVA_VS2", "#637939")
p_anhecova_vs2_individual = create_individual_method_plot("ANHECOVA_VS2", "#8c6d31")
p_sl1_vs2_individual = create_individual_method_plot("SL1_VS2", "#7b4173")
p_sl_glmnet_vs2_individual = create_individual_method_plot("SL_glmnet_VS2", "#ce6dbd")  # ADDED THIS LINE
p_dml_vs2_individual = create_individual_method_plot("DML_VS2", "#8ca252")
p_tmle_vs2_individual = create_individual_method_plot("TMLE_VS2", "#de9ed6")  # ADDED THIS LINE

# Display individual plots
p_ancova_individual
p_anhecova_individual
p_sl1_individual
p_tmle_individual
p_ancova_vs1_individual
p_anhecova_vs1_individual
p_sl1_vs1_individual
p_tmle_vs1_individual
p_ancova_vs2_individual
p_anhecova_vs2_individual
p_sl1_vs2_individual
p_sl_glmnet_vs2_individual  # ADDED THIS LINE
p_dml_vs2_individual
p_tmle_vs2_individual  # ADDED THIS LINE
```

# Violin Plots
```{r}
###############################################################################
##  0.  Long data BEFORE trimming --------------------------------------------
###############################################################################

# First need to filter df_new to get primary and all outcomes datasets
df_new_all_outcomes = df_new  # All outcomes

# Primary outcomes only (outcomes starting with YP_)
df_new_primary = df_new %>%
  filter(str_detect(Outcome, "^YP_"))

# Function to prepare long data
prepare_long_data = function(data) {
  data %>%
    select(outcome_group, starts_with("precision_gain_")) %>%
    pivot_longer(cols      = starts_with("precision_gain_"),
                 names_to  = "method_raw",
                 values_to = "pg") %>%
    mutate(method = dplyr::case_match(
      method_raw,
      # All methods - excluding SL1 and individual SL methods
      "precision_gain_ANCOVA"                       ~ "ANCOVA",
      "precision_gain_ANHECOVA"                     ~ "ANHECOVA",
      "precision_gain_G_Logistic"                  ~ "G-Logistic",
      "precision_gain_DML"                          ~ "DML",
      "precision_gain_TMLE"                         ~ "TMLE",
      
      # Top-3 methods
      "precision_gain_ANCOVA_Top-3"                 ~ "ANCOVA Top-3",
      "precision_gain_ANHECOVA_Top-3"               ~ "ANHECOVA Top-3",
      "precision_gain_G_Logistic_Top-3"            ~ "G-Logistic Top-3",
      "precision_gain_DML_Top-3"                    ~ "DML Top-3",
      "precision_gain_TMLE_Top-3"                   ~ "TMLE Top-3",
      
      # Baseline+ methods
      "precision_gain_ANCOVA_Baseline+"             ~ "ANCOVA\nBaseline+",
      "precision_gain_ANHECOVA_Baseline+"           ~ "ANHECOVA\nBaseline+",
      "precision_gain_G_Logistic_Baseline+"        ~ "G-Logistic\nBaseline+",
      "precision_gain_DML_Baseline+"                ~ "DML\nBaseline+",
      "precision_gain_TMLE_Baseline+"               ~ "TMLE\nBaseline+"
    )) %>%
    filter(!is.na(method))  # Remove rows where method couldn't be matched
}

# Create long data for both datasets
df_long_full_all = prepare_long_data(df_new_all_outcomes)
df_long_full_primary = prepare_long_data(df_new_primary)

###############################################################################
##  1.  Table builder for ONE outcome type and method type ------------------
###############################################################################
build_and_print_table = function(outcome_type, vs_type = "All", data_type = "all") {

  # Select appropriate data source
  df_long_source = if (data_type == "primary") df_long_full_primary else df_long_full_all

  ## Filter methods based on VS type
  method_filter = function(methods) {
    if (vs_type == "All") {
      methods[!grepl("(Top-3|Baseline\\+)$", methods)]
    } else if (vs_type == "Top-3") {
      methods[grepl("Top-3$", methods)]
    } else if (vs_type == "Baseline+") {
      methods[grepl("Baseline\\+$", methods)]
    } else {
      methods
    }
  }

  ## ---- counts of outliers (pg ≥ 2) ---------------------------
  outliers = df_long_source %>%
    filter(outcome_group == outcome_type, !is.na(pg)) %>%
    mutate(outlier = pg >= 2) %>%
    group_by(method) %>%
    summarise(outliers_removed = sum(outlier), .groups = "drop") %>%
    filter(method %in% method_filter(method))

  ## ---- counts of original NA ----------------------------
  nas = df_long_source %>%
    filter(outcome_group == outcome_type) %>%
    group_by(method) %>%
    summarise(na_removed = sum(is.na(pg)), .groups = "drop") %>%
    filter(method %in% method_filter(method))

  ## For *continuous* outcome, drop G-Logistic methods from NA line
  if (outcome_type == "continuous") {
    logistic_methods = if (vs_type == "All") {
      "G-Logistic"
    } else if (vs_type == "Top-3") {
      "G-Logistic Top-3"
    } else if (vs_type == "Baseline+") {
      "G-Logistic\nBaseline+"
    }
    nas = nas %>% filter(!method %in% logistic_methods)
  }

  # Print table header
  cat("\n========================================\n")
  cat(paste0(stringr::str_to_title(outcome_type), " Outcomes - ", vs_type, 
             " (", stringr::str_to_title(data_type), " Outcomes)\n"))
  cat("========================================\n\n")
  
  cat("Outliers Removed (≥2):\n")
  print(outliers)
  
  cat("\nNA Removed:\n")
  print(nas)
  cat("\n")
}

###############################################################################
##  2.  Color palette matching smooth plots ---------------------------------
###############################################################################
# Define color palette that matches the smooth plots
method_colors = c(
  "ANCOVA" = "#F8766D",
  "ANHECOVA" = "#B79F00",
  "G-Logistic" = "#00BA38",
  "DML" = "#00BFC4",
  "TMLE" = "#619CFF",
  "ANCOVA Top-3" = "#F8766D",
  "ANHECOVA Top-3" = "#B79F00",
  "G-Logistic Top-3" = "#00BA38",
  "DML Top-3" = "#00BFC4",
  "TMLE Top-3" = "#619CFF",
  "ANCOVA\nBaseline+" = "#F8766D",
  "ANHECOVA\nBaseline+" = "#B79F00",
  "G-Logistic\nBaseline+" = "#00BA38",
  "DML\nBaseline+" = "#00BFC4",
  "TMLE\nBaseline+" = "#619CFF"
)

###############################################################################
##  3.  Plot function with colors and improved text size ---------------------
###############################################################################
make_plot = function(data, outcome_type) {
  
  # Set factor levels for binary outcomes to control order
  if (outcome_type == "binary") {
    # Define custom order: G-Logistic before DML
    method_levels = c("ANCOVA", "ANHECOVA", "G-Logistic", "DML", "TMLE",
                     "ANCOVA Top-3", "ANHECOVA Top-3", "G-Logistic Top-3", "DML Top-3", "TMLE Top-3",
                     "ANCOVA\nBaseline+", "ANHECOVA\nBaseline+", "G-Logistic\nBaseline+", "DML\nBaseline+", "TMLE\nBaseline+")
    
    data = data %>%
      mutate(method = factor(method, levels = method_levels))
  }
  
  ggplot(data, aes(method, precision_gain, fill = method)) +
    geom_violin(colour = "grey25", alpha = .50, width = 0.5) +
    geom_hline(yintercept = 1, linetype = "dashed", colour = "grey40") +
    scale_fill_manual(values = method_colors) +
    labs(x = NULL, y = "Variance Ratio") +
    coord_cartesian(ylim = c(0, 2)) +
    theme_minimal(base_size = 15) +
    theme(
      axis.text.x   = element_text(angle = 0, hjust = 0.5, size = 13),
      axis.text.y   = element_text(size = 13),
      axis.title.y  = element_text(size = 15),
      panel.grid.minor = element_blank(),
      panel.background = element_rect(fill = "white", colour = NA),
      plot.background = element_rect(fill = "white", colour = NA),
      legend.position = "none"
    )
}

###############################################################################
##  4.  Create outlier-removed datasets for all outcomes ---------------------
###############################################################################

# Function to remove outliers
remove_outliers = function(data) {
  data %>%
    mutate(precision_gain = ifelse(pg >= 2, NA, pg)) %>%
    filter(!is.na(precision_gain))
}

# Create outlier-removed datasets
df_long_outlier_removed_all = remove_outliers(df_long_full_all)
df_long_outlier_removed_primary = remove_outliers(df_long_full_primary)

###############################################################################
##  Publication quality settings ---------------------------------------------
###############################################################################
pub_width = 10
pub_height = 6
pub_dpi = 600  # 600 dpi for publication quality

###############################################################################
##  5.  Generate all plots (All outcomes) ------------------------------------
###############################################################################

# All methods - All outcomes
df_binary_all_all = df_long_outlier_removed_all %>% 
  filter(outcome_group == "binary", !grepl("(Top-3|Baseline\\+)$", method))
build_and_print_table("binary", vs_type = "All", data_type = "all")

p_binary_all_all = make_plot(df_binary_all_all, "binary")
ggsave("cleaned_data/Plot/precision_gain_binary_all_all.png", 
       p_binary_all_all, width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")

# Top-3 methods - All outcomes
df_binary_top3_all = df_long_outlier_removed_all %>% 
  filter(outcome_group == "binary", grepl("Top-3$", method))
build_and_print_table("binary", vs_type = "Top-3", data_type = "all")

p_binary_top3_all = make_plot(df_binary_top3_all, "binary")
ggsave("cleaned_data/Plot/precision_gain_binary_top3_all.png", 
       p_binary_top3_all, width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")

# Baseline+ methods - All outcomes
df_binary_baseline_all = df_long_outlier_removed_all %>% 
  filter(outcome_group == "binary", grepl("Baseline\\+$", method))
build_and_print_table("binary", vs_type = "Baseline+", data_type = "all")

p_binary_baseline_all = make_plot(df_binary_baseline_all, "binary")
ggsave("cleaned_data/Plot/precision_gain_binary_baseline_all.png", 
       p_binary_baseline_all, width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")

# Continuous plots - All outcomes
df_continuous_all_all = df_long_outlier_removed_all %>% 
  filter(outcome_group == "continuous", !grepl("(Top-3|Baseline\\+)$", method))
build_and_print_table("continuous", vs_type = "All", data_type = "all")

p_cont_all_all = make_plot(df_continuous_all_all, "continuous")
ggsave("cleaned_data/Plot/precision_gain_continuous_all_all.png", 
       p_cont_all_all, width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")

df_continuous_top3_all = df_long_outlier_removed_all %>% 
  filter(outcome_group == "continuous", grepl("Top-3$", method))
build_and_print_table("continuous", vs_type = "Top-3", data_type = "all")

p_cont_top3_all = make_plot(df_continuous_top3_all, "continuous")
ggsave("cleaned_data/Plot/precision_gain_continuous_top3_all.png", 
       p_cont_top3_all, width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")

df_continuous_baseline_all = df_long_outlier_removed_all %>% 
  filter(outcome_group == "continuous", grepl("Baseline\\+$", method))
build_and_print_table("continuous", vs_type = "Baseline+", data_type = "all")

p_cont_baseline_all = make_plot(df_continuous_baseline_all, "continuous")
ggsave("cleaned_data/Plot/precision_gain_continuous_baseline_all.png", 
       p_cont_baseline_all, width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")

###############################################################################
##  6.  Generate all plots (Primary outcomes only) --------------------------
###############################################################################

# All methods - Primary outcomes
df_binary_all_primary = df_long_outlier_removed_primary %>% 
  filter(outcome_group == "binary", !grepl("(Top-3|Baseline\\+)$", method))
build_and_print_table("binary", vs_type = "All", data_type = "primary")

p_binary_all_primary = make_plot(df_binary_all_primary, "binary")
ggsave("cleaned_data/Plot/precision_gain_binary_all_primary.png", 
       p_binary_all_primary, width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")

# Top-3 methods - Primary outcomes
df_binary_top3_primary = df_long_outlier_removed_primary %>% 
  filter(outcome_group == "binary", grepl("Top-3$", method))
build_and_print_table("binary", vs_type = "Top-3", data_type = "primary")

p_binary_top3_primary = make_plot(df_binary_top3_primary, "binary")
ggsave("cleaned_data/Plot/precision_gain_binary_top3_primary.png", 
       p_binary_top3_primary, width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")

# Baseline+ methods - Primary outcomes
df_binary_baseline_primary = df_long_outlier_removed_primary %>% 
  filter(outcome_group == "binary", grepl("Baseline\\+$", method))
build_and_print_table("binary", vs_type = "Baseline+", data_type = "primary")

p_binary_baseline_primary = make_plot(df_binary_baseline_primary, "binary")
ggsave("cleaned_data/Plot/precision_gain_binary_baseline_primary.png", 
       p_binary_baseline_primary, width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")

# Continuous plots - Primary outcomes
df_continuous_all_primary = df_long_outlier_removed_primary %>% 
  filter(outcome_group == "continuous", !grepl("(Top-3|Baseline\\+)$", method))
build_and_print_table("continuous", vs_type = "All", data_type = "primary")

p_cont_all_primary = make_plot(df_continuous_all_primary, "continuous")
ggsave("cleaned_data/Plot/precision_gain_continuous_all_primary.png", 
       p_cont_all_primary, width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")

df_continuous_top3_primary = df_long_outlier_removed_primary %>% 
  filter(outcome_group == "continuous", grepl("Top-3$", method))
build_and_print_table("continuous", vs_type = "Top-3", data_type = "primary")

p_cont_top3_primary = make_plot(df_continuous_top3_primary, "continuous")
ggsave("cleaned_data/Plot/precision_gain_continuous_top3_primary.png", 
       p_cont_top3_primary, width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")

df_continuous_baseline_primary = df_long_outlier_removed_primary %>% 
  filter(outcome_group == "continuous", grepl("Baseline\\+$", method))
build_and_print_table("continuous", vs_type = "Baseline+", data_type = "primary")

p_cont_baseline_primary = make_plot(df_continuous_baseline_primary, "continuous")
ggsave("cleaned_data/Plot/precision_gain_continuous_baseline_primary.png", 
       p_cont_baseline_primary, width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")

# Display all 12 plots
cat("\n========================================\n")
cat("All plots saved at publication quality (600 dpi, white background)\n")
cat("========================================\n\n")

cat("All Outcomes Plots:\n")
print(p_binary_all_all)
print(p_binary_top3_all)
print(p_binary_baseline_all)
print(p_cont_all_all)
print(p_cont_top3_all)
print(p_cont_baseline_all)

cat("\nPrimary Outcomes Plots:\n")
print(p_binary_all_primary)
print(p_binary_top3_primary)
print(p_binary_baseline_primary)
print(p_cont_all_primary)
print(p_cont_top3_primary)
print(p_cont_baseline_primary)
```
# N vs Var Ratio Plot
```{r}
###############################################################################
##  6.  Sample Size vs Variance Ratio Plots (3 versions) - LOESS + ALL PLOTS
###############################################################################

library(future)
library(furrr)

plan(multisession, workers = parallel::detectCores() - 1)

###############################################################################
##  Color palette for consistent colors across all plots
###############################################################################
method_colors = c(
  "ANCOVA" = "#F8766D",
  "ANHECOVA" = "#A3A500",
  "G-Logistic" = "#00BF7D",
  "DML" = "#00B0F6",
  "TMLE" = "#E76BF3",
  "ANCOVA Top-3" = "#F8766D",
  "ANHECOVA Top-3" = "#A3A500",
  "G-Logistic Top-3" = "#00BF7D",
  "DML Top-3" = "#00B0F6",
  "TMLE Top-3" = "#E76BF3",
  "ANCOVA Baseline+" = "#F8766D",
  "ANHECOVA Baseline+" = "#A3A500",
  "G-Logistic Baseline+" = "#00BF7D",
  "DML Baseline+" = "#00B0F6",
  "TMLE Baseline+" = "#E76BF3"
)

# CORRECT APPROACH: Add Sample_Size directly when creating long data
prepare_long_data_with_size = function(data) {
  data %>%
    select(outcome_group, Sample_Size, starts_with("precision_gain_")) %>%
    pivot_longer(cols = starts_with("precision_gain_"),
                 names_to = "method_raw",
                 values_to = "pg") %>%
    mutate(method = dplyr::case_match(
      method_raw,
      # All methods
      "precision_gain_ANCOVA"                       ~ "ANCOVA",
      "precision_gain_ANHECOVA"                     ~ "ANHECOVA",
      "precision_gain_G_Logistic"                  ~ "G-Logistic",
      "precision_gain_DML"                          ~ "DML",
      "precision_gain_TMLE"                         ~ "TMLE",
      
      # Top-3 methods
      "precision_gain_ANCOVA_Top-3"                 ~ "ANCOVA Top-3",
      "precision_gain_ANHECOVA_Top-3"               ~ "ANHECOVA Top-3",
      "precision_gain_G_Logistic_Top-3"            ~ "G-Logistic Top-3",
      "precision_gain_DML_Top-3"                    ~ "DML Top-3",
      "precision_gain_TMLE_Top-3"                   ~ "TMLE Top-3",
      
      # Baseline+ methods (no line break - used in legend)
      "precision_gain_ANCOVA_Baseline+"             ~ "ANCOVA Baseline+",
      "precision_gain_ANHECOVA_Baseline+"           ~ "ANHECOVA Baseline+",
      "precision_gain_G_Logistic_Baseline+"        ~ "G-Logistic Baseline+",
      "precision_gain_DML_Baseline+"                ~ "DML Baseline+",
      "precision_gain_TMLE_Baseline+"               ~ "TMLE Baseline+"
    )) %>%
    filter(!is.na(method))
}

# Create long data WITH Sample_Size
df_long_with_size_all = prepare_long_data_with_size(df_new_all_outcomes)
df_long_with_size_primary = prepare_long_data_with_size(df_new_primary)

cat("Sample size data prepared:\n")
cat("All outcomes:", nrow(df_long_with_size_all), "rows\n")
cat("Primary outcomes:", nrow(df_long_with_size_primary), "rows\n")

# Remove outliers (same as violin plots)
df_long_size_cleaned_all = df_long_with_size_all %>%
  mutate(precision_gain = ifelse(pg >= 2, NA, pg)) %>%
  filter(!is.na(precision_gain), !is.na(Sample_Size))

df_long_size_cleaned_primary = df_long_with_size_primary %>%
  mutate(precision_gain = ifelse(pg >= 2, NA, pg)) %>%
  filter(!is.na(precision_gain), !is.na(Sample_Size))

cat("After outlier removal:\n")
cat("All outcomes:", nrow(df_long_size_cleaned_all), "rows\n")
cat("Primary outcomes:", nrow(df_long_size_cleaned_primary), "rows\n")
cat("Sample size range:", min(df_long_size_cleaned_all$Sample_Size), 
    "to", max(df_long_size_cleaned_all$Sample_Size), "\n\n")

# Function for smoothed plot (log10 sample size) - USING LOESS
make_plot_smooth_log = function(data, outcome_type) {
  if (outcome_type == "binary") {
    method_levels = c("ANCOVA", "ANHECOVA", "G-Logistic", "DML", "TMLE",
                     "ANCOVA Top-3", "ANHECOVA Top-3", "G-Logistic Top-3", "DML Top-3", "TMLE Top-3",
                     "ANCOVA Baseline+", "ANHECOVA Baseline+", "G-Logistic Baseline+", "DML Baseline+", "TMLE Baseline+")
    data = data %>% mutate(method = factor(method, levels = method_levels))
  } else {
    # For continuous, exclude G-Logistic
    method_levels = c("ANCOVA", "ANHECOVA", "DML", "TMLE",
                     "ANCOVA Top-3", "ANHECOVA Top-3", "DML Top-3", "TMLE Top-3",
                     "ANCOVA Baseline+", "ANHECOVA Baseline+", "DML Baseline+", "TMLE Baseline+")
    data = data %>% mutate(method = factor(method, levels = method_levels))
  }
  
  ggplot(data, aes(x = log10(Sample_Size), y = precision_gain, color = method)) +
    geom_smooth(method = "loess", span = 0.75, se = FALSE, linewidth = 1) +
    geom_hline(yintercept = 1, linetype = "dashed", colour = "grey40") +
    scale_color_manual(values = method_colors) +
    labs(x = "Log10(Sample Size)", y = "Variance Ratio", color = "Method") +
    coord_cartesian(ylim = c(0, 2)) +
    theme_minimal(base_size = 15) +
    theme(panel.grid.minor = element_blank(),
          panel.background = element_rect(fill = "white", colour = NA),
          plot.background = element_rect(fill = "white", colour = NA),
          legend.position = "right",
          legend.text = element_text(size = 13),
          legend.title = element_text(size = 15),
          axis.text = element_text(size = 13),
          axis.title = element_text(size = 15))
}

# Function for scatter plot (original sample size)
make_plot_scatter = function(data, outcome_type) {
  if (outcome_type == "binary") {
    method_levels = c("ANCOVA", "ANHECOVA", "G-Logistic", "DML", "TMLE",
                     "ANCOVA Top-3", "ANHECOVA Top-3", "G-Logistic Top-3", "DML Top-3", "TMLE Top-3",
                     "ANCOVA Baseline+", "ANHECOVA Baseline+", "G-Logistic Baseline+", "DML Baseline+", "TMLE Baseline+")
    data = data %>% mutate(method = factor(method, levels = method_levels))
  } else {
    # For continuous, exclude G-Logistic
    method_levels = c("ANCOVA", "ANHECOVA", "DML", "TMLE",
                     "ANCOVA Top-3", "ANHECOVA Top-3", "DML Top-3", "TMLE Top-3",
                     "ANCOVA Baseline+", "ANHECOVA Baseline+", "DML Baseline+", "TMLE Baseline+")
    data = data %>% mutate(method = factor(method, levels = method_levels))
  }
  
  ggplot(data, aes(x = Sample_Size, y = precision_gain, color = method)) +
    geom_point(alpha = 0.5, size = 1) +
    geom_hline(yintercept = 1, linetype = "dashed", colour = "grey40") +
    scale_color_manual(values = method_colors) +
    labs(x = "Sample Size", y = "Variance Ratio", color = "Method") +
    coord_cartesian(ylim = c(0, 2)) +
    theme_minimal(base_size = 15) +
    theme(panel.grid.minor = element_blank(),
          panel.background = element_rect(fill = "white", colour = NA),
          plot.background = element_rect(fill = "white", colour = NA),
          legend.position = "right",
          legend.text = element_text(size = 13),
          legend.title = element_text(size = 15),
          axis.text = element_text(size = 13),
          axis.title = element_text(size = 15))
}

# Function for scatter plot (log10 sample size)
make_plot_scatter_log = function(data, outcome_type) {
  if (outcome_type == "binary") {
    method_levels = c("ANCOVA", "ANHECOVA", "G-Logistic", "DML", "TMLE",
                     "ANCOVA Top-3", "ANHECOVA Top-3", "G-Logistic Top-3", "DML Top-3", "TMLE Top-3",
                     "ANCOVA Baseline+", "ANHECOVA Baseline+", "G-Logistic Baseline+", "DML Baseline+", "TMLE Baseline+")
    data = data %>% mutate(method = factor(method, levels = method_levels))
  } else {
    # For continuous, exclude G-Logistic
    method_levels = c("ANCOVA", "ANHECOVA", "DML", "TMLE",
                     "ANCOVA Top-3", "ANHECOVA Top-3", "DML Top-3", "TMLE Top-3",
                     "ANCOVA Baseline+", "ANHECOVA Baseline+", "DML Baseline+", "TMLE Baseline+")
    data = data %>% mutate(method = factor(method, levels = method_levels))
  }
  
  ggplot(data, aes(x = log10(Sample_Size), y = precision_gain, color = method)) +
    geom_point(alpha = 0.5, size = 1) +
    geom_hline(yintercept = 1, linetype = "dashed", colour = "grey40") +
    scale_color_manual(values = method_colors) +
    labs(x = "Log10(Sample Size)", y = "Variance Ratio", color = "Method") +
    coord_cartesian(ylim = c(0, 2)) +
    theme_minimal(base_size = 15) +
    theme(panel.grid.minor = element_blank(),
          panel.background = element_rect(fill = "white", colour = NA),
          plot.background = element_rect(fill = "white", colour = NA),
          legend.position = "right",
          legend.text = element_text(size = 13),
          legend.title = element_text(size = 15),
          axis.text = element_text(size = 13),
          axis.title = element_text(size = 15))
}

# Create plot configs - only the necessary columns
plot_configs = tibble::tibble(
  data_source = rep(c(rep("all", 6), rep("primary", 6)), 3),
  outcome_type = rep(rep(c("binary", "binary", "binary", "continuous", "continuous", "continuous"), 2), 3),
  vs_type = rep(rep(c("all", "top3", "baseline", "all", "top3", "baseline"), 2), 3),
  version = c(rep("smooth_log", 12), rep("scatter", 12), rep("scatter_log", 12))
) %>%
  mutate(
    plot_name = paste0("samplesize_", outcome_type, "_", vs_type, "_", data_source, "_", version)
  )

# Function to generate single plot - matches the column names exactly
generate_single_plot = function(data_source, outcome_type, vs_type, version, plot_name) {
  
  # Select appropriate dataset
  df_long_cleaned = if (data_source == "all") df_long_size_cleaned_all else df_long_size_cleaned_primary
  
  # Filter based on outcome type and VS type
  if (vs_type == "all") {
    df_filtered = df_long_cleaned %>% 
      filter(outcome_group == outcome_type, !grepl("(Top-3|Baseline\\+)$", method))
  } else if (vs_type == "top3") {
    df_filtered = df_long_cleaned %>% 
      filter(outcome_group == outcome_type, grepl("Top-3$", method))
  } else if (vs_type == "baseline") {
    df_filtered = df_long_cleaned %>% 
      filter(outcome_group == outcome_type, grepl("Baseline\\+$", method))
  }
  
  # Check if we have data
  if (nrow(df_filtered) == 0) {
    warning(paste("No data for", plot_name))
    return(NULL)
  }
  
  # Create appropriate plot based on version
  p = if (version == "smooth_log") {
    make_plot_smooth_log(df_filtered, outcome_type)
  } else if (version == "scatter") {
    make_plot_scatter(df_filtered, outcome_type)
  } else if (version == "scatter_log") {
    make_plot_scatter_log(df_filtered, outcome_type)
  }
  
  return(list(plot_name = plot_name, plot = p))
}

cat("\n========================================\n")
cat("Generating 36 sample size plots (12 configs × 3 versions)...\n")
cat(sprintf("Using %d cores\n", parallel::detectCores() - 1))
cat("========================================\n\n")

start_time = Sys.time()

results = future_pmap(
  plot_configs,
  generate_single_plot,
  .options = furrr_options(seed = TRUE),
  .progress = TRUE
)

end_time = Sys.time()

cat("\n========================================\n")
cat("36 plots generated (not saved)\n")
cat(sprintf("Time elapsed: %.2f seconds\n", as.numeric(end_time - start_time, units = "secs")))
cat("========================================\n\n")

# Display ALL 36 plots organized by type
cat(strrep("=", 70), "\n")
cat("DISPLAYING ALL 36 PLOTS\n")
cat(strrep("=", 70), "\n\n")

# Group plots by version for better organization
for (v in c("smooth_log", "scatter", "scatter_log")) {
  version_name = case_when(
    v == "smooth_log" ~ "SMOOTHED (Log10 Scale)",
    v == "scatter" ~ "SCATTER (Original Scale)",
    v == "scatter_log" ~ "SCATTER (Log10 Scale)"
  )
  
  cat("\n", strrep("=", 70), "\n")
  cat(version_name, "\n")
  cat(strrep("=", 70), "\n\n")
  
  # Get indices for this version
  version_indices = which(plot_configs$version == v)
  
  for (idx in version_indices) {
    cat("\n--- Plot", idx, ":", plot_configs$plot_name[idx], "---\n")
    print(results[[idx]]$plot)
  }
}

cat("\n", strrep("=", 70), "\n")
cat("ALL 36 PLOTS DISPLAYED\n")
cat(strrep("=", 70), "\n")

plan(sequential)

###############################################################################
##  Publication quality settings ---------------------------------------------
###############################################################################
pub_width = 10
pub_height = 6
pub_dpi = 600
```
## smoothed log
```{r}

###############################################################################
##  Save all Version 1 plots (Smoothed Log10 Scale) with clear labels
###############################################################################
cat("\n", strrep("=", 70), "\n")
cat("SAVING VERSION 1: SMOOTHED (Log10 Scale) - ALL 12 PLOTS\n")
cat(strrep("=", 70), "\n\n")

# Get indices for smooth_log version
version1_indices = which(plot_configs$version == "smooth_log")

for (idx in version1_indices) {
  # Get plot details
  outcome = plot_configs$outcome_type[idx]
  vs = plot_configs$vs_type[idx]
  data_src = plot_configs$data_source[idx]
  
  # Create descriptive label for console output
  outcome_label = ifelse(outcome == "binary", "Binary", "Continuous")
  vs_label = case_when(
    vs == "all" ~ "All Methods",
    vs == "top3" ~ "Top-3 Methods",
    vs == "baseline" ~ "Baseline+ Methods"
  )
  data_label = ifelse(data_src == "all", "ALL OUTCOMES", "PRIMARY OUTCOMES ONLY")
  
  # Create filename
  filename = paste0("cleaned_data/Plot/", plot_configs$plot_name[idx], ".png")
  
  # Save the plot
  ggsave(filename, results[[idx]]$plot, 
         width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")
  
  cat(sprintf("✓ Saved: %s - %s [%s]\n", outcome_label, vs_label, data_label))
  cat(sprintf("  File: %s\n\n", filename))
}

cat(strrep("=", 70), "\n")
cat("ALL 12 VERSION 1 PLOTS SAVED\n")
cat(strrep("=", 70), "\n")
```
## smoothed original(outdate)
```{r}
# First, we need to create a new plotting function for smoothed original scale
make_plot_smooth_original = function(data, outcome_type) {
  if (outcome_type == "binary") {
    method_levels = c("ANCOVA", "ANHECOVA", "Logistic G-computation", "DML", "TMLE",
                     "ANCOVA_VS1", "ANHECOVA_VS1", "Logistic G-computation_VS1", "DML_VS1", "TMLE_VS1",
                     "ANCOVA_VS2", "ANHECOVA_VS2", "Logistic G-computation_VS2", "DML_VS2", "TMLE_VS2")
    data = data %>% mutate(method = factor(method, levels = method_levels))
  }
  
  ggplot(data, aes(x = Sample_Size, y = precision_gain, color = method)) +
    geom_smooth(method = "loess", span = 0.75, se = FALSE, linewidth = 1) +
    geom_hline(yintercept = 1, linetype = "dashed", colour = "grey40") +
    labs(x = "Sample Size", y = "Variance Ratio", color = "Method") +
    coord_cartesian(ylim = c(0, 2)) +
    theme_minimal(base_size = 14) +
    theme(panel.grid.minor = element_blank(),
          panel.background = element_rect(fill = "white", colour = NA),
          plot.background = element_rect(fill = "white", colour = NA),
          legend.position = "right")
}

# Generate the plots for smoothed original scale
cat("\n", strrep("=", 70), "\n")
cat("SMOOTHED (Original Sample Size Scale) - ALL 12 PLOTS\n")
cat(strrep("=", 70), "\n\n")

# Create list to store these plots
smooth_original_plots = list()

for (i in 1:12) {
  # Get configuration for this plot
  data_src = plot_configs$data_source[i]
  outcome = plot_configs$outcome_type[i]
  vs = plot_configs$vs_type[i]
  
  # Select appropriate dataset
  df_long_cleaned = if (data_src == "all") df_long_size_cleaned_all else df_long_size_cleaned_primary
  
  # Filter based on outcome type and VS type
  if (vs == "base") {
    df_filtered = df_long_cleaned %>% 
      filter(outcome_group == outcome, !grepl("_VS[12]$", method))
  } else if (vs == "vs1") {
    df_filtered = df_long_cleaned %>% 
      filter(outcome_group == outcome, grepl("_VS1$", method))
  } else if (vs == "vs2") {
    df_filtered = df_long_cleaned %>% 
      filter(outcome_group == outcome, grepl("_VS2$", method))
  }
  
  # Create plot
  p = make_plot_smooth_original(df_filtered, outcome)
  smooth_original_plots[[i]] = p
  
  # Create descriptive label
  outcome_label = ifelse(outcome == "binary", "Binary", "Continuous")
  vs_label = case_when(
    vs == "base" ~ "Base Methods",
    vs == "vs1" ~ "VS1 Methods",
    vs == "vs2" ~ "VS2 Methods"
  )
  data_label = ifelse(data_src == "all", "ALL OUTCOMES", "PRIMARY OUTCOMES ONLY")
  
  cat("\n", strrep("-", 70), "\n")
  cat(sprintf("PLOT %d: %s - %s [%s]\n", i, outcome_label, vs_label, data_label))
  cat(strrep("-", 70), "\n")
  
  print(p)
  cat("\n")
}

cat(strrep("=", 70), "\n")
cat("ALL 12 SMOOTHED (ORIGINAL SCALE) PLOTS DISPLAYED\n")
cat(strrep("=", 70), "\n")

# Save all smoothed original scale plots
cat("\n", strrep("=", 70), "\n")
cat("SAVING SMOOTHED (Original Sample Size Scale) - ALL 12 PLOTS\n")
cat(strrep("=", 70), "\n\n")

for (i in 1:12) {
  # Get configuration for this plot
  data_src = plot_configs$data_source[i]
  outcome = plot_configs$outcome_type[i]
  vs = plot_configs$vs_type[i]
  
  # Create descriptive label
  outcome_label = ifelse(outcome == "binary", "Binary", "Continuous")
  vs_label = case_when(
    vs == "base" ~ "Base Methods",
    vs == "vs1" ~ "VS1 Methods",
    vs == "vs2" ~ "VS2 Methods"
  )
  data_label = ifelse(data_src == "all", "ALL OUTCOMES", "PRIMARY OUTCOMES ONLY")
  
  # Create filename
  filename = paste0("cleaned_data/Plot/samplesize_", outcome, "_", vs, "_", data_src, "_smooth_original.png")
  
  # Save the plot
  ggsave(filename, smooth_original_plots[[i]], 
         width = pub_width, height = pub_height, dpi = pub_dpi, bg = "white")
  
  cat(sprintf("✓ Saved: %s - %s [%s]\n", outcome_label, vs_label, data_label))
  cat(sprintf("  File: %s\n", filename))
}

cat("\n", strrep("=", 70), "\n")
cat("ALL 12 SMOOTHED (ORIGINAL SCALE) PLOTS SAVED\n")
cat(strrep("=", 70), "\n")
```
# 4 Panel Plot
```{r}
library(patchwork)

###############################################################################
##  Create 4-panel combined figures
###############################################################################
# Function to create a 4-panel figure
create_4panel_figure = function(outcome_type, vs_type) {
  
  # Get violin plots (already created)
  if (outcome_type == "binary") {
    if (vs_type == "all") {
      p_violin_all = p_binary_all_all
      p_violin_primary = p_binary_all_primary
    } else if (vs_type == "top3") {
      p_violin_all = p_binary_top3_all
      p_violin_primary = p_binary_top3_primary
    } else if (vs_type == "baseline") {
      p_violin_all = p_binary_baseline_all
      p_violin_primary = p_binary_baseline_primary
    }
  } else {  # continuous
    if (vs_type == "all") {
      p_violin_all = p_cont_all_all
      p_violin_primary = p_cont_all_primary
    } else if (vs_type == "top3") {
      p_violin_all = p_cont_top3_all
      p_violin_primary = p_cont_top3_primary
    } else if (vs_type == "baseline") {
      p_violin_all = p_cont_baseline_all
      p_violin_primary = p_cont_baseline_primary
    }
  }
  
  # Get corresponding smooth log plots from results
  idx_all = which(plot_configs$outcome_type == outcome_type & 
                  plot_configs$vs_type == vs_type & 
                  plot_configs$data_source == "all" & 
                  plot_configs$version == "smooth_log")
  
  idx_primary = which(plot_configs$outcome_type == outcome_type & 
                      plot_configs$vs_type == vs_type & 
                      plot_configs$data_source == "primary" & 
                      plot_configs$version == "smooth_log")
  
  p_smooth_all = results[[idx_all]]$plot
  p_smooth_primary = results[[idx_primary]]$plot
  
  # Combine into 2x2 grid without labels
  combined = (p_violin_all | p_smooth_all) / (p_violin_primary | p_smooth_primary)
  
  return(combined)
}

###############################################################################
##  Generate and save all 6 four-panel figures
###############################################################################
cat("\n", strrep("=", 70), "\n")
cat("Creating 6 four-panel combined figures...\n")
cat(strrep("=", 70), "\n\n")

# Configuration for all 6 figures
fig_configs = tibble::tribble(
  ~outcome_type, ~vs_type,     ~fig_name,
  "binary",      "all",        "combined_binary_all",
  "binary",      "top3",       "combined_binary_top3",
  "binary",      "baseline",   "combined_binary_baseline",
  "continuous",  "all",        "combined_continuous_all",
  "continuous",  "top3",       "combined_continuous_top3",
  "continuous",  "baseline",   "combined_continuous_baseline"
)

# Adjusted width since Baseline+ labels now fit better with line breaks
combined_width = 24  # Reduced from 30 since text overlapping is solved
combined_height = 12

# Create and save each figure
for (i in 1:nrow(fig_configs)) {
  outcome = fig_configs$outcome_type[i]
  vs = fig_configs$vs_type[i]
  fig_name = fig_configs$fig_name[i]
  
  # Create descriptive label for console output
  outcome_label = ifelse(outcome == "binary", "Binary", "Continuous")
  vs_label = case_when(
    vs == "all" ~ "All Methods",
    vs == "top3" ~ "Top-3 Methods",
    vs == "baseline" ~ "Baseline+ Methods"
  )
  
  cat(sprintf("Creating figure %d/6: %s - %s...\n", i, outcome_label, vs_label))
  
  # Create the 4-panel figure
  combined_fig = create_4panel_figure(outcome, vs)
  
  # Save the figure
  filename = paste0("cleaned_data/Plot/", fig_name, ".png")
  ggsave(filename, combined_fig, 
         width = combined_width, height = combined_height, dpi = pub_dpi, bg = "white")
  
  cat(sprintf("✓ Saved: %s\n", filename))
  cat(sprintf("  Dimensions: %d × %d inches @ %d dpi\n\n", 
              combined_width, combined_height, pub_dpi))
  
  # Display the figure
  print(combined_fig)
}

cat(strrep("=", 70), "\n")
cat("ALL 6 FOUR-PANEL FIGURES CREATED AND SAVED\n")
cat(strrep("=", 70), "\n")
cat(sprintf("• Each figure: %d × %d inches @ %d dpi\n", 
            combined_width, combined_height, pub_dpi))
cat("• Layout: Violin plots (left) | Smoothed plots (right)\n")
cat("          All outcomes (top) | Primary outcomes (bottom)\n")
cat(strrep("=", 70), "\n\n")
```



# Variance Summary(outdate)
```{r}
###############################################################################
##  Summary Tables: Mean and Variance for Each Method by Outcome Type -------
##  Using OUTLIER REMOVED data
###############################################################################

library(dplyr)
library(knitr)
library(kableExtra)

# Function to create summary tables using outlier-removed data
create_summary_table = function(outcome_type, vs_type = "none") {
  
  # Filter methods based on VS type using df_long_outlier_removed
  if (vs_type == "none") {
    data_filtered = df_long_outlier_removed %>% 
      filter(outcome_group == outcome_type, !grepl("_VS[12]$", method))
  } else if (vs_type == "VS1") {
    data_filtered = df_long_outlier_removed %>% 
      filter(outcome_group == outcome_type, grepl("_VS1$", method))
  } else if (vs_type == "VS2") {
    data_filtered = df_long_outlier_removed %>% 
      filter(outcome_group == outcome_type, grepl("_VS2$", method))
  }
  
  # Calculate summary statistics (data already filtered for outliers and NAs)
  summary_stats = data_filtered %>%
    group_by(method) %>%
    summarise(
      N = n(),
      Mean = round(mean(precision_gain, na.rm = TRUE), 4),
      Variance = round(var(precision_gain, na.rm = TRUE), 4),
      SD = round(sd(precision_gain, na.rm = TRUE), 4),
      Min = round(min(precision_gain, na.rm = TRUE), 4),
      Max = round(max(precision_gain, na.rm = TRUE), 4),
      Q25 = round(quantile(precision_gain, 0.25, na.rm = TRUE), 4),
      Median = round(median(precision_gain, na.rm = TRUE), 4),
      Q75 = round(quantile(precision_gain, 0.75, na.rm = TRUE), 4),
      .groups = "drop"
    ) %>%
    arrange(method)
  
  # Create table title
  vs_label = case_when(
    vs_type == "none" ~ "Base Methods",
    vs_type == "VS1" ~ "VS1 Methods", 
    vs_type == "VS2" ~ "VS2 Methods"
  )
  
  table_title = paste0("Summary Statistics: ", stringr::str_to_title(outcome_type), 
                      " Outcomes - ", vs_label)
  
  # Return formatted table
  summary_stats %>%
    kable(caption = table_title,
          format = "html",
          align = "c") %>%
    kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"),
                  full_width = FALSE,
                  position = "center") %>%
    column_spec(1, bold = TRUE) %>%
    add_header_above(c(" " = 1, "Sample" = 1, "Central Tendency" = 3, "Spread" = 5))
}

###############################################################################
##  1. BINARY OUTCOME TABLES -------------------------------------------------
###############################################################################

# Binary - Base Methods
table_binary_base = create_summary_table("binary", "none")
print(table_binary_base)

# Binary - VS1 Methods  
table_binary_vs1 = create_summary_table("binary", "VS1")
print(table_binary_vs1)

# Binary - VS2 Methods
table_binary_vs2 = create_summary_table("binary", "VS2")
print(table_binary_vs2)

###############################################################################
##  2. CONTINUOUS OUTCOME TABLES ---------------------------------------------
###############################################################################

# Continuous - Base Methods
table_continuous_base = create_summary_table("continuous", "none")
print(table_continuous_base)

# Continuous - VS1 Methods
table_continuous_vs1 = create_summary_table("continuous", "VS1")
print(table_continuous_vs1)

# Continuous - VS2 Methods  
table_continuous_vs2 = create_summary_table("continuous", "VS2")
print(table_continuous_vs2)

###############################################################################
##  3. Simple Data Frame Tables (outlier removed) ---------------------------
###############################################################################

# Function to create simple data frame tables using outlier-removed data
create_simple_table = function(outcome_type, vs_type = "none") {
  
  # Filter methods based on VS type using df_long_outlier_removed  
  if (vs_type == "none") {
    data_filtered = df_long_outlier_removed %>% 
      filter(outcome_group == outcome_type, !grepl("_VS[12]$", method))
  } else if (vs_type == "VS1") {
    data_filtered = df_long_outlier_removed %>% 
      filter(outcome_group == outcome_type, grepl("_VS1$", method))
  } else if (vs_type == "VS2") {
    data_filtered = df_long_outlier_removed %>% 
      filter(outcome_group == outcome_type, grepl("_VS2$", method))
  }
  
  # Calculate summary statistics (data already has outliers removed and NAs filtered)
  summary_stats = data_filtered %>%
    group_by(method) %>%
    summarise(
      N = n(),
      Mean = round(mean(precision_gain, na.rm = TRUE), 4),
      Variance = round(var(precision_gain, na.rm = TRUE), 4),
      SD = round(sd(precision_gain, na.rm = TRUE), 4),
      Median = round(median(precision_gain, na.rm = TRUE), 4),
      .groups = "drop"
    ) %>%
    arrange(method)
  
  return(summary_stats)
}

# Create simple tables
cat("\n=== BINARY OUTCOMES ===\n")

cat("\n--- Binary: Base Methods ---\n")
df_binary_base_simple = create_simple_table("binary", "none")
print(df_binary_base_simple)

cat("\n--- Binary: VS1 Methods ---\n") 
df_binary_vs1_simple = create_simple_table("binary", "VS1")
print(df_binary_vs1_simple)

cat("\n--- Binary: VS2 Methods ---\n")
df_binary_vs2_simple = create_simple_table("binary", "VS2") 
print(df_binary_vs2_simple)

cat("\n=== CONTINUOUS OUTCOMES ===\n")

cat("\n--- Continuous: Base Methods ---\n")
df_continuous_base_simple = create_simple_table("continuous", "none")
print(df_continuous_base_simple)
```

# N Hist
```{r}
# Create output directory if it doesn't exist
dir.create("cleaned_data/Plot", recursive = TRUE, showWarnings = FALSE)

# Create a data frame
df = data.frame(sample_size = df_meta$'Sample Size')

# Calculate summary statistics
mean_size = mean(df$sample_size)
median_size = median(df$sample_size)
n_studies = length(df$sample_size)

###############################################################################
## Plot 1: Original Linear Scale Histogram
###############################################################################

p = ggplot(df, aes(x = sample_size)) +
  geom_histogram(bins = 30, 
                 fill = "#4CAF50", 
                 color = "white", 
                 alpha = 0.8,
                 boundary = 0) +
  geom_vline(aes(xintercept = mean_size), 
             color = "#FF5722", 
             linetype = "dashed", 
             linewidth = 1.2,
             alpha = 0.8) +
  geom_vline(aes(xintercept = median_size), 
             color = "#2196F3", 
             linetype = "dotted", 
             linewidth = 1.2,
             alpha = 0.8) +
  labs(x = "Sample Size",
       y = "Number of Studies") +
  theme_minimal(base_size = 16) +
  theme(
    axis.title = element_text(size = 18, face = "bold"),
    axis.text = element_text(size = 16),
    panel.grid.minor = element_blank(),
    panel.grid.major.x = element_blank(),
    panel.grid.major.y = element_line(color = "gray90", linewidth = 0.5),
    panel.background = element_rect(fill = "white", colour = NA),
    plot.background = element_rect(fill = "white", colour = NA)
  ) +
  scale_x_continuous(labels = scales::comma_format()) +
  scale_y_continuous(expand = c(0, 0, 0.05, 0))

print(p)
ggsave("cleaned_data/Plot/sample_size_linear.png", p, width = 10, height = 6, dpi = 600, bg = "white")

###############################################################################
## Plot 2: Custom Bins (RECOMMENDED for skewed data)
###############################################################################

# Create custom bins with wider intervals for larger values
df_binned = df %>%
  mutate(
    size_category = cut(sample_size, 
                       breaks = c(0, 50, 100, 200, 500, 1000, Inf),
                       labels = c("0-50", "51-100", "101-200", 
                                 "201-500", "501-1000", "1000+"),
                       include.lowest = TRUE)
  )

# Count by category
bin_summary = df_binned %>%
  count(size_category) %>%
  mutate(percentage = round(n/sum(n)*100, 1))

p_custom = ggplot(df_binned, aes(x = size_category)) +
  geom_bar(fill = "#4CAF50", alpha = 0.8, color = "white") +
  geom_text(stat = "count", aes(label = after_stat(count)), 
            vjust = -0.5, size = 5, fontface = "bold") +
  labs(x = "Sample Size Range",
       y = "Number of Studies") +
  theme_minimal(base_size = 16) +
  theme(
    axis.title = element_text(size = 18, face = "bold"),
    axis.text = element_text(size = 16),
    axis.text.x = element_text(angle = 0),
    panel.grid.minor = element_blank(),
    panel.grid.major.x = element_blank(),
    panel.grid.major.y = element_line(color = "gray90", linewidth = 0.5),
    panel.background = element_rect(fill = "white", colour = NA),
    plot.background = element_rect(fill = "white", colour = NA)
  ) +
  scale_y_continuous(expand = c(0, 0, 0.1, 0))

print(p_custom)
ggsave("cleaned_data/Plot/sample_size_custom_bins.png", p_custom, width = 10, height = 6, dpi = 600, bg = "white")

###############################################################################
## Plot 3: Square Root Transformation
###############################################################################

p_sqrt = ggplot(df, aes(x = sqrt(sample_size))) +
  geom_histogram(bins = 20, 
                 fill = "#FF9800", 
                 color = "white", 
                 alpha = 0.8) +
  scale_x_continuous(
    breaks = sqrt(c(0, 100, 500, 1000, 2000, 4000, 6000)),
    labels = scales::comma_format()(c(0, 100, 500, 1000, 2000, 4000, 6000))
  ) +
  labs(x = "Sample Size (√ scale)",
       y = "Number of Studies") +
  theme_minimal(base_size = 16) +
  theme(
    axis.title = element_text(size = 18, face = "bold"),
    axis.text = element_text(size = 16),
    panel.grid.minor = element_blank(),
    panel.grid.major.x = element_blank(),
    panel.grid.major.y = element_line(color = "gray90", linewidth = 0.5),
    panel.background = element_rect(fill = "white", colour = NA),
    plot.background = element_rect(fill = "white", colour = NA)
  ) +
  scale_y_continuous(expand = c(0, 0, 0.05, 0))

print(p_sqrt)
ggsave("cleaned_data/Plot/sample_size_sqrt.png", p_sqrt, width = 10, height = 6, dpi = 600, bg = "white")

###############################################################################
## Plot 4: Log-Transformed Distribution
###############################################################################

p_log = ggplot(df, aes(x = log10(sample_size))) +
  geom_histogram(bins = 25, 
                 fill = "#9C27B0", 
                 color = "white", 
                 alpha = 0.8) +
  labs(x = "Log10(Sample Size)",
       y = "Number of Studies") +
  theme_minimal(base_size = 16) +
  theme(
    axis.title = element_text(size = 18, face = "bold"),
    axis.text = element_text(size = 16),
    panel.grid.minor = element_blank(),
    panel.grid.major.x = element_blank(),
    panel.grid.major.y = element_line(color = "gray90", linewidth = 0.5),
    panel.background = element_rect(fill = "white", colour = NA),
    plot.background = element_rect(fill = "white", colour = NA)
  ) +
  scale_y_continuous(expand = c(0, 0, 0.05, 0))

print(p_log)
ggsave("cleaned_data/Plot/sample_size_log.png", p_log, width = 10, height = 6, dpi = 600, bg = "white")

###############################################################################
## Additional Analysis: Categorize Studies by Size
###############################################################################

df = df %>%
  mutate(size_category_detailed = case_when(
    sample_size < 100 ~ "Small (< 100)",
    sample_size >= 100 & sample_size < 500 ~ "Medium (100-499)",
    sample_size >= 500 & sample_size < 1000 ~ "Large (500-999)",
    sample_size >= 1000 ~ "Very Large (≥ 1000)"
  ))

# Print summary
cat("\n========================================\n")
cat("Sample Size Summary Statistics\n")
cat("========================================\n")
print(summary(df$sample_size))

cat("\n\nDistribution by Size Category:\n")
category_summary = df %>%
  count(size_category_detailed) %>%
  mutate(percentage = round(n/sum(n)*100, 1))
print(category_summary)

cat("\n\nDistribution by Custom Bins:\n")
print(bin_summary)

cat("\n========================================\n")
cat("All plots saved to cleaned_data/Plot/\n")
cat("========================================\n")
```

# Pub Hist
```{r}
###############################################################################
##  Publication Year Histogram
###############################################################################

# Prepare data
df_pub_year = data.frame(
  pub_year = df_meta$PublicationYear
) %>%
  filter(!is.na(pub_year))

# Create histogram
p_pub_year = ggplot(df_pub_year, aes(x = pub_year)) +
  geom_histogram(binwidth = 1, fill = "#2196F3", color = "white", alpha = 0.8) +
  labs(x = "Publication Year",
       y = "Number of Trials") +
  theme_minimal(base_size = 15) +
  theme(
    axis.title = element_text(size = 15),
    axis.text = element_text(size = 13),
    panel.grid.minor = element_blank(),
    panel.background = element_rect(fill = "white", colour = NA),
    plot.background = element_rect(fill = "white", colour = NA)
  ) +
  scale_x_continuous(breaks = seq(1940, 2030, by = 5))

# Display and save
print(p_pub_year)
ggsave("cleaned_data/Plot/publication_year_histogram.png", p_pub_year, 
       width = 10, height = 6, dpi = 600, bg = "white")

###############################################################################
## Summary Statistics
###############################################################################
cat("\n=== Publication Year Summary ===\n")
cat("Number of trials:", nrow(df_pub_year), "\n")
cat("Year range:", min(df_pub_year$pub_year), "-", max(df_pub_year$pub_year), "\n")
cat("\nYear Distribution:\n")
print(summary(df_pub_year$pub_year))
cat("\nTrials per decade:\n")
df_pub_year %>%
  mutate(decade = floor(pub_year / 10) * 10) %>%
  count(decade) %>%
  arrange(decade) %>%
  print()
cat("\nPlot saved to cleaned_data/Plot/publication_year_histogram.png\n")
```


# N. Cova vs N Plot
```{r}
###############################################################################
##  Covariates vs Sample Size - Scatter Plots Only
###############################################################################

# Prepare data: get mean covariates per trial and merge with sample size
df_cov_summary = df_comparison %>% 
  group_by(Trial_No) %>% 
  summarise(mean_covariates = round(mean(N_Covariates, na.rm = TRUE)), 
            .groups = 'drop')

# Merge with sample size data from df_meta (using Trial_ID)
df_cov_size = df_meta %>%
  select(Trial_ID, Sample_Size = `Sample Size`) %>%
  inner_join(df_cov_summary, by = c("Trial_ID" = "Trial_No")) %>%
  filter(!is.na(Sample_Size), !is.na(mean_covariates))

# Calculate correlation
correlation = cor(df_cov_size$Sample_Size, df_cov_size$mean_covariates, 
                  use = "complete.obs")

###############################################################################
## Original Scale Version (Scatter Only)
###############################################################################
p_cov_size = ggplot(df_cov_size, aes(x = Sample_Size, y = mean_covariates)) +
  geom_point(alpha = 0.6, size = 3, color = "#2196F3") +
  labs(x = "Sample Size",
       y = "Average Number of Covariates") +
  theme_minimal(base_size = 15) +
  theme(
    axis.title = element_text(size = 15),
    axis.text = element_text(size = 13),
    panel.grid.minor = element_blank(),
    panel.background = element_rect(fill = "white", colour = NA),
    plot.background = element_rect(fill = "white", colour = NA)
  ) +
  scale_x_continuous(labels = scales::comma_format())

# Display and save
print(p_cov_size)
ggsave("cleaned_data/Plot/covariates_vs_sample_size.png", p_cov_size, 
       width = 10, height = 6, dpi = 600, bg = "white")

###############################################################################
## Log10 Version (Scatter Only)
###############################################################################
p_cov_size_log = ggplot(df_cov_size, aes(x = log10(Sample_Size), y = mean_covariates)) +
  geom_point(alpha = 0.6, size = 3, color = "#2196F3") +
  labs(x = "Log10(Sample Size)",
       y = "Average Number of Covariates") +
  theme_minimal(base_size = 15) +
  theme(
    axis.title = element_text(size = 15),
    axis.text = element_text(size = 13),
    panel.grid.minor = element_blank(),
    panel.background = element_rect(fill = "white", colour = NA),
    plot.background = element_rect(fill = "white", colour = NA)
  )

# Display and save log version
print(p_cov_size_log)
ggsave("cleaned_data/Plot/covariates_vs_sample_size_log.png", p_cov_size_log, 
       width = 10, height = 6, dpi = 600, bg = "white")

###############################################################################
## Summary Statistics
###############################################################################
cat("\n=== Covariates vs Sample Size Summary ===\n")
cat("Number of trials:", nrow(df_cov_size), "\n")
cat("Correlation coefficient:", round(correlation, 3), "\n")
cat("\nSample Size Summary:\n")
print(summary(df_cov_size$Sample_Size))
cat("\nNumber of Covariates Summary:\n")
print(summary(df_cov_size$mean_covariates))
cat("\nBoth plots saved to cleaned_data/Plot/\n")
cat("  - covariates_vs_sample_size.png (original scale)\n")
cat("  - covariates_vs_sample_size_log.png (log10 scale)\n")
```


# Research Area Pie Chart
```{r}
# Consolidate similar research areas
df_meta_consolidated <- df_meta %>%
  mutate(Research_Area_Consolidated = case_when(
    `Research Area` %in% c("Anesthesiology") ~ "Anesthesiology",
    `Research Area` %in% c("HIV") ~ "HIV/AIDS",
    `Research Area` %in% c("Maternal and Child Health", "Obstetrics", "Neonatology") ~ "Maternal & Child Health",
    `Research Area` %in% c("Neurology", "Neuropsychology") ~ "Neurology",
    `Research Area` %in% c("COVID-19", "Tuberculosis", "Vaccinology") ~ "Infectious Disease",
    `Research Area` %in% c("Mental Health", "Addiction Medicine") ~ "Mental Health",
    `Research Area` %in% c("Cardiovascular Disease", "Hypertension") ~ "Cardiovascular",
    TRUE ~ `Research Area`
  ))

# Count and prepare data
area_counts <- df_meta_consolidated %>%
  count(Research_Area_Consolidated) %>%
  arrange(desc(n)) %>%
  mutate(
    percentage = n / sum(n) * 100,
    label = ifelse(percentage > 3, 
                   paste0(Research_Area_Consolidated, "\n(", n, ")"),
                   "")
  )

# Plot research area pie chart
p2 <- ggplot(area_counts, 
             aes(x = "", y = n, fill = Research_Area_Consolidated)) +
  geom_bar(stat = "identity", width = 1, color = "white", linewidth = 0.5) +
  coord_polar("y", start = 0) +
  scale_fill_viridis_d(option = "turbo") +
  theme_void() +
  theme(
    legend.title = element_text(size = 16, face = "bold"),
    legend.text = element_text(size = 14),
    legend.position = "right"
  ) +
  labs(fill = "Research Area") +
  geom_text(aes(label = ifelse(n >= 3, n, "")), 
            position = position_stack(vjust = 0.5),
            color = "white", size = 3.5, fontface = "bold")

# Display and save
print(p2)
ggsave("cleaned_data/Plot/research_area_pie.png", p2, 
       width = 12, height = 7, dpi = 600, bg = "white")

# Print summary
cat("\n=== Research Area Summary ===\n")
print(area_counts %>% select(-label))
```

# Rand Scheme Pie Chart 
```{r}
# Count and prepare data for Randomization Scheme
randomization_counts <- df_meta %>%
  # Combine Stratified and Stratified Block into Stratified
  mutate(`Randomization Scheme(High Level)` = case_when(
    `Randomization Scheme(High Level)` %in% c("Stratified", "Stratified Block") ~ "Stratified",
    TRUE ~ `Randomization Scheme(High Level)`
  )) %>%
  count(`Randomization Scheme(High Level)`) %>%
  arrange(desc(n)) %>%
  mutate(
    percentage = n / sum(n) * 100,
    label = paste0(`Randomization Scheme(High Level)`, "\n(", n, ", ", round(percentage, 1), "%)")
  )

# Create color palette with updated categories
rand_colors <- c(
  "Stratified" = "#E41A1C",
  "Simple" = "#377EB8", 
  "Block" = "#4DAF4A",
  "Stratified Rerandomization" = "#FF7F00",
  "Biased Coin" = "#FFFF33"
)

# Plot randomization scheme pie chart
p1 <- ggplot(randomization_counts, 
             aes(x = "", y = n, fill = `Randomization Scheme(High Level)`)) +
  geom_bar(stat = "identity", width = 1, color = "white", linewidth = 0.5) +
  coord_polar("y", start = 0) +
  scale_fill_manual(values = rand_colors) +
  theme_void() +
  theme(
    legend.title = element_text(size = 16, face = "bold"),
    legend.text = element_text(size = 14),
    legend.position = "right"
  ) +
  labs(fill = "Randomization Scheme") +
  geom_text(aes(label = n), 
            position = position_stack(vjust = 0.5),
            color = "white", size = 4, fontface = "bold")

# Display and save
print(p1)
ggsave("cleaned_data/Plot/randomization_scheme_pie.png", p1, 
       width = 10, height = 6, dpi = 600, bg = "white")

# Print summary
cat("\n=== Randomization Scheme Summary ===\n")
print(randomization_counts %>% select(-label))
```

