---
title: "RCT_analysis"
author: "Yulin Shao"
date: "2025-06-02"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rio)
library(janitor)
library(readxl)
library(striprtf)
library(stringr)
library(tibble)
library(tidyr)
library(stringi)
library(haven)
library(purrr)
library(DescTools)
library(RobinCar)
library(ggplot2)
library(writexl)
```

# Load Data

```{r}
df_comparison = read_xlsx("cleaned_data/meta_data_comparison.xlsx")
```

# Function

## analyze_rct_sl()

```{r}
analyze_rct_sl = function(data,
                          treatment_col  = "Treatment",
                          outcome_cols,
                          covariate_cols,
                          reference_arm  = NULL,
                          K              = 5,
                          SL_methods     = c("SL.glm", "SL.rpart", "SL.mean", "SL.nnet"),
                          n_cores        = parallel::detectCores() - 2) {
  require(dplyr)
  require(SuperLearner)
  require(foreach)
  require(doSNOW)
  require(doRNG)
  
  n  = nrow(data)
  
  ## ── set up inner cluster ────────────────────────────────────────────────
  cl = makeCluster(n_cores)
  registerDoSNOW(cl)
  registerDoRNG()
  on.exit(stopCluster(cl), add = TRUE)
  
  arms = levels(data[[treatment_col]])
  if (is.null(reference_arm))
    reference_arm = arms[1]
  if (!(reference_arm %in% arms))
    stop("reference_arm must be one of: ", paste(arms, collapse = ", "))
  
  pi_tab = prop.table(table(data[[treatment_col]]))
  
  ## CV splits — handle K = 1 specially
  if (K == 1) {
    splits = list(seq_len(n))
  } else {
    split_ix = sample(rep(1:K, length.out = n))
    splits   = split(seq_len(n), split_ix)
  }
  
  combos = expand.grid(
    Outcome   = outcome_cols,
    Treatment = setdiff(arms, reference_arm),
    stringsAsFactors = FALSE
  )
  
  results = foreach(
    i = seq_len(nrow(combos)),
    .combine = dplyr::bind_rows,
    .packages = c("dplyr", "SuperLearner")
  ) %dopar% {
    Y   = combos$Outcome[i]
    arm = combos$Treatment[i]
    pair_arms = c(reference_arm, arm)
    pi_pair   = pi_tab[pair_arms]
    
    ## matrix to hold EIF contributions for all n rows
    full_preds = matrix(
      NA_real_,
      nrow = n,
      ncol = 2,
      dimnames = list(NULL, pair_arms)
    )
    
    for (k in seq_along(splits)) {
      val_ix   = splits[[k]]
      train_ix = if (K == 1)
        val_ix
      else
        setdiff(seq_len(n), val_ix)
      
      for (a in pair_arms) {
        sel_tr = train_ix[data[[treatment_col]][train_ix] == a]
        
        fit = SuperLearner(
          Y          = data[[Y]][sel_tr],
          X          = data[sel_tr, covariate_cols, drop = FALSE],
          newX       = data[val_ix, covariate_cols, drop = FALSE],
          family     = gaussian(),
          cvControl  = list(V = min(10, length(sel_tr))),
          SL.library = SL_methods
        )
        
        eta_hat = fit$SL.predict
        A_k     = as.integer(data[[treatment_col]][val_ix] == a)
        full_preds[val_ix, a] =
          A_k / pi_pair[a] * (data[[Y]][val_ix] - eta_hat) + eta_hat
      }
    }
    
    D_i = full_preds[, arm] - full_preds[, reference_arm]
    tibble(
      Outcome   = Y,
      Treatment = arm,
      Control   = reference_arm,
      Est_SL    = mean(D_i),
      SE_SL     = sqrt(var(D_i) / n)
    )
  }
  
  results
}
```

## analyze_rct()

```{r}
analyze_rct = function(df,
                       outcome_cols = NULL,
                       covariate_col = NULL,
                       treatment_col = "Treatment",
                       K = 5,
                       SL_methods = c("SL.glm", "SL.rpart", "SL.mean", "SL.nnet"),
                       selection = FALSE,
                       n_select = 3,
                       n_cores = parallel::detectCores() - 2,
                       seed = 123) {
  require(dplyr)
  require(RobinCar)
  require(tidyr)
  require(DescTools)
  
  # Set seed once at the beginning for reproducibility
  set.seed(seed)
  
  # Auto-detect outcome columns if not specified
  if (is.null(outcome_cols)) {
    # All YP columns
    yp_cols = names(df)[startsWith(names(df), "YP")]
    
    # Numeric and binary YS columns
    ys_cols = names(df)[startsWith(names(df), "YS")]
    ys_valid = character(0)
    for (col in ys_cols) {
      if (is.numeric(df[[col]]) ||
          (is.factor(df[[col]]) &&
           length(levels(df[[col]])) == 2)) {
        ys_valid = c(ys_valid, col)
      }
    }
    
    outcome_cols = c(yp_cols, ys_valid)
    cat(
      "Auto-detected",
      length(outcome_cols),
      "outcome columns:",
      paste(outcome_cols, collapse = ", "),
      "\n"
    )
  }
  
  # Setup covariates
  if (is.null(covariate_col)) {
    covariates = names(df)[startsWith(names(df), "X_")]
    # Add n_participants if it exists
    if ("n_participants" %in% names(df)) {
      covariates = c(covariates, "n_participants")
    }
  } else {
    covariates = covariate_col
  }
  
  # Fill missing values in covariates
  df = df %>%
    mutate(across(all_of(covariates), ~ if (is.numeric(.)) {
      replace(., is.na(.), mean(., na.rm = TRUE))
    } else if (is.factor(.)) {
      replace(., is.na(.), Mode(., na.rm = TRUE)[1])
    }))
  
  control_level = levels(df[[treatment_col]])[1]
  treat_pattern = paste0("^", treatment_col)
  
  control_level = levels(df[[treatment_col]])[1]
  treat_pattern = paste0("^", treatment_col)
  
  # Process each outcome
  all_results = vector("list", length(outcome_cols))
  valid_outcomes = character(0)
  
  for (i in seq_along(outcome_cols)) {
    outcome = outcome_cols[i]
    
    # Check missing proportion for outcome
    missing_prop = mean(is.na(df[[outcome]]))
    if (missing_prop > 0.4) {
      cat(
        "REMOVED outcome:",
        outcome,
        "- Missing proportion:",
        round(missing_prop, 3),
        "(> 0.4)\n"
      )
      next
    }
    
    # Filter complete cases for this outcome
    complete_vars = c(outcome, treatment_col, covariates)
    complete_cases_idx = complete.cases(df[, complete_vars, drop = FALSE])
    df_complete = df[complete_cases_idx, , drop = FALSE]
    
    cat(
      "Outcome:",
      outcome,
      "- Sample size:",
      nrow(df_complete),
      "(",
      nrow(df) - nrow(df_complete),
      "rows removed)\n"
    )
    
    # Check for single-level factors after filtering
    if (is.factor(df_complete[[outcome]]) &&
        length(levels(droplevels(df_complete[[outcome]]))) <= 1) {
      cat("REMOVED outcome:",
          outcome,
          "- Only one level after filtering\n")
      next
    }
    
    # Check covariates for single levels and remove them
    valid_covariates = character(0)
    for (cov in covariates) {
      if (is.factor(df_complete[[cov]]) &&
          length(levels(droplevels(df_complete[[cov]]))) <= 1) {
        cat(
          "REMOVED covariate:",
          cov,
          "- Only one level after filtering (outcome:",
          outcome,
          ")\n"
        )
      } else {
        valid_covariates = c(valid_covariates, cov)
      }
    }
    
    # Determine if outcome is binary
    is_binary = is.factor(df_complete[[outcome]]) && 
                length(levels(droplevels(df_complete[[outcome]]))) == 2
    
    # For variable selection and traditional models, convert to numeric
    df_complete_numeric = df_complete
    if (is_binary) {
      # Convert binary factor/numeric to 0,1
      # Handle cases where data is already 0,1 or needs conversion from 1,2
      numeric_outcome = as.numeric(df_complete_numeric[[outcome]])
      unique_vals = sort(unique(numeric_outcome))
      
      if (all(unique_vals == c(0, 1))) {
        # Already 0,1 - keep as is
        df_complete_numeric[[outcome]] = numeric_outcome
      } else if (all(unique_vals == c(1, 2))) {
        # Convert 1,2 to 0,1
        df_complete_numeric[[outcome]] = numeric_outcome - 1
      } else {
        stop(paste("Binary outcome", outcome, "has unexpected values:", paste(unique_vals, collapse = ", "), "- expected 0,1 or 1,2"))
      }
    } else {
      df_complete_numeric[[outcome]] = as.numeric(df_complete_numeric[[outcome]])
    }
    
    # Variable selection: select top n_select covariates by outcome-specific correlation
    if (selection && length(valid_covariates) > 0) {
      if (length(valid_covariates) > n_select) {
        # Get correlations between this outcome and ALL covariates (convert factors to numeric temporarily)
        cov_values = numeric(length(valid_covariates))
        names(cov_values) = valid_covariates
        
        for (cov in valid_covariates) {
          # Convert covariate to numeric temporarily for correlation computation
          cov_numeric = as.numeric(df_complete_numeric[[cov]])
          cov_values[cov] = cor(df_complete_numeric[[outcome]], cov_numeric, use = "complete.obs")
        }
        
        # Select top n_select by absolute correlation magnitude
        top_idx = order(abs(cov_values), decreasing = TRUE)[1:n_select]
        selected_covariates = valid_covariates[top_idx]
        valid_covariates = selected_covariates
      }
      # If ≤n_select valid covariates, use all of them (valid_covariates unchanged)
    }
    
    
    # Fit traditional models (using numeric version)
    coef_unadj = coef(summary(lm(
      reformulate(treatment_col, outcome), df_complete_numeric
    )))
    coef_ancova = coef(summary(lm(
      reformulate(c(treatment_col, valid_covariates), outcome), df_complete_numeric
    )))
    
    # Extract treatment effects
    treat_idx_unadj = which(startsWith(rownames(coef_unadj), treatment_col))
    treat_idx_ancova = which(startsWith(rownames(coef_ancova), treatment_col))
    
    # Create results for this outcome
    n_treat = length(treat_idx_unadj)
    treatment_levels = sub(treat_pattern, "", rownames(coef_unadj)[treat_idx_unadj])
    
    # Calculate pairwise sample sizes (control + current treatment)
    pairwise_n = sapply(treatment_levels, function(treat_level) {
      sum(df_complete[[treatment_col]] %in% c(control_level, treat_level))
    })
    
    # Create base outcome results
    outcome_results = tibble(
      Outcome = rep(outcome, n_treat),
      Treatment = treatment_levels,
      Control = rep(control_level, n_treat),
      N = pairwise_n,
      N_Covariates = rep(length(valid_covariates), n_treat),
      # Unadjusted
      Est_UN = coef_unadj[treat_idx_unadj, 1],
      SE_UN = coef_unadj[treat_idx_unadj, 2],
      # ANCOVA
      Est_AC = coef_ancova[treat_idx_ancova, 1],
      SE_AC = coef_ancova[treat_idx_ancova, 2]
    )
    
    # Add Selected_Covariates column only if selection = TRUE
    if (selection) {
      outcome_results$Selected_Covariates = rep(paste(valid_covariates, collapse = ", "), n_treat)
    }
    
    # RobinCar - run both ANCOVA and ANHECOVA (using numeric version)
    rc_fit_ancova = suppressWarnings(
      robincar_linear(
        df_complete_numeric,
        treatment_col,
        outcome,
        covariate_cols = valid_covariates,
        adj_method = "ANCOVA",
        contrast_h = "diff"
      )
    )
    rc_result_ancova = rc_fit_ancova$contrast$result
    outcome_results$Est_RC_ANCOVA = rc_result_ancova$estimate
    outcome_results$SE_RC_ANCOVA = rc_result_ancova$se
    
    rc_fit_anhecova = suppressWarnings(
      robincar_linear(
        df_complete_numeric,
        treatment_col,
        outcome,
        covariate_cols = valid_covariates,
        adj_method = "ANHECOVA",
        contrast_h = "diff"
      )
    )
    rc_result_anhecova = rc_fit_anhecova$contrast$result
    outcome_results$Est_RC_ANHECOVA = rc_result_anhecova$estimate
    outcome_results$SE_RC_ANHECOVA = rc_result_anhecova$se
    
    # RobinCar GLM for binary outcomes
    if (is_binary) {
      # Create formula for GLM: outcome ~ Treatment + covariates
      formula_terms = c(treatment_col, valid_covariates)
      glm_formula = as.formula(paste(outcome, "~", paste(formula_terms, collapse = " + ")))
      
      rc_fit_binom = suppressWarnings(
        robincar_glm(
          df_complete_numeric,  # Use numeric version (0,1 for binary outcome)
          treatment_col,
          outcome,
          formula = glm_formula,
          g_family = stats::binomial,
          contrast_h = "diff"
        )
      )
      rc_result_binom = rc_fit_binom$contrast$result
      outcome_results$Est_RC_Binom = rc_result_binom$estimate
      outcome_results$SE_RC_Binom = rc_result_binom$se
    } else {
      # For non-binary outcomes, set Binom results to NA
      outcome_results$Est_RC_Binom = rep(NA_real_, n_treat)
      outcome_results$SE_RC_Binom = rep(NA_real_, n_treat)
    }
    
    # SuperLearner - run ensemble and individual methods (using numeric version)
    tryCatch({
      sl_res = analyze_rct_sl(
        data = df_complete_numeric,
        outcome_cols = outcome,
        covariate_cols = valid_covariates,
        treatment_col = treatment_col,
        reference_arm = control_level,
        K = K,
        SL_methods = SL_methods,
        n_cores = n_cores
      )
      outcome_results$Est_SL = sl_res$Est_SL
      outcome_results$SE_SL = sl_res$SE_SL
    }, error = function(e) {
      if (grepl("All algorithms dropped from library", e$message)) {
        outcome_results$Est_SL <<- rep(NA_real_, n_treat)
        outcome_results$SE_SL <<- rep(NA_real_, n_treat)
      } else {
        stop(e)
      }
    })
    
    # Run individual SL methods - only rpart, and nnet
    individual_methods = c("SL.rpart", "SL.nnet")
    for (method in individual_methods) {
      tryCatch({
        sl_res_individual = analyze_rct_sl(
          data = df_complete_numeric,
          outcome_cols = outcome,
          covariate_cols = valid_covariates,
          treatment_col = treatment_col,
          reference_arm = control_level,
          K = K,
          SL_methods = method,
          n_cores = n_cores
        )
        # Clean method name for column naming
        method_clean = gsub("SL\\.", "SL_", method)
        outcome_results[[paste0("Est_", method_clean)]] = sl_res_individual$Est_SL
        outcome_results[[paste0("SE_", method_clean)]] = sl_res_individual$SE_SL
      }, error = function(e) {
        # For any error, set to NA
        method_clean = gsub("SL\\.", "SL_", method)
        outcome_results[[paste0("Est_", method_clean)]] <<- rep(NA_real_, n_treat)
        outcome_results[[paste0("SE_", method_clean)]] <<- rep(NA_real_, n_treat)
      })
    }
    
    valid_outcomes = c(valid_outcomes, outcome)
    all_results[[length(valid_outcomes)]] = outcome_results
  }
  
  if (length(valid_outcomes) == 0) {
    stop("No valid outcomes remaining after data cleaning")
  }
  
  # Combine all outcomes
  final_results = bind_rows(all_results[1:length(valid_outcomes)]) %>%
    # Round for cleaner output
    mutate(across(starts_with("Est_"), ~ round(.x, 5)),
           across(starts_with("SE_"), ~ round(.x, 5))) %>%
    # Reorder columns
    select(
      Outcome,
      N,
      N_Covariates,
      Treatment,
      Control,
      Est_RC_ANCOVA,
      SE_RC_ANCOVA,
      Est_RC_ANHECOVA,
      SE_RC_ANHECOVA,
      Est_RC_Binom,
      SE_RC_Binom,
      Est_AC,
      SE_AC,
      Est_UN,
      SE_UN,
      Est_SL,
      SE_SL,
      everything()
    )
  
  return(final_results)
}
```

## update_df()

```{r}
update_df = function(trial_no,
                     outcome_type,
                     results1 = res1,
                     results2 = res2,
                     contrast = "diff",
                     df = df_comparison) {

  library(dplyr)

  ## ────────────────────────────────────────────────────────────────
  ## 0)  Outcome → Outcome-Type lookup
  ## ────────────────────────────────────────────────────────────────
  unique_outcomes = unique(results1$Outcome)
  stopifnot(length(outcome_type) == length(unique_outcomes))

  outcome_type_map = tibble(
    Outcome        = unique_outcomes,
    `Outcome Type` = outcome_type
  )

  ## ────────────────────────────────────────────────────────────────
  ## 1)  Helper: tidy one result set (BASE or VS)
  ## ────────────────────────────────────────────────────────────────
  process_results = function(results, suffix = "") {

    if (suffix == "") {
      results_renamed = results %>%
        mutate(
          ANCOVA_est            = Est_RC_ANCOVA,
          ANCOVA_robust_se      = SE_RC_ANCOVA,
          ANHECOVA_est          = Est_RC_ANHECOVA,
          ANHECOVA_robust_se    = SE_RC_ANHECOVA,
          Binom_est             = Est_RC_Binom,
          Binom_robust_se       = SE_RC_Binom,
          ANCOVA_model_based_se = SE_AC,
          Unadjust_est          = Est_UN,
          Unadjust_se           = SE_UN,
          SL_est                = Est_SL,
          SL_se                 = SE_SL
        )
    } else {
      results_renamed = results %>%
        mutate(
          ANCOVA_VS_est            = Est_RC_ANCOVA,
          ANCOVA_VS_robust_se      = SE_RC_ANCOVA,
          ANHECOVA_VS_est          = Est_RC_ANHECOVA,
          ANHECOVA_VS_robust_se    = SE_RC_ANHECOVA,
          Binom_VS_est             = Est_RC_Binom,
          Binom_VS_robust_se       = SE_RC_Binom,
          ANCOVA_VS_model_based_se = SE_AC,
          SL_VS_est                = Est_SL,
          SL_VS_se                 = SE_SL,
          Unadjust_est             = Est_UN,
          Unadjust_se              = SE_UN
          # Selected_Covariates is already in results2; leave untouched
        )
    }

    ## ── rename SL member columns ───────────────────────────────────
    sl_methods = c("SL_rpart", "SL_nnet")
    for (m in sl_methods) {
      est_old = paste0("Est_", m)
      se_old  = paste0("SE_",  m)

      est_new = if (suffix == "") paste0(m, "_est") else paste0(m, "_VS_est")
      se_new  = if (suffix == "") paste0(m, "_se")  else paste0(m, "_VS_se")

      if (est_old %in% names(results_renamed))
        results_renamed = rename(results_renamed, !!est_new := !!est_old)
      if (se_old  %in% names(results_renamed))
        results_renamed = rename(results_renamed, !!se_new := !!se_old)
    }

    ## ── attach meta data ───────────────────────────────────────────
    results_processed = results_renamed %>%
      left_join(outcome_type_map, by = "Outcome") %>%
      mutate(
        Trial_No     = trial_no,
        Sample_Size  = N,
        N_Covariates = N_Covariates,   # VS copy dropped later
        Contrast     = contrast
      )

    ## ── precision gain / variance ratio / diff-in-estimate columns ─
    if (suffix == "") {
      results_processed = results_processed %>%
        mutate(
          `How much precision gain can ANCOVA provide?`   = (ANCOVA_robust_se / Unadjust_se)^2,
          `How much precision gain can ANHECOVA provide?` = (ANHECOVA_robust_se / Unadjust_se)^2,
          `How much precision gain can Binom provide?`    = (Binom_robust_se / Unadjust_se)^2,
          `How much precision gain can SL provide?`       = (SL_se / Unadjust_se)^2,
          `ANCOVA vs ANHECOVA variance ratio`             = (ANCOVA_robust_se / ANHECOVA_robust_se)^2,
          `The ratio between robust and model-based variance estimators` =
            (ANCOVA_robust_se / ANCOVA_model_based_se)^2,
          `The difference between unadjusted and ANCOVA point estimates` =
            (ANCOVA_est - Unadjust_est) /
            sqrt((ANCOVA_robust_se^2 + Unadjust_se^2) / 2),
          `The difference between unadjusted and ANHECOVA point estimates` =
            (ANHECOVA_est - Unadjust_est) /
            sqrt((ANHECOVA_robust_se^2 + Unadjust_se^2) / 2),
          `The difference between unadjusted and Binom point estimates` =
            (Binom_est - Unadjust_est) /
            sqrt((Binom_robust_se^2 + Unadjust_se^2) / 2),
          `The difference between unadjusted and SL point estimates` =
            (SL_est - Unadjust_est) /
            sqrt((SL_se^2 + Unadjust_se^2) / 2)
        )
    } else {
      results_processed = results_processed %>%
        mutate(
          `How much precision gain can ANCOVA_VS provide?`   = (ANCOVA_VS_robust_se / Unadjust_se)^2,
          `How much precision gain can ANHECOVA_VS provide?` = (ANHECOVA_VS_robust_se / Unadjust_se)^2,
          `How much precision gain can Binom_VS provide?`    = (Binom_VS_robust_se / Unadjust_se)^2,
          `How much precision gain can SL_VS provide?`       = (SL_VS_se / Unadjust_se)^2,
          `ANCOVA_VS vs ANHECOVA_VS variance ratio`          = (ANCOVA_VS_robust_se / ANHECOVA_VS_robust_se)^2,
          `The ratio between robust and model-based variance estimators_VS` =
            (ANCOVA_VS_robust_se / ANCOVA_VS_model_based_se)^2,
          `The difference between unadjusted and ANCOVA_VS point estimates` =
            (ANCOVA_VS_est - Unadjust_est) /
            sqrt((ANCOVA_VS_robust_se^2 + Unadjust_se^2) / 2),
          `The difference between unadjusted and ANHECOVA_VS point estimates` =
            (ANHECOVA_VS_est - Unadjust_est) /
            sqrt((ANHECOVA_VS_robust_se^2 + Unadjust_se^2) / 2),
          `The difference between unadjusted and Binom_VS point estimates` =
            (Binom_VS_est - Unadjust_est) /
            sqrt((Binom_VS_robust_se^2 + Unadjust_se^2) / 2),
          `The difference between unadjusted and SL_VS point estimates` =
            (SL_VS_est - Unadjust_est) /
            sqrt((SL_VS_se^2 + Unadjust_se^2) / 2)
        )
    }

    ## ── SL-member-specific precision gains & diffs ──────────────────
    for (m in sl_methods) {
      if (suffix == "") {
        se_col  = paste0(m, "_se")
        est_col = paste0(m, "_est")
        pg_col  = paste0("How much precision gain can ", m, " provide?")
        diff_col= paste0("The difference between unadjusted and ", m, " point estimates")
      } else {
        se_col  = paste0(m, "_VS_se")
        est_col = paste0(m, "_VS_est")
        pg_col  = paste0("How much precision gain can ", m, "_VS provide?")
        diff_col= paste0("The difference between unadjusted and ", m, "_VS point estimates")
      }

      if (all(c(se_col, est_col) %in% names(results_processed))) {
        results_processed = results_processed %>%
          mutate(
            !!pg_col  := (.data[[se_col]] / Unadjust_se)^2,
            !!diff_col:= (.data[[est_col]] - Unadjust_est) /
                         sqrt((.data[[se_col]]^2 + Unadjust_se^2) / 2)
          )
      }
    }

    results_processed
  }

  ## ────────────────────────────────────────────────────────────────
  ## 2)  Process BASE and (optional) VS results
  ## ────────────────────────────────────────────────────────────────
  new_rows_base = process_results(results1, "")
  new_rows      = new_rows_base

  if (!is.null(results2)) {

    new_rows_vs = process_results(results2, "VS") %>%
      select(-N_Covariates)              # keep Selected_Covariates, drop VS N_Covariates

    join_keys = c("Trial_No", "Sample_Size", "Contrast",
                  "Treatment", "Control", "Outcome",
                  "Unadjust_est", "Unadjust_se")

    new_rows = new_rows_base %>%
      left_join(new_rows_vs, by = join_keys, suffix = c("", ".vs")) %>%
      select(-matches("\\.vs$"))         # remove accidental *.vs duplicates
  }

  ## ────────────────────────────────────────────────────────────────
  ## 3)  Desired column order
  ## ────────────────────────────────────────────────────────────────
  base_cols = if (!is.null(results2)) {
    c("Trial_No", "Sample_Size", "N_Covariates", "Selected_Covariates",
      "Treatment", "Control", "Contrast", "Outcome", "Outcome Type")
  } else {
    c("Trial_No", "Sample_Size", "N_Covariates",
      "Treatment", "Control", "Contrast", "Outcome", "Outcome Type")
  }

  se_unadj = "Unadjust_se"
  se_base  = c("ANCOVA_robust_se","ANCOVA_model_based_se","ANHECOVA_robust_se",
               "Binom_robust_se","SL_se","SL_rpart_se","SL_nnet_se")
  se_vs    = c("ANCOVA_VS_robust_se","ANCOVA_VS_model_based_se","ANHECOVA_VS_robust_se",
               "Binom_VS_robust_se","SL_VS_se","SL_rpart_VS_se","SL_nnet_VS_se")

  pg_base = c(
    "How much precision gain can ANCOVA provide?",
    "How much precision gain can ANHECOVA provide?",
    "How much precision gain can Binom provide?",
    "How much precision gain can SL provide?",
    "How much precision gain can SL_rpart provide?",
    "How much precision gain can SL_nnet provide?"
  )
  pg_vs = c(
    "How much precision gain can ANCOVA_VS provide?",
    "How much precision gain can ANHECOVA_VS provide?",
    "How much precision gain can Binom_VS provide?",
    "How much precision gain can SL_VS provide?",
    "How much precision gain can SL_rpart_VS provide?",
    "How much precision gain can SL_nnet_VS provide?"
  )

  ratio_base = c(
    "The ratio between robust and model-based variance estimators",
    "ANCOVA vs ANHECOVA variance ratio"
  )
  ratio_vs = c(
    "The ratio between robust and model-based variance estimators_VS",
    "ANCOVA_VS vs ANHECOVA_VS variance ratio"
  )

  est_unadj = "Unadjust_est"
  est_base  = c("ANCOVA_est","ANHECOVA_est","Binom_est","SL_est",
                "SL_rpart_est","SL_nnet_est")
  est_vs    = c("ANCOVA_VS_est","ANHECOVA_VS_est","Binom_VS_est","SL_VS_est",
                "SL_rpart_VS_est","SL_nnet_VS_est")

  diff_base = c(
    "The difference between unadjusted and ANCOVA point estimates",
    "The difference between unadjusted and ANHECOVA point estimates",
    "The difference between unadjusted and Binom point estimates",
    "The difference between unadjusted and SL point estimates",
    "The difference between unadjusted and SL_rpart point estimates",
    "The difference between unadjusted and SL_nnet point estimates"
  )
  diff_vs = c(
    "The difference between unadjusted and ANCOVA_VS point estimates",
    "The difference between unadjusted and ANHECOVA_VS point estimates",
    "The difference between unadjusted and Binom_VS point estimates",
    "The difference between unadjusted and SL_VS point estimates",
    "The difference between unadjusted and SL_rpart_VS point estimates",
    "The difference between unadjusted and SL_nnet_VS point estimates"
  )

  all_cols = if (!is.null(results2)) {
    c(base_cols, se_unadj, se_base, se_vs,
      pg_base, pg_vs, ratio_base, ratio_vs,
      est_unadj, est_base, est_vs, diff_base, diff_vs)
  } else {
    c(base_cols, se_unadj, se_base,
      pg_base, ratio_base, est_unadj, est_base, diff_base)
  }

  new_rows = select(new_rows, all_of(intersect(all_cols, names(new_rows))))

  ## ────────────────────────────────────────────────────────────────
  ## 4)  Overwrite / append in df_comparison
  ## ────────────────────────────────────────────────────────────────
  for (i in seq_len(nrow(new_rows))) {
    row_i = new_rows[i, ]

    idx = which(
      df$Trial_No == row_i$Trial_No &
        df$Outcome   == row_i$Outcome &
        df$Treatment == row_i$Treatment &
        df$Control   == row_i$Control
    )

    if (length(idx) > 0) df[idx[1], names(row_i)] = row_i
    else                 df = bind_rows(df, row_i)
  }

  df
}


```

# Trial 1

## Load Data

```{r}
df1 = read_rds("cleaned_data/Non_Clustered_RCT/trial1.rds")
```

## Process
```{r}
res1 = analyze_rct(df1)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df1, selection = T)

df_comparison = update_df(1, rep("continuous", 15))
```

# Trial 2

## Load Data

```{r}
df2 = read_rds("cleaned_data/Non_Clustered_RCT/trial2.rds")

df2 = df2 %>% select(-YP_early_7d, -YP_late_12d)
```

## Process
```{r}
res1 = analyze_rct(df2)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df2, selection = T)

df_comparison = update_df(2, c("time to event", "binary", "binary"))
```


# Trial 3

## Load Data

```{r}
df3 = read_rds("cleaned_data/Non_Clustered_RCT/trial3.rds")
```

## Process
```{r}
res1 = analyze_rct(df3)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df3, selection = T)

df_comparison = update_df(3, c("binary", "time to event", rep("binary", 4), "continuous", "binary"))
```



# Trial 4

## Load Data

```{r}
df4 = read_rds("cleaned_data/Non_Clustered_RCT/trial4.rds")
```

## Process

```{r}
res1 = analyze_rct(df4)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df4, selection = T)

df_comparison = update_df(4, c("continuous", "continuous", "continuous", "continuous"))
```



# Trial 5

## Load Data

```{r}
df5 = read_rds("cleaned_data/Non_Clustered_RCT/trial5.rds")
```

## Process

```{r}
res1 = analyze_rct(df5)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df5, selection = T)

df_comparison = update_df(5, c("composite binary", "continuous", rep("binary", 10), rep("continuous", 3), "binary"))
```


# Trial 6

## Load Data

```{r}
df6 = read_rds("cleaned_data/Non_Clustered_RCT/trial6.rds")
```

## Process

```{r}
res1 = analyze_rct(df6)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df6, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(6, rep("continuous", n))
```


# Trial 7

## Load Data

```{r}
df7 = read_rds("cleaned_data/Non_Clustered_RCT/trial7.rds")
```

## Process

```{r}
res1 = analyze_rct(df7)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df7, selection = T)

df_comparison = update_df(7, rep("continuous", 8))
```


# Trial 8

## Load Data

```{r}
df8 = read_rds("cleaned_data/Non_Clustered_RCT/trial8.rds")

df8 = df8 %>% select(-X_comorbidities_0d)
```

## Process

```{r}
res1 = analyze_rct(df8)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df8, selection = T)

df_comparison = update_df(8, rep("binary", 6))
```


# Trial 9

## Load Data

```{r}
df9 = read_rds("cleaned_data/Non_Clustered_RCT/trial9.rds")
```

## Process

```{r}
res1 = analyze_rct(df9)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df9, selection = T)

df_comparison = update_df(9, c("binary", rep("continuous", 4), rep("binary", 10), "continuous",
                               rep("binary", 2), "continuous", rep("binary", 2)))
```


# Trial 10
## Load Data

```{r}
df10 = read_rds("cleaned_data/Non_Clustered_RCT/trial10.rds")
```

## Process

```{r}
res1 = analyze_rct(df10)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df10, selection = T)

df_comparison = update_df(10, c(rep("binary", 3), "continuous", rep("binary", 3), rep("continuous", 15)))
```
# Trial 11
## Load Data

```{r}
df11 = read_rds("cleaned_data/Non_Clustered_RCT/trial11.rds")
```

## Process

```{r}
res1 = analyze_rct(df11)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df11, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(11, rep("continuous", n))
```

# Trial 12
## Load Data

```{r}
df12 = read_rds("cleaned_data/Non_Clustered_RCT/trial12.rds")
```

## Process

```{r}
res1 = analyze_rct(df12)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df12, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(12, c(rep("binary", n)))
```

# Trial 13
## Load Data

```{r}
df13 = read_rds("cleaned_data/Non_Clustered_RCT/trial13.rds")
```

## Process

```{r}
res1 = analyze_rct(df13)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df13, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(13, c("continuous", "binary", rep("continuous", 7), "binary", "binary", rep("continuous", 5)))
```

# Trial 14
## Load Data

```{r}
df14 = read_rds("cleaned_data/Non_Clustered_RCT/trial14.rds")
```

## Process

```{r}
res1 = analyze_rct(df14)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df14, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(14, c(rep("continuous", n-5), rep("binary", 5)))
```

# Trial 15
## Load Data

```{r}
df15 = read_rds("cleaned_data/Non_Clustered_RCT/trial15.rds")
```

## Process

```{r}
res1 = analyze_rct(df15)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df15, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(15, rep("continuous", n))
```


# Trial 16
## Load Data

```{r}
df16 = read_rds("cleaned_data/Non_Clustered_RCT/trial16.rds")
```

## Process

```{r}
res1 = analyze_rct(df16)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df16, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(16, rep("continuous", n))
```


# Trial 17
## Load Data

```{r}
df17 = read_rds("cleaned_data/Non_Clustered_RCT/trial17.rds")
```

## Process

```{r}
res1 = analyze_rct(df17)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df17, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(17, rep("continuous", n))
```


# Trial 18
## Load Data

```{r}
df18 = read_rds("cleaned_data/Non_Clustered_RCT/trial18.rds") %>% 
  select(-YP_event_disengaged_12m)
```

## Process

```{r}
res1 = analyze_rct(df18)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df18, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(18, c("time to event", rep("continuous", n-1)))
```


# Trial 19
## Load Data

```{r}
df19 = read_rds("cleaned_data/Non_Clustered_RCT/trial19.rds")
```

## Process

```{r}
res1 = analyze_rct(df19)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df19, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(19, c(rep("continuous", n-1), "binary"))
```


# Trial 20
## Load Data

```{r}
df20 = read_rds("cleaned_data/Non_Clustered_RCT/trial20.rds")
```

## Process

```{r}
res1 = analyze_rct(df20)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df20, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(20, rep("continuous", n))
```


# Trial 21
## Load Data

```{r}
df21 = read_rds("cleaned_data/Non_Clustered_RCT/trial21.rds") %>% 
  select(-YP_tb_treatment_initiation)
```

## Process

```{r}
res1 = analyze_rct(df21)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df21, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(21, c("time to event", rep("binary", 4), "continuous"))
```


# Trial 22
## Load Data

```{r}
df22 = read_rds("cleaned_data/Non_Clustered_RCT/trial22.rds")
```

## Process

```{r}
res1 = analyze_rct(df22)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df22, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(22, c(rep("binary", 2), "continuous", rep("binary", 1), "continuous"))
```


# Trial 23
## Load Data

```{r}
df23 = read_rds("cleaned_data/Non_Clustered_RCT/trial23.rds") %>% 
  select(-YP_event_28d, -YP_event_90d)
```

## Process

```{r}
res1 = analyze_rct(df23)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df23, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(23, c("time to event", "time to event", rep("continuous", n - 2)))
```


# Trial 24
## Load Data

```{r}
df24 = read_rds("cleaned_data/Non_Clustered_RCT/trial24.rds")
```

## Process

```{r}
res1 = analyze_rct(df24)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df24, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(24, c("binary", "continuous", "continuous"))
```


# Trial 25
## Load Data

```{r}
df25 = read_rds("cleaned_data/Non_Clustered_RCT/trial25.rds")
```

## Process

```{r}
res1 = analyze_rct(df25)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df25, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(25, c(rep("continuous", 11), "binary", rep("continuous", 5)))
```


# Trial 26
## Load Data

```{r}
df26 = read_rds("cleaned_data/Non_Clustered_RCT/trial26.rds")
```

## Process

```{r}
res1 = analyze_rct(df26)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df26, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(26, c("continuous", "binary", "categorical", rep("continuous", n-3)))
```


# Trial 27
## Load Data

```{r}
df27 = read_rds("cleaned_data/Non_Clustered_RCT/trial27.rds")
```

## Process

```{r}
res1 = analyze_rct(df27)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df27, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(27, c("categorical", "binary", "continuous", "categorical",
                                "continuous", "continuous", "binary", "continuous"))
```


# Trial 28
## Load Data

```{r}
df28 = read_rds("cleaned_data/Non_Clustered_RCT/trial28.rds")
```

## Process

```{r}
res1 = analyze_rct(df28)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df28, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(28, c("binary", rep("continuous", 7), "binary", "continuous",
                                "binary", rep("continuous", 2)))
```


# Trial 29
## Load Data

```{r}
df29 = read_rds("cleaned_data/Non_Clustered_RCT/trial29.rds") %>% 
  select(-YP_death)
```

## Process

```{r}
res1 = analyze_rct(df29)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df29, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(29, c("time to event", "binary", "binary", "continuous"))
```



# Trial 30
## Load Data

```{r}
df30 = read_rds("cleaned_data/Non_Clustered_RCT/trial30.rds")
```

## Process

```{r}
res1 = analyze_rct(df30)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df30, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(30, c(rep("continuous", 6), "binary", rep("continuous", 2)))
```

# Trial 31
## Load Data

```{r}
df31 = read_rds("cleaned_data/Non_Clustered_RCT/trial31.rds") %>% 
  select(-YP_flu_infection)
```

## Process

```{r}
res1 = analyze_rct(df31)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df31, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(31, c("time to event", "continuous", "continuous", "binary", "binary"))
```


# Trial 32
## Load Data

```{r}
df32 = read_rds("cleaned_data/Non_Clustered_RCT/trial32.rds")
```

## Process

```{r}
res1 = analyze_rct(df32)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df32, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(32, c("categorical", "binary", "binary", "binary"))
```

# Trial 33
## Load Data

```{r}
df33 = read_rds("cleaned_data/Non_Clustered_RCT/trial33.rds")
```

## Process

```{r}
res1 = analyze_rct(df33)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df33, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(33, c("continuous", "binary"))
```
# Trial 34
## Load Data

```{r}
df34 = read_rds("cleaned_data/Non_Clustered_RCT/trial34.rds")
```

## Process

```{r}
res1 = analyze_rct(df34)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df34, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(34, c("binary", "continuous", rep("binary", 6)))
```

# Trial 35
## Load Data

```{r}
df35 = read_rds("cleaned_data/Non_Clustered_RCT/trial35.rds")
```

## Process

```{r}
res1 = analyze_rct(df35)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df35, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(35, c("continuous", "continuous", "continuous", "binary",
                                rep("continuous", 6)))
```
# Trial 36
## Load Data

```{r}
df36 = read_rds("cleaned_data/Non_Clustered_RCT/trial36.rds")
```

## Process

```{r}
res1 = analyze_rct(df36)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df36, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(36, rep("continuous", n))
```
# Trial 37
## Load Data

```{r}
df37 = read_rds("cleaned_data/Non_Clustered_RCT/trial37.rds")
```

## Process

```{r}
res1 = analyze_rct(df37)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df37, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(37, rep("binary", n))
```

# Trial 38
## Load Data

```{r}
df38 = read_rds("cleaned_data/Non_Clustered_RCT/trial38.rds") %>% 
  select(-YP_event_flag)
```

## Process

```{r}
res1 = analyze_rct(df38)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df38, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(38, c("time to event", "continuous", "continuous"))
```


# Trial 39
## Load Data

```{r}
df39 = read_rds("cleaned_data/Non_Clustered_RCT/trial39.rds") %>% 
  select(-YP_event_flag)
```


## Process

```{r}
res1 = analyze_rct(df39)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df39, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(39, c("time to event"))
```

# Trial 40
## Load Data

```{r}
df40 = read_rds("cleaned_data/Non_Clustered_RCT/trial40.rds") %>% 
  select(-YP_success_flag,  -YS_attempt1_time, -YS_attempt2_time, -YS_attempt3_time,
         -YS_attempt1_success, -YS_attempt2_success, -YS_attempt3_success, -YS_attempt2_assigned,-YS_attempt3_assigned)
```


## Process

```{r}
res1 = analyze_rct(df40)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df40, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(40, c("time to event", "continuous", "continuous", "binary", "continuous",
                                "continuous", "binary"))
```

# Trial 41
## Load Data

```{r}
df41 = read_rds("cleaned_data/Non_Clustered_RCT/trial41.rds")
```


## Process

```{r}
res1 = analyze_rct(df41)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df41, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(41, c(rep("binary", 5)))
```


# Trial 42
## Load Data

```{r}
df42 = read_rds("cleaned_data/Non_Clustered_RCT/trial42.rds") %>% 
  select(-YP_onset_sensory_censor, -YS_med_duration, -YS_med_duration_censor)
```


## Process

```{r}
res1 = analyze_rct(df42)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df42, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(42, c("time to event", rep("continuous", n-1)))
```

# Trial 43
## Load Data

```{r}
df43 = read_rds("cleaned_data/Non_Clustered_RCT/trial43.rds") %>% 
  select(-YP_preterm_flag)
```


## Process

```{r}
res1 = analyze_rct(df43)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df43, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(43, c("time to event", rep("continuous", 3), "binary"))
```

# Trial 44
## Load Data

```{r}
df44 = read_rds("cleaned_data/Non_Clustered_RCT/trial44.rds")
```


## Process

```{r}
res1 = analyze_rct(df44)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df44, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(44, c("binary", rep("continuous", 3)))
```

# Trial 45
## Load Data

```{r}
df45 = read_rds("cleaned_data/Non_Clustered_RCT/trial45.rds") %>% 
  select(-YS_delta_icedtea_24w, -YS_delta_alcohol_24w, -YS_delta_salty_24w,
         -YS_delta_fats_24w, -YS_delta_ldl_24w, -YS_delta_tg_24w, -YS_delta_hba1c_24w)
```


## Process

```{r}
res1 = analyze_rct(df45)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df45, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(45, c(rep("continuous", n)))
```

# Trial 46
## Load Data

```{r}
df46 = read_rds("cleaned_data/Non_Clustered_RCT/trial46.rds")
```

## Process

```{r}
res1 = analyze_rct(df46)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df46, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(46, c(rep("continuous", n)))
```


# Trial 47
## Load Data

```{r}
df47 = read_rds("cleaned_data/Non_Clustered_RCT/trial47.rds")
```



## Process

```{r}
res1 = analyze_rct(df47)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df47, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(47, c(rep("binary", 1), "continuous", "binary", "binary"))
```

# Trial 48
## Load Data

```{r}
df48 = read_rds("cleaned_data/Non_Clustered_RCT/trial48.rds")
```


## Process

```{r}
res1 = analyze_rct(df48)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df48, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(48, c("binary", rep("continuous", 6), rep("binary", 2)))
```


# Trial 49
## Load Data

```{r}
df49 = read_rds("cleaned_data/Non_Clustered_RCT/trial49.rds") %>% 
    select(-YS_t_sondad, -YS_full_oral)
```



## Process

```{r}
res1 = analyze_rct(df49)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df49, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(49, c(rep("continuous", 4), rep("binary", 4), rep("continuous", 9)))
```


# Trial 50
## Load Data

```{r}
df50 = read_rds("cleaned_data/Non_Clustered_RCT/trial50.rds") %>% 
  select(-YP_first_infection_event)
```


## Process

```{r}
res1 = analyze_rct(df50)
cat("\n<------------------Variable Seclection------------->\n\n")
res2 = analyze_rct(df50, selection = T)

n = length(unique(res1$Outcome))

df_comparison = update_df(50, c("time to event", "continuous"))
```


# Export

```{r}
write_xlsx(df_comparison, "cleaned_data/meta_data_comparison.xlsx")
```


# Summary Data
```{r}
# Create outcome_group variable
df_new = df_comparison %>%
  mutate(
    outcome_group = case_when(
      `Outcome Type` %in% c("continuous", "continuous proportion") ~ "continuous",
      `Outcome Type` %in% c("ordinal", "categorical") ~ "categorical", 
      `Outcome Type` %in% c("binary", "composite binary") ~ "binary",
      `Outcome Type` == "time to event" ~ "time_to_event",
      TRUE ~ "other"
    )
  )

# Rename all precision gain and variance ratio columns
df_new = df_new %>%
  rename(
    # Precision gain columns
    precision_gain_ANCOVA = `How much precision gain can ANCOVA provide?`,
    precision_gain_ANHECOVA = `How much precision gain can ANHECOVA provide?`,
    precision_gain_Binom = `How much precision gain can Binom provide?`,
    precision_gain_SL = `How much precision gain can SL provide?`,
    precision_gain_SL_rpart = `How much precision gain can SL_rpart provide?`,
    precision_gain_SL_nnet = `How much precision gain can SL_nnet provide?`,
    precision_gain_ANCOVA_VS = `How much precision gain can ANCOVA_VS provide?`,
    precision_gain_ANHECOVA_VS = `How much precision gain can ANHECOVA_VS provide?`,
    precision_gain_Binom_VS = `How much precision gain can Binom_VS provide?`,
    precision_gain_SL_VS = `How much precision gain can SL_VS provide?`,
    precision_gain_SL_rpart_VS = `How much precision gain can SL_rpart_VS provide?`,
    precision_gain_SL_nnet_VS = `How much precision gain can SL_nnet_VS provide?`,
    
    # Variance ratio columns
    variance_ratio_robust_model = `The ratio between robust and model-based variance estimators`,
    variance_ratio_ANCOVA_ANHECOVA = `ANCOVA vs ANHECOVA variance ratio`,
    variance_ratio_robust_model_VS = `The ratio between robust and model-based variance estimators_VS`,
    variance_ratio_ANCOVA_ANHECOVA_VS = `ANCOVA_VS vs ANHECOVA_VS variance ratio`
  )
```



## Variance Summary
```{r}
df_summary = df_new %>%
  group_by(outcome_group) %>%
  summarise(
    # ANCOVA precision-gain
    mean_prec_gain_ANCOVA     = mean(precision_gain_ANCOVA, na.rm = TRUE),
    sd_prec_gain_ANCOVA       = sd(precision_gain_ANCOVA,   na.rm = TRUE),
    
    # ANCOVA robust vs model-based variance ratio (original)
    mean_var_ratio_robust_model     = mean(variance_ratio_robust_model, na.rm = TRUE),
    sd_var_ratio_robust_model       = sd(variance_ratio_robust_model,   na.rm = TRUE),
    
    # ── ANCOVA vs ANHECOVA variance ratio *low outlier removed* ─────────────────────
    mean_var_ratio_ANCOVA_ANHECOVA = {
      v  = variance_ratio_ANCOVA_ANHECOVA
      lb = quantile(v, 0.25, na.rm = TRUE) - 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v >= lb], na.rm = TRUE)
    },
    sd_var_ratio_ANCOVA_ANHECOVA   = {
      v  = variance_ratio_ANCOVA_ANHECOVA
      lb = quantile(v, 0.25, na.rm = TRUE) - 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v >= lb], na.rm = TRUE)
    },
    # ANCOVA vs ANHECOVA variance ratio (full)
    mean_var_ratio_ANCOVA_ANHECOVA_full  = mean(variance_ratio_ANCOVA_ANHECOVA, na.rm = TRUE),
    sd_var_ratio_ANCOVA_ANHECOVA_full    = sd(variance_ratio_ANCOVA_ANHECOVA,   na.rm = TRUE),
    
    # ── ANHECOVA precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_ANHECOVA = {
      v  = precision_gain_ANHECOVA
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_ANHECOVA   = {
      v  = precision_gain_ANHECOVA
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    # ANHECOVA precision-gain (full)
    mean_prec_gain_ANHECOVA_full  = mean(precision_gain_ANHECOVA, na.rm = TRUE),
    sd_prec_gain_ANHECOVA_full    = sd(precision_gain_ANHECOVA,   na.rm = TRUE),
    
    # ── Binom precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_Binom = {
      v  = precision_gain_Binom
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_Binom   = {
      v  = precision_gain_Binom
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    # Binom precision-gain (full)
    mean_prec_gain_Binom_full  = mean(precision_gain_Binom, na.rm = TRUE),
    sd_prec_gain_Binom_full    = sd(precision_gain_Binom,   na.rm = TRUE),
    
    # ── SuperLearner precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_SL = {
      v  = precision_gain_SL
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_SL   = {
      v  = precision_gain_SL
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    # SuperLearner precision-gain (full)
    mean_prec_gain_SL_full     = mean(precision_gain_SL,  na.rm = TRUE),
    sd_prec_gain_SL_full       = sd(precision_gain_SL,    na.rm = TRUE),
    
    # ── SL_rpart precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_SL_rpart = {
      v  = precision_gain_SL_rpart
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_SL_rpart   = {
      v  = precision_gain_SL_rpart
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    # SL_rpart precision-gain (full)
    mean_prec_gain_SL_rpart_full  = mean(precision_gain_SL_rpart, na.rm = TRUE),
    sd_prec_gain_SL_rpart_full    = sd(precision_gain_SL_rpart,   na.rm = TRUE),
    
    # ── SL_nnet precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_SL_nnet = {
      v  = precision_gain_SL_nnet
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_SL_nnet   = {
      v  = precision_gain_SL_nnet
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    # SL_nnet precision-gain (full)
    mean_prec_gain_SL_nnet_full  = mean(precision_gain_SL_nnet, na.rm = TRUE),
    sd_prec_gain_SL_nnet_full    = sd(precision_gain_SL_nnet,   na.rm = TRUE),
    
    # ── ANCOVA_VS precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_ANCOVA_VS = {
      v  = precision_gain_ANCOVA_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_ANCOVA_VS   = {
      v  = precision_gain_ANCOVA_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    # ANCOVA_VS precision-gain (full)
    mean_prec_gain_ANCOVA_VS_full  = mean(precision_gain_ANCOVA_VS, na.rm = TRUE),
    sd_prec_gain_ANCOVA_VS_full    = sd(precision_gain_ANCOVA_VS,   na.rm = TRUE),
    
    # ── ANHECOVA_VS precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_ANHECOVA_VS = {
      v  = precision_gain_ANHECOVA_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_ANHECOVA_VS   = {
      v  = precision_gain_ANHECOVA_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    # ANHECOVA_VS precision-gain (full)
    mean_prec_gain_ANHECOVA_VS_full  = mean(precision_gain_ANHECOVA_VS, na.rm = TRUE),
    sd_prec_gain_ANHECOVA_VS_full    = sd(precision_gain_ANHECOVA_VS,   na.rm = TRUE),
    
    # ── Binom_VS precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_Binom_VS = {
      v  = precision_gain_Binom_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_Binom_VS   = {
      v  = precision_gain_Binom_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    # Binom_VS precision-gain (full)
    mean_prec_gain_Binom_VS_full  = mean(precision_gain_Binom_VS, na.rm = TRUE),
    sd_prec_gain_Binom_VS_full    = sd(precision_gain_Binom_VS,   na.rm = TRUE),
    
    # ── SL_VS precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_SL_VS = {
      v  = precision_gain_SL_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_SL_VS   = {
      v  = precision_gain_SL_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    # SL_VS precision-gain (full)
    mean_prec_gain_SL_VS_full  = mean(precision_gain_SL_VS, na.rm = TRUE),
    sd_prec_gain_SL_VS_full    = sd(precision_gain_SL_VS,   na.rm = TRUE),
    
    # ── SL_rpart_VS precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_SL_rpart_VS = {
      v  = precision_gain_SL_rpart_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_SL_rpart_VS   = {
      v  = precision_gain_SL_rpart_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    # SL_rpart_VS precision-gain (full)
    mean_prec_gain_SL_rpart_VS_full  = mean(precision_gain_SL_rpart_VS, na.rm = TRUE),
    sd_prec_gain_SL_rpart_VS_full    = sd(precision_gain_SL_rpart_VS,   na.rm = TRUE),
    
    # ── SL_nnet_VS precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_SL_nnet_VS = {
      v  = precision_gain_SL_nnet_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_SL_nnet_VS   = {
      v  = precision_gain_SL_nnet_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    # SL_nnet_VS precision-gain (full)
    mean_prec_gain_SL_nnet_VS_full  = mean(precision_gain_SL_nnet_VS, na.rm = TRUE),
    sd_prec_gain_SL_nnet_VS_full    = sd(precision_gain_SL_nnet_VS,   na.rm = TRUE),
    
    # ── Additional variance ratio variables ─────────────────────
    # Robust vs model-based variance ratio VS (with outlier removal)
    mean_var_ratio_robust_model_VS = {
      v  = variance_ratio_robust_model_VS
      lb = quantile(v, 0.25, na.rm = TRUE) - 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v >= lb], na.rm = TRUE)
    },
    sd_var_ratio_robust_model_VS   = {
      v  = variance_ratio_robust_model_VS
      lb = quantile(v, 0.25, na.rm = TRUE) - 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v >= lb], na.rm = TRUE)
    },
    # Robust vs model-based variance ratio VS (full)
    mean_var_ratio_robust_model_VS_full  = mean(variance_ratio_robust_model_VS, na.rm = TRUE),
    sd_var_ratio_robust_model_VS_full    = sd(variance_ratio_robust_model_VS,   na.rm = TRUE),
    
    # ANCOVA_VS vs ANHECOVA_VS variance ratio (with outlier removal)
    mean_var_ratio_ANCOVA_ANHECOVA_VS = {
      v  = variance_ratio_ANCOVA_ANHECOVA_VS
      lb = quantile(v, 0.25, na.rm = TRUE) - 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v >= lb], na.rm = TRUE)
    },
    sd_var_ratio_ANCOVA_ANHECOVA_VS   = {
      v  = variance_ratio_ANCOVA_ANHECOVA_VS
      lb = quantile(v, 0.25, na.rm = TRUE) - 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v >= lb], na.rm = TRUE)
    },
    # ANCOVA_VS vs ANHECOVA_VS variance ratio (full)
    mean_var_ratio_ANCOVA_ANHECOVA_VS_full  = mean(variance_ratio_ANCOVA_ANHECOVA_VS, na.rm = TRUE),
    sd_var_ratio_ANCOVA_ANHECOVA_VS_full    = sd(variance_ratio_ANCOVA_ANHECOVA_VS,   na.rm = TRUE)
    
  ) %>%
  ungroup()

print(df_summary)
```
### Outlier Removed Table
```{r}
df_summary_filtered = df_new %>%
  group_by(outcome_group) %>%
  summarise(
    # ANCOVA precision-gain (no outlier removal)
    mean_prec_gain_ANCOVA     = mean(precision_gain_ANCOVA, na.rm = TRUE),
    sd_prec_gain_ANCOVA       = sd(precision_gain_ANCOVA,   na.rm = TRUE),
    
    # ANCOVA robust vs model-based variance ratio (no outlier removal)
    mean_var_ratio_robust_model     = mean(variance_ratio_robust_model, na.rm = TRUE),
    sd_var_ratio_robust_model       = sd(variance_ratio_robust_model,   na.rm = TRUE),
    
    # ── ANCOVA vs ANHECOVA variance ratio *low outlier removed* ─────────────────────
    mean_var_ratio_ANCOVA_ANHECOVA = {
      v  = variance_ratio_ANCOVA_ANHECOVA
      lb = quantile(v, 0.25, na.rm = TRUE) - 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v >= lb], na.rm = TRUE)
    },
    sd_var_ratio_ANCOVA_ANHECOVA   = {
      v  = variance_ratio_ANCOVA_ANHECOVA
      lb = quantile(v, 0.25, na.rm = TRUE) - 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v >= lb], na.rm = TRUE)
    },
    
    # ── ANHECOVA precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_ANHECOVA = {
      v  = precision_gain_ANHECOVA
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_ANHECOVA   = {
      v  = precision_gain_ANHECOVA
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    
    # ── Binom precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_Binom = {
      v  = precision_gain_Binom
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_Binom   = {
      v  = precision_gain_Binom
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    
    # ── SuperLearner precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_SL = {
      v  = precision_gain_SL
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_SL   = {
      v  = precision_gain_SL
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    
    # ── SL_rpart precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_SL_rpart = {
      v  = precision_gain_SL_rpart
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_SL_rpart   = {
      v  = precision_gain_SL_rpart
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    
    # ── SL_nnet precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_SL_nnet = {
      v  = precision_gain_SL_nnet
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_SL_nnet   = {
      v  = precision_gain_SL_nnet
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    
    # ── ANCOVA_VS precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_ANCOVA_VS = {
      v  = precision_gain_ANCOVA_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_ANCOVA_VS   = {
      v  = precision_gain_ANCOVA_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    
    # ── ANHECOVA_VS precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_ANHECOVA_VS = {
      v  = precision_gain_ANHECOVA_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_ANHECOVA_VS   = {
      v  = precision_gain_ANHECOVA_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    
    # ── Binom_VS precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_Binom_VS = {
      v  = precision_gain_Binom_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_Binom_VS   = {
      v  = precision_gain_Binom_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    
    # ── SL_VS precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_SL_VS = {
      v  = precision_gain_SL_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_SL_VS   = {
      v  = precision_gain_SL_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    
    # ── SL_rpart_VS precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_SL_rpart_VS = {
      v  = precision_gain_SL_rpart_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_SL_rpart_VS   = {
      v  = precision_gain_SL_rpart_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    
    # ── SL_nnet_VS precision-gain *outlier removed* ─────────────────────
    mean_prec_gain_SL_nnet_VS = {
      v  = precision_gain_SL_nnet_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v <= ub], na.rm = TRUE)
    },
    sd_prec_gain_SL_nnet_VS   = {
      v  = precision_gain_SL_nnet_VS
      ub = quantile(v, 0.75, na.rm = TRUE) + 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v <= ub], na.rm = TRUE)
    },
    
    # ── Additional variance ratio variables *outlier removed* ─────────────────────
    # Robust vs model-based variance ratio VS
    mean_var_ratio_robust_model_VS = {
      v  = variance_ratio_robust_model_VS
      lb = quantile(v, 0.25, na.rm = TRUE) - 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v >= lb], na.rm = TRUE)
    },
    sd_var_ratio_robust_model_VS   = {
      v  = variance_ratio_robust_model_VS
      lb = quantile(v, 0.25, na.rm = TRUE) - 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v >= lb], na.rm = TRUE)
    },
    
    # ANCOVA_VS vs ANHECOVA_VS variance ratio
    mean_var_ratio_ANCOVA_ANHECOVA_VS = {
      v  = variance_ratio_ANCOVA_ANHECOVA_VS
      lb = quantile(v, 0.25, na.rm = TRUE) - 1.5 * IQR(v, na.rm = TRUE)
      mean(v[v >= lb], na.rm = TRUE)
    },
    sd_var_ratio_ANCOVA_ANHECOVA_VS   = {
      v  = variance_ratio_ANCOVA_ANHECOVA_VS
      lb = quantile(v, 0.25, na.rm = TRUE) - 1.5 * IQR(v, na.rm = TRUE)
      sd(v[v >= lb], na.rm = TRUE)
    }
    
  ) %>%
  ungroup()

print(df_summary_filtered)
```


## Violin Plot
### Full(n)
```{r}
# Create sample size categories for better visualization
df_new = df_new %>%
  mutate(
    sample_size_cat = case_when(
      Sample_Size < 50 ~ "<50",
      Sample_Size < 100 ~ "50-99", 
      Sample_Size < 500 ~ "100-499",
      TRUE ~ "≥500"
    ),
    sample_size_cat = factor(sample_size_cat, 
                           levels = c("<50", "50-99", "100-499", "≥500")),
    # Log-transform for size mapping (less skewed)
    log_sample_size = log10(Sample_Size)
  )

# Color palette for sample size categories
size_colors = c("<50" = "#d73027", "50-99" = "#fc8d59", 
                "100-499" = "#74c476", "≥500" = "#4575b4")

# Reshape data for plotting all methods together
library(tidyr)

##################################
## Apply outlier removal for each method (except ANCOVA)
##################################

# Function to remove upper outliers
remove_upper_outliers = function(x) {
  ub = quantile(x, 0.75, na.rm = TRUE) + 1.5 * IQR(x, na.rm = TRUE)
  ifelse(x <= ub, x, NA)
}

# Apply outlier removal to all methods except ANCOVA
df_outlier_removed = df_new %>%
  mutate(
    precision_gain_ANHECOVA = remove_upper_outliers(precision_gain_ANHECOVA),
    precision_gain_Binom = remove_upper_outliers(precision_gain_Binom),
    precision_gain_SL = remove_upper_outliers(precision_gain_SL),
    precision_gain_SL_rpart = remove_upper_outliers(precision_gain_SL_rpart),
    precision_gain_SL_nnet = remove_upper_outliers(precision_gain_SL_nnet),
    precision_gain_ANCOVA_VS = remove_upper_outliers(precision_gain_ANCOVA_VS),
    precision_gain_ANHECOVA_VS = remove_upper_outliers(precision_gain_ANHECOVA_VS),
    precision_gain_Binom_VS = remove_upper_outliers(precision_gain_Binom_VS),
    precision_gain_SL_VS = remove_upper_outliers(precision_gain_SL_VS),
    precision_gain_SL_rpart_VS = remove_upper_outliers(precision_gain_SL_rpart_VS),
    precision_gain_SL_nnet_VS = remove_upper_outliers(precision_gain_SL_nnet_VS)
    # Note: precision_gain_ANCOVA is kept as-is (no outlier removal)
    # Note: ranger methods removed
  )

# Create long format data with outlier-removed precision gain methods
df_long_outlier_removed = df_outlier_removed %>%
  select(outcome_group, sample_size_cat, 
         precision_gain_ANCOVA, precision_gain_ANHECOVA, precision_gain_Binom, precision_gain_SL,
         precision_gain_SL_rpart, precision_gain_SL_nnet,
         precision_gain_ANCOVA_VS, precision_gain_ANHECOVA_VS, precision_gain_Binom_VS,
         precision_gain_SL_VS, precision_gain_SL_rpart_VS, precision_gain_SL_nnet_VS) %>%
  pivot_longer(cols = starts_with("precision_gain_"), 
               names_to = "method", 
               values_to = "precision_gain") %>%
  filter(!is.na(precision_gain)) %>%  # Remove NA values explicitly
  mutate(
    method = case_when(
      method == "precision_gain_ANCOVA" ~ "ANCOVA",
      method == "precision_gain_ANHECOVA" ~ "ANHECOVA", 
      method == "precision_gain_Binom" ~ "Binom",
      method == "precision_gain_SL" ~ "SL",
      method == "precision_gain_SL_rpart" ~ "SL_rpart",
      method == "precision_gain_SL_nnet" ~ "SL_nnet",
      method == "precision_gain_ANCOVA_VS" ~ "ANCOVA_VS",
      method == "precision_gain_ANHECOVA_VS" ~ "ANHECOVA_VS",
      method == "precision_gain_Binom_VS" ~ "Binom_VS",
      method == "precision_gain_SL_VS" ~ "SL_VS",
      method == "precision_gain_SL_rpart_VS" ~ "SL_rpart_VS",
      method == "precision_gain_SL_nnet_VS" ~ "SL_nnet_VS"
    ),
    method = factor(method, levels = c("ANCOVA", "ANHECOVA", "Binom", "SL", "SL_rpart", "SL_nnet",
                                     "ANCOVA_VS", "ANHECOVA_VS", "Binom_VS", "SL_VS", "SL_rpart_VS", "SL_nnet_VS"))
  )

# Color palette for methods (ranger removed)
method_colors = c("ANCOVA" = "#1f77b4", "ANHECOVA" = "#ff7f0e", "Binom" = "#2ca02c", "SL" = "#d62728",
                  "SL_rpart" = "#9467bd", "SL_nnet" = "#e377c2",
                  "ANCOVA_VS" = "#7f7f7f", "ANHECOVA_VS" = "#bcbd22", "Binom_VS" = "#17becf",
                  "SL_VS" = "#ff9896", "SL_rpart_VS" = "#c5b0d5", "SL_nnet_VS" = "#f7b6d3")

##################################
## All Methods Together (Outlier Removed) - By Outcome Type
##################################

# 1. Binary Outcome Group - All Methods (Outlier Removed)
df_binary_or = df_long_outlier_removed %>% filter(outcome_group == "binary")

ggplot(df_binary_or, aes(x = method, y = precision_gain)) +
  geom_violin(aes(fill = method), trim = FALSE, alpha = 0.6) +
  geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_fill_manual(values = method_colors, guide = "none") +
  scale_color_manual(values = size_colors, name = "Sample Size") +
  labs(
    title = "Precision Gain vs Unadjusted - Binary \n(Outlier Removed)",
    subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
    x = "",
    y = "Variance Ratio"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
        axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
        panel.grid.minor = element_blank(),
        legend.position = "right",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 9),
        legend.key.size = unit(0.4, "cm"))

# 2. Continuous Outcome Group - All Methods (Outlier Removed)
df_continuous_or = df_long_outlier_removed %>% filter(outcome_group == "continuous")

ggplot(df_continuous_or, aes(x = method, y = precision_gain)) +
  geom_violin(aes(fill = method), trim = FALSE, alpha = 0.6) +
  geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_fill_manual(values = method_colors, guide = "none") +
  scale_color_manual(values = size_colors, name = "Sample Size") +
  labs(
    title = "Precision Gain vs Unadjusted - Continuous \n(Outlier Removed)",
    subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
    x = "",
    y = "Variance Ratio"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
        axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
        panel.grid.minor = element_blank(),
        legend.position = "right",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 9),
        legend.key.size = unit(0.4, "cm"))

# 3. Categorical Outcome Group - All Methods (Outlier Removed)
df_categorical_or = df_long_outlier_removed %>% filter(outcome_group == "categorical")

ggplot(df_categorical_or, aes(x = method, y = precision_gain)) +
  geom_violin(aes(fill = method), trim = FALSE, alpha = 0.6) +
  geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_fill_manual(values = method_colors, guide = "none") +
  scale_color_manual(values = size_colors, name = "Sample Size") +
  labs(
    title = "Precision Gain vs Unadjusted - Categorical \n(Outlier Removed)",
    subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
    x = "",
    y = "Variance Ratio"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
        axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
        panel.grid.minor = element_blank(),
        legend.position = "right",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 9),
        legend.key.size = unit(0.4, "cm"))

# 4. Time-to-Event Outcome Group - All Methods (Outlier Removed)
df_time_to_event_or = df_long_outlier_removed %>% filter(outcome_group == "time_to_event")

ggplot(df_time_to_event_or, aes(x = method, y = precision_gain)) +
  geom_violin(aes(fill = method), trim = FALSE, alpha = 0.6) +
  geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_fill_manual(values = method_colors, guide = "none") +
  scale_color_manual(values = size_colors, name = "Sample Size") +
  labs(
    title = "Precision Gain vs Unadjusted - Time-to-Event\n (Outlier Removed)",
    subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
    x = "",
    y = "Variance Ratio"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
        axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
        panel.grid.minor = element_blank(),
        legend.position = "right",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 9),
        legend.key.size = unit(0.4, "cm"))

##################################
## Individual Method Plots (No Outlier Removal)
##################################

# ANCOVA (already no outlier removal)
ggplot(df_new %>% filter(!is.na(precision_gain_ANCOVA)), aes(x = outcome_group, y = precision_gain_ANCOVA)) +
  geom_violin(trim = FALSE, fill = "#1f77b4", alpha = 0.6) +
  geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_color_manual(values = size_colors, name = "Sample Size") +
  labs(
    title = "ANCOVA Precision Gain vs Unadjusted (Full Data)",
    subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
    x = "Outcome Group",
    y = "Variance Ratio"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
        panel.grid.minor = element_blank(),
        legend.position = "right",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 9),
        legend.key.size = unit(0.4, "cm"))

# ANHECOVA (full data)
ggplot(df_new %>% filter(!is.na(precision_gain_ANHECOVA)), aes(x = outcome_group, y = precision_gain_ANHECOVA)) +
  geom_violin(trim = FALSE, fill = "#ff7f0e", alpha = 0.6) +
  geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_color_manual(values = size_colors, name = "Sample Size") +
  labs(
    title = "ANHECOVA Precision Gain vs Unadjusted (Full Data)",
    subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
    x = "Outcome Group",
    y = "Variance Ratio"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
        panel.grid.minor = element_blank(),
        legend.position = "right",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 9),
        legend.key.size = unit(0.4, "cm"))

# Binom (full data)
ggplot(df_new %>% filter(!is.na(precision_gain_Binom)), aes(x = outcome_group, y = precision_gain_Binom)) +
  geom_violin(trim = FALSE, fill = "#2ca02c", alpha = 0.6) +
  geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_color_manual(values = size_colors, name = "Sample Size") +
  labs(
    title = "Binom Precision Gain vs Unadjusted (Full Data)",
    subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
    x = "Outcome Group",
    y = "Variance Ratio"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
        panel.grid.minor = element_blank(),
        legend.position = "right",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 9),
        legend.key.size = unit(0.4, "cm"))

# Super Learner (full data)
ggplot(df_new %>% filter(!is.na(precision_gain_SL)), aes(x = outcome_group, y = precision_gain_SL)) +
  geom_violin(trim = FALSE, fill = "#d62728", alpha = 0.6) +
  geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_color_manual(values = size_colors, name = "Sample Size") +
  labs(
    title = "Super Learner Precision Gain vs Unadjusted (Full Data)",
    subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
    x = "Outcome Group",
    y = "Variance Ratio"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
        panel.grid.minor = element_blank(),
        legend.position = "right",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 9),
        legend.key.size = unit(0.4, "cm"))

# SL_rpart (full data)
ggplot(df_new %>% filter(!is.na(precision_gain_SL_rpart)), aes(x = outcome_group, y = precision_gain_SL_rpart)) +
  geom_violin(trim = FALSE, fill = "#9467bd", alpha = 0.6) +
  geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_color_manual(values = size_colors, name = "Sample Size") +
  labs(
    title = "SL_rpart Precision Gain vs Unadjusted (Full Data)",
    subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
    x = "Outcome Group",
    y = "Variance Ratio"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
        panel.grid.minor = element_blank(),
        legend.position = "right",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 9),
        legend.key.size = unit(0.4, "cm"))

# SL_nnet (full data)
ggplot(df_new %>% filter(!is.na(precision_gain_SL_nnet)), aes(x = outcome_group, y = precision_gain_SL_nnet)) +
  geom_violin(trim = FALSE, fill = "#e377c2", alpha = 0.6) +
  geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_color_manual(values = size_colors, name = "Sample Size") +
  labs(
    title = "SL_nnet Precision Gain vs Unadjusted (Full Data)",
    subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
    x = "Outcome Group",
    y = "Variance Ratio"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
        panel.grid.minor = element_blank(),
        legend.position = "right",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 9),
        legend.key.size = unit(0.4, "cm"))

# ANCOVA_VS (full data)
ggplot(df_new %>% filter(!is.na(precision_gain_ANCOVA_VS)), aes(x = outcome_group, y = precision_gain_ANCOVA_VS)) +
  geom_violin(trim = FALSE, fill = "#7f7f7f", alpha = 0.6) +
  geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_color_manual(values = size_colors, name = "Sample Size") +
  labs(
    title = "ANCOVA_VS Precision Gain vs Unadjusted (Full Data)",
    subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
    x = "Outcome Group",
    y = "Variance Ratio"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
        panel.grid.minor = element_blank(),
        legend.position = "right",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 9),
        legend.key.size = unit(0.4, "cm"))

# ANHECOVA_VS (full data)
ggplot(df_new %>% filter(!is.na(precision_gain_ANHECOVA_VS)), aes(x = outcome_group, y = precision_gain_ANHECOVA_VS)) +
  geom_violin(trim = FALSE, fill = "#bcbd22", alpha = 0.6) +
  geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_color_manual(values = size_colors, name = "Sample Size") +
  labs(
    title = "ANHECOVA_VS Precision Gain vs Unadjusted (Full Data)",
    subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
    x = "Outcome Group",
    y = "Variance Ratio"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
        panel.grid.minor = element_blank(),
        legend.position = "right",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 9),
        legend.key.size = unit(0.4, "cm"))

# Binom_VS (full data)
ggplot(df_new %>% filter(!is.na(precision_gain_Binom_VS)), aes(x = outcome_group, y = precision_gain_Binom_VS)) +
  geom_violin(trim = FALSE, fill = "#17becf", alpha = 0.6) +
  geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_color_manual(values = size_colors, name = "Sample Size") +
  labs(
    title = "Binom_VS Precision Gain vs Unadjusted (Full Data)",
    subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
    x = "Outcome Group",
    y = "Variance Ratio"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
        panel.grid.minor = element_blank(),
        legend.position = "right",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 9),
        legend.key.size = unit(0.4, "cm"))

# SL_VS (full data)
ggplot(df_new %>% filter(!is.na(precision_gain_SL_VS)), aes(x = outcome_group, y = precision_gain_SL_VS)) +
  geom_violin(trim = FALSE, fill = "#ff9896", alpha = 0.6) +
  geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_color_manual(values = size_colors, name = "Sample Size") +
  labs(
    title = "SL_VS Precision Gain vs Unadjusted (Full Data)",
    subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
    x = "Outcome Group",
    y = "Variance Ratio"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
        panel.grid.minor = element_blank(),
        legend.position = "right",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 9),
        legend.key.size = unit(0.4, "cm"))

# SL_rpart_VS (full data)
ggplot(df_new %>% filter(!is.na(precision_gain_SL_rpart_VS)), aes(x = outcome_group, y = precision_gain_SL_rpart_VS)) +
  geom_violin(trim = FALSE, fill = "#c5b0d5", alpha = 0.6) +
  geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_color_manual(values = size_colors, name = "Sample Size") +
  labs(
    title = "SL_rpart_VS Precision Gain vs Unadjusted (Full Data)",
    subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
    x = "Outcome Group",
    y = "Variance Ratio"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
        panel.grid.minor = element_blank(),
        legend.position = "right",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 9),
        legend.key.size = unit(0.4, "cm"))

# SL_nnet_VS (full data)
ggplot(df_new %>% filter(!is.na(precision_gain_SL_nnet_VS)), aes(x = outcome_group, y = precision_gain_SL_nnet_VS)) +
  geom_violin(trim = FALSE, fill = "#f7b6d3", alpha = 0.6) +
  geom_jitter(aes(color = sample_size_cat), width = 0.15, alpha = 0.7, size = 1) +
  geom_hline(yintercept = 1, linetype = "dashed", color = "gray40") +
  scale_color_manual(values = size_colors, name = "Sample Size") +
  labs(
    title = "SL_nnet_VS Precision Gain vs Unadjusted (Full Data)",
    subtitle = "Values <1 indicate precision improvement over unadjusted analysis",
    x = "Outcome Group",
    y = "Variance Ratio"
  ) +
  theme_minimal(base_size = 14) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5, color = "gray60", size = 12),
        panel.grid.minor = element_blank(),
        legend.position = "right",
        legend.title = element_text(size = 10),
        legend.text = element_text(size = 9),
        legend.key.size = unit(0.4, "cm"))
```

